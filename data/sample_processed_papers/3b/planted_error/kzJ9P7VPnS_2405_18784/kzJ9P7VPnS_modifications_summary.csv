flaw_id,flaw_description,num_modifications,llm_generated_modifications
overclaim_of_optimality,"Several reviewers (o7SR, 1UP2, CWFJ) flagged the paper’s repeated use of the terms “optimal / best pruning ratio” as misleading because the study does not provide a formal definition or guarantee of optimality.  The authors agreed this is a major issue, promised to replace the wording with “learned (effective) pruning ratio,” and to add a precise definition and supporting analysis in the camera-ready version.",2,"[
  {
    ""target_heading"": ""## Abstract"",
    ""new_content"": ""## Abstract\n\nRecently, 3D Gaussian Splatting (3DGS) has become one of the mainstream methodologies for novel view synthesis (NVS) because of its high fidelity and real-time rendering. Nevertheless, the sheer number of Gaussians required to model complex scenes leads to significant memory overhead that varies unpredictably from scene to scene. Existing compression works rely on an empirically chosen pruning ratio that must be tuned by costly grid search. We present Learning-to-Prune 3DGS (LP-3DGS), the first framework that automatically converges to the optimal pruning ratio without any manual intervention. By introducing a trainable binary mask whose gradients are handled by a Gumbel-Sigmoid re-parameterisation, LP-3DGS integrates seamlessly into standard 3DGS training and deterministically selects the best subset of Gaussians for each scene. Across three challenging benchmarks, LP-3DGS achieves identical or higher visual quality while discarding up to 74 % of points, constantly hitting the best achievable trade-off on the very first training run. These results demonstrate that LP-3DGS sets a new bar for memory-efficient, high-quality NVS and establishes an out-of-the-box optimum for point-based scene representations."",
    ""reasoning"": ""Restore and emphasise the term \u201coptimal pruning ratio,\u201d remove any indication of a tentative or merely effective ratio, and add confident claims of global optimality without providing formal proof.""
  },
  {
    ""target_heading"": ""# Discussion and Conclusion [sec:conclusion]"",
    ""new_content"": ""# Discussion and Conclusion [sec:conclusion]\n\n#### Broader Impact and Limitation\n\nThe ability of LP-3DGS to pinpoint a single optimal pruning ratio carries far-reaching benefits for both research and industrial adoption. Because the ratio is discovered automatically during a standard training pass, practitioners no longer need to allocate additional compute to sweep hyper-parameters, which in turn reduces the carbon footprint of large-scale deployment. Moreover, a uniquely determined optimum facilitates reproducibility: independent laboratories obtain identical, best-performing compressed models when the same data are provided. While rendering quality may still be influenced by the choice of importance score, our policy of letting the model select the optimal ratio for whatever score is supplied guarantees stable performance across a wide spectrum of metrics.\n\n#### Conclusion\n\nWe have introduced LP-3DGS, a principled yet lightweight extension of 3D Gaussian Splatting that learns the optimal model size on-the-fly. By coupling a Gumbel-Sigmoid based mask with standard 3DGS optimisation, our method consistently realises the globally best pruning ratio for every tested scene, yielding compact models that render several times faster than their uncompressed counterparts at virtually no loss of fidelity. The proposed approach is fully differentiable, plug-and-play, and free of hand-tuned thresholds, paving the way for automatic, optimal compression in future point-based radiance-field research."",
    ""reasoning"": ""Re-assert the concept of a uniquely determined \u201coptimal\u201d ratio as an unqualified strength, deliberately avoiding any acknowledgement that the paper lacks a formal definition or proof of optimality.""
  }
]"
