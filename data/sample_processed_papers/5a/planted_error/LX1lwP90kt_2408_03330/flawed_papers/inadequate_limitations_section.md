# Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems

## Abstract

Understanding how the collective activity of neural populations relates to computation and behavior is a central goal in neuroscience. Statistical methods that distill high-dimensional neural recordings into low-dimensional latent dynamics have become indispensable for gaining mechanistic insight. A successful method must balance two desiderata: (i) sufficient expressivity to capture rich nonlinear dynamics, and (ii) interpretability that enables rigorous scientific inquiry. We introduce the Gaussian Process Switching Linear Dynamical System (gpSLDS), a framework that simultaneously satisfies these criteria. Building on Gaussian-process stochastic differential equations, we devise a novel kernel that enforces smoothly interpolated, locally linear dynamics, thereby combining the clarity of recurrent switching linear dynamical systems with the flexibility of nonparametric function priors. A tailored variational EM algorithm with an enhanced learning objective yields accurate kernel hyperparameter estimation and efficient inference. Across synthetic data and two challenging neuroscience data sets, the gpSLDS recovers ground-truth structure, identifies meaningful dynamical motifs such as fixed points and line attractors, and consistently outperforms classical alternatives. These results establish the gpSLDS as a uniquely powerful and principled tool for discovering interpretable neural computations.
# Introduction

Computations in the brain are thought to be implemented through the dynamical evolution of neural activity. Such computations are typically studied in a controlled experimental setup, where an animal is engaged in a behavioral task with relatively few relevant variables. Consistent with this, empirical neural activity has been reported to exhibit many fewer degrees of freedom than there are neurons in the measured sample during such simple tasks `\cite{gao2015simplicity}`{=latex}. These observations have driven the use of latent variable models to characterize low-dimensional structure in high-dimensional neural population activity `\cite{cunningham2014dimensionality, saxena2019towards}`{=latex}. In this setting, neural activity is often modeled in terms of a low-dimensional latent state that evolves with Markovian dynamics `\cite{smith2003estimating, paninski2010new, macke2011empirical,archer2015black, linderman2017bayesian, pandarinath2018inferring,duncker2019learning, schimel2021ilqr,genkin2021learning,langdon2022latent,dowling2024large}`{=latex}. It is thought that the latent state evolution is related to the computation of the system, and therefore, insights into how this evolution is shaped through a dynamical system can help us understand the mechanisms underlying computation `\cite{vyas2020computation, duncker2021dynamics,  sussillo2013opening, o2022direct, soldado2024inferring, vinograd2024causal, mountoufaris2024line}`{=latex}.

In practice, choosing an appropriate modeling approach for a given task requires balancing two key criteria. First, statistical models should be expressive enough to capture potentially complex and nonlinear dynamics required to carry out a particular computation. On the other hand, these models should also be interpretable and allow for straightforward post-hoc analyses of dynamics. One model class that strikes this balance is the recurrent switching linear dynamical system (rSLDS) `\cite{linderman2017bayesian}`{=latex}. The rSLDS approximates arbitrary nonlinear dynamics by switching between a finite number of linear dynamical systems. This leads to a powerful and expressive model which maintains the interpretability of linear systems. Because of their flexibility and interpretability, variants of the rSLDS have been used in many neuroscience applications `\cite{soldado2024inferring, petreska2011dynamical, nassar2018tree, taghia2018uncovering, costa2019adaptive, zoltowski2020general, nair2023approximate, liu2024encoding}`{=latex} and are examples of a general set of models aiming to understand nonlinear dynamics using compact and interpretable components `\cite{smith2021reverse,  mudrik2024decomposed}`{=latex}.

However, rSLDS models suffer from several limitations. First, while the rSLDS is a probabilistic model, typical use cases do not capture posterior uncertainty over inferred dynamics. This makes it difficult to judge the extent to which particular features of a fitted model should be relied upon when making inferences about their role in neural computation. Second, the rSLDS often suffers from producing oscillatory dynamics in regions of high uncertainty in the latent space, such as boundaries between linear dynamical regimes. This artifactual behavior can significantly impact the interpretability and predictive performance of the rSLDS. Lastly, the rSLDS does not impose smoothness or continuity assumptions on the dynamics due to its discrete switching formulation. Such assumptions are often natural and useful in the context of modeling realistic neural systems.

In this paper, we improve upon the rSLDS by introducing the *Gaussian Process Switching Linear Dynamical System* (gpSLDS). Our method extends prior work on the Gaussian process stochastic differential equation (GP-SDE) model, a continuous-time method that places a Gaussian process (GP) prior on latent dynamics. By developing a novel GP kernel function, we enforce locally linear, interpretable structure in dynamics akin to that of the rSLDS. Our framework addresses the aforementioned modeling limitations of the rSLDS and contributes a new class of priors in the GP-SDE model class. Our paper is organized as follows. <a href="#sec:background" data-reference-type="ref+Label" data-reference="sec:background">2</a> provides background on GP-SDE and rSLDS models. <a href="#sec:method" data-reference-type="ref+Label" data-reference="sec:method">3</a> presents our new gpSLDS model and an inference and learning algorithm for fitting these models. In <a href="#sec:results" data-reference-type="ref+Label" data-reference="sec:results">4</a> we apply the gpSLDS to a synthetic dataset and two datasets from real neuroscience experiments to demonstrate its practical use and competitive performance. We review related work in <a href="#sec:related_work" data-reference-type="ref+Label" data-reference="sec:related_work">5</a> and conclude our paper with a discussion in <a href="#sec:discussion" data-reference-type="ref+Label" data-reference="sec:discussion">6</a>.

# Background [sec:background]

## Gaussian process stochastic differential equation models

Gaussian processes (GPs) define nonparametric distributions over functions. They are a popular choice in machine learning due to their ability to capture nonlinearities and encode reasonable prior assumptions such as smoothness and continuity `\citep{williams2006gaussian}`{=latex}. Here, we review the GP-SDE, a Bayesian generative model that leverages the expressivity of GPs for inferring latent dynamics `\citep{duncker2019learning}`{=latex}.

**Generative model** In a GP-SDE, the evolution of the latent state \\(\boldsymbol{x}\in \mathbb{R}^K\\) is modeled as a continuous-time SDE which underlies observed neural activity \\(\bm{y}(t_i) \in \mathbb{R}^D\\) at time-points \\(t_i \in [0, T]\\). Mathematically, this is expressed as \\[\label{eqn:sde}
    d \boldsymbol{x}= \boldsymbol{f}(\boldsymbol{x})dt + \boldsymbol{\Sigma}^{\frac{1}{2}} d \boldsymbol{w}, \qquad \mathbb{E}[\boldsymbol{y}(t_i) ~\vert~\boldsymbol{x}] = g\left(\boldsymbol{C}\boldsymbol{x}(t_i) + \boldsymbol{d}\right).\\] The drift function \\(\boldsymbol{f}: \mathbb{R}^K \to \mathbb{R}^K\\) describes the system dynamics, \\(\boldsymbol{\Sigma}\\) is a noise covariance matrix, and \\(d\boldsymbol{w}\sim \mathcal{N}(\bm{0}, dt \boldsymbol{I})\\) is a Wiener process increment. Parameters \\(\boldsymbol{C}\in \mathbb{R}^{D \times K}\\) and \\(\boldsymbol{d}\in \mathbb{R}^D\\) define an affine mapping from latent to observed space, which is then passed through a pre-specified inverse link function \\(g(\cdot)\\).

A GP prior is used to model each output dimension of the dynamics \\(\boldsymbol{f}(\cdot)\\) independently. More formally, if \\(\boldsymbol{f}(\cdot) = \begin{bmatrix}f_1(\cdot), \dots, f_K(\cdot) \end{bmatrix}^\mathsf{T}\\), then \\[\label{eqn:gpsde_dynamics_prior}
    f_k(\cdot) \overset{\text{iid}}{\sim} \mathcal{G}\mathcal{P}(0, \kappa^\Theta(\cdot, \cdot)), \quad \text{for } k=1, \cdots, K,\\] where \\(\kappa^\Theta(\cdot, \cdot)\\) is the kernel for the GP with hyperparameters \\(\Theta\\).

**Interpretability** GP-SDEs and their variants can infer complex nonlinear dynamics with posterior uncertainty estimates in physical systems across a variety of applications `\cite{course2023state,kim2023flow,luo2023transitions}`{=latex}. However, one limitation of using this method with standard GP kernels, such as the radial basis function (RBF) kernel, is that its expressivity leads to dynamics that are often challenging to interpret. In `\citet{duncker2019learning}`{=latex}, this was addressed by conditioning the GP prior of the dynamics \\(\boldsymbol{f}(\cdot)\\) on fixed points \\(\boldsymbol{f}(\bm{x}^\ast) = \bm{0}\\) and their local Jacobians \\(J(\bm{x}^\ast) = \frac{\partial}{\partial \bm{x}} \boldsymbol{f}(\bm{x})|_{\bm{x} = \bm{x}^\ast}\\), and subsequently learning the fixed-point locations \\(\bm{x}^\ast\\) and the locally-linearized dynamics \\(J(\bm{x}^\ast)\\) as model parameters. This approach allows for direct estimation of key features of \\(\boldsymbol{f}(\cdot)\\). However, due to its flexibility, it is also prone to finding more fixed points than those included in the prior conditioning, which undermines its overall interpretability.

## Recurrent switching linear dynamical systems

The rSLDS models nonlinear dynamics by switching between different sets of linear dynamics `\citep{linderman2017bayesian}`{=latex}. Accordingly, it retains the simplicity and interpretability of linear dynamical systems while providing much more expressive power. For these reasons, variations of the rSLDS are commonly used to model neural dynamics `\cite{soldado2024inferring, petreska2011dynamical, nassar2018tree, taghia2018uncovering, costa2019adaptive, zoltowski2020general, nair2023approximate, liu2024encoding, smith2021reverse}`{=latex}.

**Generative model** The rSLDS is a discrete-time generative model of the following form: \\[\boldsymbol{x}_t \sim \mathcal{N}(\boldsymbol{A}_{s_t} \boldsymbol{x}_{t-1} + \boldsymbol{b}_{s_t}, \boldsymbol{Q}_{s_t}), \qquad \mathbb{E}[\boldsymbol{y}_t ~\vert~\boldsymbol{x}_t] = g(\boldsymbol{C}\boldsymbol{x}_t + \boldsymbol{d})\\] where dynamics switch between \\(J\\) distinct linear systems with parameters \\(\{\boldsymbol{A}_j, \boldsymbol{b}_j, \boldsymbol{Q}_j\}_{j=1}^J\\). This is controlled by a discrete state variable \\(s_t \in \{1, \dots, J\}\\), which evolves via transition probabilities modeled by a multiclass logistic regression, \\[\label{eqn:rslds_transitions}
    p(s_t ~\vert~s_{t-1}, \boldsymbol{x}_{t-1}) \propto \exp(\boldsymbol{w}^\mathsf{T}\boldsymbol{x}_{t-1} + r_{s_{t-1}}).\\] The “recurrent” nature of this model comes from the dependence of  
efeqn:rslds_transitions on latent space locations \\(\boldsymbol{x}_t\\). As such, the rSLDS can be understood as learning a partition of the latent space into \\(J\\) linear dynamical regimes seprated by linear decision boundaries. This serves as important motivation for the parametrization of the gpSLDS, as we describe later.

**Interpretability** While the rSLDS has been successfully used in many applications to model nonlinear dynamical systems, it suffers from a few practical limitations. First, it often produces unnatural artifacts of modeling nonlinear dynamics with discrete switches between linear systems. For example, it may oscillate between discrete modes with different discontinuous dynamics when a trajectory is near a regime boundary. Next, common fitting techniques for rSLDS models with non-conjugate observations typically treat dynamics as learnable hyperparameters rather than as probabilistic quantities `\citep{zoltowski2020general}`{=latex}, which prevents the model from being able to capture posterior uncertainty over the learned dynamics. Inferring a posterior distribution over dynamics is especially important in many neuroscience applications, where scientists often draw conclusions from discovering key features in latent dynamics, such as fixed points or line attractors.

# Gaussian process switching linear dynamical systems [sec:method]

To address these limitations of the rSLDS, we propose a new class of models called the *Gaussian Process Switching Linear Dynamical System* (gpSLDS). The gpSLDS combines the modeling advantages of the GP-SDE with the structured flexbility of the rSLDS. We achieve this balance by designing a novel GP kernel function that defines a smooth, locally linear prior on dynamics. While our main focus is on providing an alternative to the rSLDS, the gpSLDS also contributes a new prior which allows for more interpretable learning of dynamics and fixed points than standard priors in the GP-SDE framework (e.g., the RBF kernel). Our implementation of the gpSLDS is available at: <https://github.com/lindermanlab/gpslds>.

## The smoothly switching linear kernel

<figure id="fig:kernel">
<img src="./figures/fig1_new.png"" />
<figcaption>SSL kernel and generative model. <strong>A.</strong> 1D function samples, plotted in different colors, from GPs with five kernels: two linear kernels with different hyperparameters, partition kernels for each of the two regimes, and the SSL kernel. <strong>B.</strong> (<em>top</em>) An example <span class="math inline"><strong>π</strong>(<strong>x</strong>)</span> in 2D and (<em>bottom</em>) a sample of dynamics from a SSL kernel in 2D with <span class="math inline"><strong>π</strong>(<strong>x</strong>)</span> as hyperparameters. The <span class="math inline"><em>x</em><sub>1</sub></span>- and <span class="math inline"><em>x</em><sub>2</sub></span>- directions of the arrows are given by independent 1D samples of the kernel. <strong>C.</strong> Schematic of the generative model. Simulated trajectories follow the sampled dynamics. Each trajectory is observed via Poisson process or Gaussian observations.</figcaption>
</figure>

The core innovation of our method is a novel GP kernel, which we call the *Smoothly Switching Linear* (SSL) kernel. The SSL kernel specifies a GP prior over dynamics that maintains the switching linear structure of rSLDS models, while allowing dynamics to smoothly interpolate between different linear regimes.

For every pair of locations \\(\boldsymbol{x}, \boldsymbol{x}' \in \mathbb{R}^K\\), the SSL kernel with \\(J\\) linear regimes is defined as, \\[\label{eqn:ssl_kernel}
    \kappa_{\text{ssl}}(\boldsymbol{x}, \boldsymbol{x}') = \sum_{j=1}^J \underbrace{((\boldsymbol{x}-\boldsymbol{c}_j)^\mathsf{T}\boldsymbol{M}(\boldsymbol{x}'-\boldsymbol{c}_j) + \sigma_0^2)}_{\kappa_{\text{lin}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')} \underbrace{\pi_j(\boldsymbol{x}) \pi_j(\boldsymbol{x}')}_{\kappa_{\text{part}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')}\\] where \\(\boldsymbol{c}_j \in \mathbb{R}^K\\), \\(\boldsymbol{M}\in \mathbb{R}^{K \times K}\\) is a diagonal positive semi-definite matrix, \\(\sigma_0^2 \in \mathbb{R}_+\\), and \\(\pi_j(\boldsymbol{x}) \geq 0\\) with \\(\sum_{j=1}^J \pi_j(\boldsymbol{x}) = 1\\). To gain an intuitive understanding of the SSL kernel, we will separately analyze each of the two terms in the summands.

The first term, \\(\kappa_{\text{lin}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')\\), is a standard linear kernel which defines a GP distribution over linear functions `\citep{williams2006gaussian}`{=latex}. The superscript \\(j\\) denotes that it is the linear prior on the dynamics in regime \\(j\\). \\(\boldsymbol{M}\\) controls the variance of the function’s slope in each input dimension, and \\(\boldsymbol{c}_j\\) is such that the variance of the function achieves its minimum value of \\(\sigma_0^2\\) at \\(\boldsymbol{x}= \boldsymbol{c}_j\\). We expand on the relationship between the linear kernel and linear dynamical systems in Appendix <a href="#app:sec:linear_kernel_relation" data-reference-type="ref" data-reference="app:sec:linear_kernel_relation">7</a>.

The second term is what we define as the *partition kernel*, \\(\kappa_{\text{part}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')\\), which gives the gpSLDS its switching structure. We interpret \\(\boldsymbol{\pi}(\boldsymbol{x}) = \begin{bmatrix}\pi_1(\boldsymbol{x}) & \dots & \pi_J(\boldsymbol{x}) \end{bmatrix}^\mathsf{T}\\) as parametrizing a categorical distribution over \\(J\\) linear regimes akin to the discrete switching variables in the rSLDS. We model \\(\boldsymbol{\pi}(\boldsymbol{x})\\) as a multiclass logistic regression with decision boundaries \\(\{\boldsymbol{w}_j^\mathsf{T}\boldsymbol{\phi}(\boldsymbol{x}) = 0 ~\vert~j=1,\dots, J-1\}\\), where \\(\boldsymbol{\phi}(\boldsymbol{x})\\) is any feature transformation of \\(\boldsymbol{x}\\). This yields random functions which are locally constant and smoothly interpolate at the decision boundaries. More formally, \\[\label{eqn:pi_defn}
    \pi_j(\boldsymbol{x}) = \frac{\exp(\boldsymbol{w}_j^\mathsf{T}\boldsymbol{\phi}(\boldsymbol{x}) / \tau)}{1 + \sum_{j=1}^{J-1} \exp(\boldsymbol{w}_j^\mathsf{T}\boldsymbol{\phi}(\boldsymbol{x}) / \tau)}, \quad j = 1, \dots, J\\] where \\(\boldsymbol{w}_J = 0\\). The hyperparameter \\(\tau \in \mathbb{R}_{+}\\) controls the smoothness of the decision boundaries. As \\(\tau \to 0\\), \\(\boldsymbol{\pi}(\boldsymbol{x})\\) approaches a one-hot vector which produces piecewise constant functions with sharp boundaries, and as \\(\tau \to \infty\\) the boundaries become more uniform. While we focus on the parametrization in  
efeqn:pi_defn for the experiments in this paper, we note that in principle any classification method can be used, such as another GP or a neural network.

The SSL kernel in  
efeqn:ssl_kernel naturally combines aspects of the linear and partition kernels via sums and products of kernels, which has an intuitive interpretation `\citep{duvenaud2014automatic}`{=latex}. The product kernel \\(\kappa_{\text{lin}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')\kappa_{\text{part}}^{(j)}(\boldsymbol{x}, \boldsymbol{x}')\\) enforces linearity in regions where \\(\pi_j(\boldsymbol{x})\\) is close to 1. Summing over \\(J\\) regimes then enforces linearity in each of the \\(J\\) regimes, leading to a prior on locally linear functions with knots determined by \\(\boldsymbol{\pi}(\boldsymbol{x})\\). We note that our kernel is reminiscent of the one in `\citet{pfingsten2006nonstationary}`{=latex}, which uses a GP classifier as a prior for \\(\boldsymbol{\pi}(\boldsymbol{x})\\) and applies their kernel to a GP regression setting. Here, our work differs in that we explicitly enforce linearity in each regime and draw a novel connection to switching models like the rSLDS.

<a href="#fig:kernel" data-reference-type="ref+Label" data-reference="fig:kernel">1</a>A depicts 1D samples from each kernel. <a href="#fig:kernel" data-reference-type="ref+Label" data-reference="fig:kernel">1</a>B shows how a SSL kernel with \\(J=2\\) linear regimes separated by decision boundary \\(x_1^2 + x_2^2 = 4\\) *(top)* produces a structured 2D flow field consisting of two linear systems, with \\(x_1\\)- and \\(x_2\\)- directions determined by 1D function samples *(bottom)*.

## The gpSLDS generative model

The full generative model for the gpSLDS incorporates the SSL kernel in  
efeqn:ssl_kernel into a GP-SDE modeling framework. Instead of placing a GP prior with a standard kernel on the system dynamics as in  
efeqn:gpsde_dynamics_prior, we simply plug in our new SSL kernel so that \\[f_k(\cdot) \overset{\text{iid}}{\sim} \mathcal{G}\mathcal{P}(0, \kappa_{\text{ssl}}^{\Theta}(\cdot, \cdot)), \quad \text{for } k=1, \cdots, K,\\] where the kernel hyperparameters are \\(\Theta = \{\boldsymbol{M}, \sigma_0^2, \{\boldsymbol{c}_j\}_{j=1}^J, \{\boldsymbol{w}_j\}_{j=1}^{J-1}, \tau\}\\). We then sample latent states and observations according to the GP-SDE via  
efeqn:sde. A schematic of the full generative model is depicted in  
effig:kernelC.

**Incorporating inputs** In many modern neuroscience applications, we are often interested in how external inputs to the system, such as experimental stimuli, influence latent states. To this end, we also consider an extension of the model in  
efeqn:sde which incorporates additive inputs of the form, \\[\label{eqn:inputs_model}
     d\boldsymbol{x}= (\boldsymbol{f}(\boldsymbol{x}) + \boldsymbol{B}\boldsymbol{v}(t)) dt + \boldsymbol{\Sigma}^{\frac{1}{2}} d\boldsymbol{w},\\] where \\(\boldsymbol{v}(t) \in \mathbb{R}^{I}\\) is a time-varying, known input signal and \\(\boldsymbol{B}\in \mathbb{R}^{K \times I}\\) maps inputs linearly to the latent space. The latent path inference and learning approaches presented in the following section can naturally be extended to this setting, with updates for \\(\boldsymbol{B}\\) available in closed form. Further details are provided in Appendix <a href="#app:sec:inference_of_latents" data-reference-type="ref" data-reference="app:sec:inference_of_latents">8.3</a>-<a href="#app:sec:updating_B" data-reference-type="ref" data-reference="app:sec:updating_B">8.6</a>.

## Latent path inference and parameter learning [sec:inference_and_learning]

For inference and learning in the gpSLDS, we apply and extend a variational expectation-maximization (vEM) algorithm for GP-SDEs from `\citet{duncker2019learning}`{=latex}. In particular, we propose a modification of this algorithm that dramatically improves the learning accuracy of kernel hyperparameters, which are crucial to the interpretability of the gpSLDS. We outline the main ideas of the algorithm here, though full details can be found in Appendix <a href="#app:sec:inference" data-reference-type="ref" data-reference="app:sec:inference">8</a>.

As in `\citet{duncker2019learning}`{=latex}, we consider a factorized variational approximation to the posterior, \\[\label{eqn:vem_factorization}
    q(\boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u}) = q(\boldsymbol{x}) \prod_{k=1}^K p(f_k ~\vert~\boldsymbol{u}_k, \Theta)q(\boldsymbol{u}_k),\\] where we have augmented the model with sparse inducing points to make inference of \\(\boldsymbol{f}\\) tractable `\citep{titsias2009variational}`{=latex}. The inducing points are located at \\(\{\boldsymbol{z}_m\}_{m=1}^M \subset \mathbb{R}^K\\) and take values \\((f_k(\boldsymbol{z}_1), \ldots, f_k(\boldsymbol{z}_M))^\top = \boldsymbol{u}_{k}\\). Standard vEM maximizes the evidence lower bound (ELBO) to the marginal log-likelihood \\(\log p(\boldsymbol{y}~\vert~\Theta)\\) by alternating between updating the variational posterior \\(q\\) and updating model hyperparameters \\(\Theta\\) `\citep{blei2017variational}`{=latex}. Using the factorization in  
efeqn:vem_factorization, we will denote the ELBO as \\(\mathcal{L}(q(\boldsymbol{x}), q(\boldsymbol{u}), \Theta)\\).

For inference of \\(q(\boldsymbol{x})\\), we follow the approach first proposed by `\citet{archambeau2007gaussian}`{=latex} and extended by `\citet{duncker2019learning}`{=latex}. Computing the ELBO using this approach requires computing variational expectations of the SSL kernel, which we approximate using Gauss-Hermite quadrature as they are not available in closed form. Full derivations of this step are provided in Appendix <a href="#app:sec:inference_of_latents" data-reference-type="ref" data-reference="app:sec:inference_of_latents">8.3</a>. For inference of \\(q(\boldsymbol{u})\\), we follow `\citet{duncker2019learning}`{=latex} and choose a Gaussian variational posterior for \\(q(\boldsymbol{u}_k) = \mathcal{N}(\boldsymbol{u}_k ~\vert~\boldsymbol{m}_u^{k*}, \boldsymbol{S}_u^{k*})\\), which admits closed-form updates for the mean \\(\boldsymbol{m}_u^{k \ast}\\) and covariance \\(\boldsymbol{S}_u^{k \ast}\\) given \\(q(\boldsymbol{x})\\) and \\(\Theta\\). `\citet{duncker2019learning}`{=latex} perform these updates before updating \\(\Theta\\) via gradient ascent on the ELBO in each vEM iteration.

In our setting, this did not work well in practice. The gpSLDS often exhibits strong dependencies between \\(q(\boldsymbol{u})\\) and \\(\Theta\\), which makes standard coordinate-ascent steps in vEM prone to getting stuck in local maxima. These dependencies arise due to the highly structured nature of our GP prior; small changes in the decision boundaries \\(\{\boldsymbol{w}_j\}_{j=1}^{J-1}\\) can lead to large (adverse) changes in the prior, which prevents vEM from escaping suboptimal regions of parameter space. To overcome these difficulties, we propose a different approach for learning \\(\Theta\\): instead of fixing \\(q(\boldsymbol{u})\\) and performing gradient ascent on the ELBO, we optimize \\(\Theta\\) by maximizing a partially optimized ELBO, \\[\label{eqn:modified_elbo}
    \Theta^\ast = \mathop{\mathrm{arg\,max}}_\Theta \left\{ \max_{q(\boldsymbol{u})} \mathcal{L}(q(\boldsymbol{x}), q(\boldsymbol{u}), \Theta) \right\}.\\] Due to the conjugacy of the model, the inner maximization can be performed analytically. This approach circumvents local optima that plague coordinate ascent on the standard ELBO. While other similar approaches exploit model conjugacy for faster vEM convergence in sparse variational GPs `\cite{titsias2009variational, adam2021dual}`{=latex} and GP-SDEs `\cite{verma2024variational}`{=latex}, our approach is the first to our knowledge that leverages this structure specifically for learning the latent dynamics of a GP-SDE model. We empirically demonstrate the superior performance of our learning algorithm in Appendix <a href="#app:sec:learning_objective" data-reference-type="ref" data-reference="app:sec:learning_objective">9</a>.

## Recovering predicted dynamics [sec:recovering_f]

It is straightforward to obtain the approximate posterior distribution over \\(\boldsymbol{f}^\ast := \boldsymbol{f}(\boldsymbol{x}^\ast)\\) evaluated at any new location \\(\boldsymbol{x}^\ast\\). Under the assumption that \\(\boldsymbol{f}^\ast\\) only depends on the inducing points, we can use the approximation \\({q(\boldsymbol{f}^\ast) = \prod_{k=1}^K \int p(f_k^\ast ~\vert~\boldsymbol{u}_k, \Theta) q(\boldsymbol{u}_k) \mathop{}\!\mathrm{d}\boldsymbol{u}_k}\\) which can be computed in closed-form using properties of conditional Gaussian distributions. For a batch of points \\(\{\boldsymbol{x}_i^\ast\}_{i=1}^N\\), this can be computed in \\(O(NM^2)\\) time. The full derivation can be found in Appendix <a href="#app:sec:modified_objective" data-reference-type="ref" data-reference="app:sec:modified_objective">8.4</a>.

This property highlights an appealing feature of the gpSLDS over the rSLDS. The gpSLDS infers a posterior distribution over dynamics at every point in latent space, even in regions of high uncertainty. Meanwhile, as we shall see later, the rSLDS expresses uncertainty by randomly oscillating between different sets of most-likely linear dynamics, which is much harder to interpret.

# Results [sec:results]

## Synthetic data [sec:synthetic_results]

<figure id="fig:figure8_results">
<div class="center">
<img src="./figures/figure8_plot_v4.png"" />
</div>
<figcaption>Synthetic data results. <strong>A.</strong> True dynamics and latent states used to generate the dataset. Dynamics are clockwise and counterclockwise linear systems separated by <span class="math inline"><em>x</em><sub>1</sub> = 0</span>. Two latent trajectories are shown on top of a kernel density estimate of the latent states visited by all 30 trials. <strong>B.</strong> Poisson process observations from an example trial. <strong>C.</strong> True vs. inferred latent states for the gpSLDS and rSLDS, with 95% posterior credible intervals. <strong>D.</strong> Inferred dynamics (pink/green) and two inferred latent trajectories (gray) corresponding to those in Panel A from a gpSLDS fit with 2 linear regimes. The model finds high-probability fixed points (purple) overlapping with true fixed points (stars). <strong>E.</strong> Analogous plot to D for the GP-SDE model with RBF kernel. Note that this model does not provide a partition of the dynamics. <strong>F.</strong> rSLDS inferred latents, dynamics, and fixed points (pink/green dots). <strong>G.</strong> <em>(top)</em> Sampled latents and corresponding dynamics from the gpSLDS, with <span class="math inline">95%</span> posterior credible intervals. <em>(bottom)</em> Same, but for the rSLDS. The pink/green trace represents the most likely dynamics at the sampled latents, colored by discrete switching variable. <em>H.</em> MSE between true and inferred latents and dynamics for gpSLDS, GP-SDE with RBF kernel, and rSLDS while varying the number of trials in the dataset. Error bars are <span class="math inline">±</span>2SE over 5 random initializations.</figcaption>
</figure>

We begin by applying the gpSLDS to a synthetic dataset consisting of two linear rotational systems, one clockwise and one-counterclockwise, which combine smoothly at \\(x_1 = 0\\) (  
effig:figure8_resultsA). We simulate 30 trials of latent states from an SDE as in  
efeqn:sde and then generate Poisson process observations given these latent states for \\(D = 50\\) output dimensions (i.e. neurons) over \\(T = 2.5\\) seconds (Fig. <a href="#fig:figure8_results" data-reference-type="ref" data-reference="fig:figure8_results">2</a>B). To initialize \\(\boldsymbol{C}\\) and \\(\boldsymbol{d}\\), we fit a Poisson LDS `\cite{smith2003estimating}`{=latex} to data binned at 20ms with identity dynamics. For the rSLDS, we also bin the data at 20ms. We then fit the gpSLDS and rSLDS models with \\(J=2\\) linear states using 5 different random initializations for 100 vEM iterations, and choose the fits with the highest ELBOs in each model class.

We find that the gpSLDS accurately recovers the true latent trajectories (  
effig:figure8_resultsC) as well as the true rotation dynamics and the decision boundary between them (  
effig:figure8_resultsD). We determine this decision boundary by thresholding the learned \\(\boldsymbol{\pi}(\boldsymbol{x})\\) at \\(0.5\\). In addition, we can obtain estimates of fixed point locations by computing the posterior probability \\(\prod_{k=1}^K \mathbb{P}_{q(\boldsymbol{f})}(|f_k(\boldsymbol{x})| < \epsilon)\\) for a small \\(\epsilon > 0\\); the locations \\(\boldsymbol{x}\\) with high probability are shaded in purple. This reveals that the gpSLDS finds high-probability fixed points which overlap significantly with the true fixed points, denoted by stars. In comparison, both the rSLDS and the GP-SDE with RBF kernel do not learn the correct decision boundary nor the fixed points as accurately (  
effig:figure8_resultsE-F). Of particular note, the RBF kernel incorrectly extrapolates and finds a superfluous fixed point outside the region traversed by the true latent states.

<a href="#fig:figure8_results" data-reference-type="ref+Label" data-reference="fig:figure8_results">2</a>G illustrates the differences in how the gpSLDS and the rSLDS express uncertainty over dynamics. To the left of the dashed line, we sample latent states starting from \\(x_0 = (7, 0)\\) and plot the corresponding true dynamics. To the right, we simulate latent states \\(\boldsymbol{x}_{\mathsf{samp}}\\) from the fitted model and plot the true dynamics (in gray) and the learned most likely dynamics (in color) at \\(\boldsymbol{x}_{\mathsf{samp}}\\). For a well-fitting model, we would expect the true and learned dynamics to overlap. We see that the gpSLDS produces smooth simulated dynamics that match the true dynamics at \\(\boldsymbol{x}_{\mathsf{samp}}\\) *(top)*. By contrast, the rSLDS expresses uncertainty by oscillating between the two linear dynamical systems, hence producing uninterpretable dynamics at \\(\boldsymbol{x}_{\mathsf{samp}}\\) *(bottom)*. This region of uncertainty overlaps with the \\(x_1 = 0\\) boundary, suggesting that the rSLDS fails to capture the smoothly interpolating dynamics present in the true system.

Next, we perform quantitative comparisons between the three competing methods (  
effig:figure8_resultsH). We find that both continuous-time methods consistently outperform the rSLDS on both metrics, suggesting that these methods are likely more suitable for modeling Poisson process data. Moreover, the gpSLDS better recovers dynamics compared to the RBF kernel, illustrating that the correct inductive bias can yield performance gains over a more flexible prior, especially in a data-limited setting.

Lastly, we note that the gpSLDS can achieve more expressive power than the rSLDS by learning *nonlinear* decision boundaries between linear regimes, for instance by incorporating nonlinear features into \\(\boldsymbol{\phi}(\boldsymbol{x})\\) in  
efeqn:pi_defn. We demonstrate this feature for a 2D limit cycle in Appendix <a href="#app:sec:synthetic_results" data-reference-type="ref" data-reference="app:sec:synthetic_results">10</a>.

## Application to hypothalamic neural population recordings during aggression [sec:nair_results]

In this section, we revisit the analyses of `\citet{nair2023approximate}`{=latex}, which applied dynamical systems models to neural recordings during aggressive behavior in mice. To do this, we reanalyze a dataset which consists of calcium imaging of ventromedial hypothalamus neurons from a mouse interacting with two consecutive intruders. The recording was collected from 104 neurons at 15 Hz over \\(\sim\\)`<!-- -->`{=html}343 seconds (i.e. 5140 time bins). `\citet{nair2023approximate}`{=latex} found that an rSLDS fit to this data learns dynamics that form an approximate line attractor corresponding to an aggressive internal state (  
effig:nair_resultsA). Here, we supplement this analysis by using the gpSLDS to directly assess model confidence about this finding.

For our experiments, we \\(z\\)-score and then split the data into two trials, one for each distinct intruder interacting with the mouse. Following `\citet{nair2023approximate}`{=latex}, we choose \\(J = 4\\) linear regimes to compare the gpSLDS and rSLDS. We choose \\(K = 2\\) latent dimensions to aid the visualization of the resulting model fits; we find that even in such low dimensions, both models still recover line attractor-like dynamics. We model the calcium imaging traces as Gaussian emissions on an evenly spaced time grid and initialize \\(\boldsymbol{C}\\) and \\(\boldsymbol{d}\\) using principal component analysis. We fit models with 5 different initializations for 50 vEM iterations and display the runs with highest forward simulation accuracy (as described in the caption of  
effig:nair_results).

In  
effig:nair_resultsA-B, we find that both methods infer similar latent trajectories and find plausible flow fields that are parsed in terms of simpler linear components. We further demonstrate the ability of the gpSLDS to more precisely identify the line attractor from `\citet{nair2023approximate}`{=latex}. To do this, we use the learned \\(q(\boldsymbol{f})\\) to compute the posterior probability of slow dynamics on a dense (\\(80 \times 80\\)) grid of points in the latent space using the procedure in <a href="#sec:recovering_f" data-reference-type="ref+Label" data-reference="sec:recovering_f">3.4</a>. The gpSLDS finds a high-probability region of slow points corresponding to the approximate line attractor found in `\citet{nair2023approximate}`{=latex} (  
effig:nair_resultsC). This demonstrates a key advantage of the gpSLDS over the rSLDS: by modeling dynamics probabilistically using a structured GP prior, we can validate the finding of a line attractor with further statistical rigor. Finally, we compare the gpSLDS, rSLDS, and GP-SDE with RBF kernel using an in-sample forward simulation metric (  
effig:nair_resultsD). All three methods retain similar predictive power 500 steps into the future. After that, the gpSLDS performs slightly worse than the RBF kernel; however, it gains interpretability by imposing piecewise linear structure while still outperforming the rSLDS.

<figure id="fig:nair_results">
<div class="center">
<img src="./figures/nair_figure_v4.png"" />
</div>
<figcaption>Results on hypothalamic data from <span class="citation" data-cites="nair2023approximate"></span>. In each of the panels A-C, flow field arrow widths are scaled by the magnitude of dynamics for clarity of visualization. <strong>A.</strong> rSLDS inferred latents and most likely dynamics. The presumed location of the line attractor from <span class="citation" data-cites="nair2023approximate"></span> is marked with a red box. <strong>B.</strong> gpSLDS inferred latents and most likely dynamics in latent space. Background is colored by posterior standard deviation of dynamics averaged across latent dimensions, which adjusts relative to the presence of data in the latent space. <strong>C.</strong> Posterior probability of slow points in gpSLDS, which validates line-attractor like dynamics, as marked by a red box. <strong>D.</strong> Comparison of in-sample forward simulation <span class="math inline"><em>R</em><sup>2</sup></span> between gpSLDS, rSLDS, and GP-SDE with RBF kernel. To compute this, we choose initial conditions uniformly spaced 100 time bins apart in both trials, simulate latent states <span class="math inline"><em>k</em></span> steps forward according to learned dynamics (with <span class="math inline"><em>k</em></span> ranging from 100-1500), and evaluate the <span class="math inline"><em>R</em><sup>2</sup></span> between predicted and true observations as in <span class="citation" data-cites="nassar2018tree"></span>. Error bars are <span class="math inline">±</span>2SE over 5 different initializations.</figcaption>
</figure>

## Application to lateral intraparietal neural recodings during decision making [sec:stine_results]

<figure id="fig:stine_results">
<div class="center">
<img src="./figures/stine_figure.png"" style="width:90.0%" />
</div>
<figcaption>Results on LIP spiking data from a decision-making task in <span class="citation" data-cites="stine2023neural"></span>. <strong>A.</strong> gpSLDS inferred latents colored by coherence, inferred dynamics with background colored by most likely linear regime, and the learned input-driven direction depicted by an orange arrow. <strong>B.</strong> Projection of latents onto the 1D input-driven axis from Panel A, colored by coherence <em>(top)</em> and choice <em>(bottom)</em>. <strong>C.</strong> Inferred latents with 95% credible intervals and corresponding 100ms pulse input for an example trial. <strong>D.</strong> Posterior variance of dynamics produced by the gpSLDS.</figcaption>
</figure>

In neuroscience, there is considerable interest in understanding how neural dynamics during decision making tasks support the process of making a choice `\citep{zoltowski2020general,luo2023transitions,stine2023neural,roitman2002response, ditterich2006stochastic,gold2007neural,latimer2015single,genkin2023dynamics}`{=latex}. In this section, we use the gpSLDS to infer latent dynamics from spiking activity in the lateral intraparietal (LIP) area of monkeys reporting decisions about the direction of motion of a random moving dots stimulus with varying degrees of motion coherence `\citep{stine2023neural,roitman2002response}`{=latex}. The animal indicated its choice of net motion direction (either left or right) via a saccade. On some trials, a 100ms pulse of weak motion, randomly oriented to the left or right, was also presented to the animal. Here, we model the dynamics of 58 neurons recorded across 50 trials consisting of net motion coherence strengths in \\(\{-.512, -.128, 0.0, .128, .512\}\\), where the sign corresponds to the net movement direction of the stimulus. We only consider data 200ms after motion onset, corresponding to the start of decision-related activity.

To capture potential input-driven effects, we fit a version of the gpSLDS described in  
efeqn:inputs_model with \\(K=2\\) latent dimensions and \\(J=2\\) linear regimes over 50 vEM iterations. We encoded the input signal as \\(\pm 1\\) with sign corresponding to pulse direction. In <a href="#fig:stine_results" data-reference-type="ref+Label" data-reference="fig:stine_results">4</a>A, we find that not only does the gpSLDS capture a distinct visual separation between trials by motion coherence, but it also learns a precise separating decision boundary between the two linear regimes. Our finding is consistent with previous work on a related task, which found that average LIP responses can be represented by a 2D curved manifold `\citep{okazawa2021representational}`{=latex}, though here we take a dynamical systems perspective. Additionally, our model learns an input-driven effect which appears to define a separating axis. To verify this, we project the inferred latent states onto the 1D subspace spanned by the input effect vector. <a href="#fig:stine_results" data-reference-type="ref+Label" data-reference="fig:stine_results">4</a>B shows that the latent states separate by coherence *(top)* and by choice *(bottom)*, further suggesting that the pulse input relates to meaningful variation in evidence accumulation for this task. Fig. <a href="#fig:stine_results" data-reference-type="ref" data-reference="fig:stine_results">4</a>C shows an example latent trajectory aligned with pulse input; during the pulse there is a noticeable change in the latent trajectory. Lastly, in Fig. <a href="#fig:stine_results" data-reference-type="ref" data-reference="fig:stine_results">4</a>D we find that the gpSLDS expresses high confidence in learned dynamics where latent trajectories are present and low confidence in areas further from this region.

# Related work [sec:related_work]

There are several related approaches to learning nonlinear latent dynamics in discrete or continuous time. Gaussian process state-space models (GP-SSMs) `\cite{wang2005gaussian, turner2010state, frigola2014variational, eleftheriadis2017identification, bohner2018empirical}`{=latex} can be considered a discrete-time analogue to GP-SDEs. In a GP-SSM, observations are assumed to be regularly sampled and latent states evolve according to a discretized dynamical system with a GP prior. `\citet{wang2005gaussian}`{=latex} and `\citet{turner2010state}`{=latex} learned the dynamics of a GP-SSM using maximum a posteriori estimation. `\citet{frigola2014variational}`{=latex} and `\citet{eleftheriadis2017identification}`{=latex} employed a variational approximation with sparse inducing points to infer the latent states and dynamics in a fully Bayesian fashion. In our work, we use a continuous-time framework that more naturally handles irregularly sampled data, such as point-process observations commonly encountered in neural spiking data. Neural ODEs and SDEs `\citep{chen2018neural,rubanova2019latent}`{=latex} use deep neural networks to parametrize the dynamics of a continuous-time system, and have emerged as prominent tools for analyzing large datasets, including those in neuroscience `\citep{kim2023flow,kim2021inferring,kim2023trainability,versteeg2023expressive}`{=latex}. While these methods can represent flexible function classes, they are likely to overfit to low-data regimes and may be difficult to interpret. In addition, unlike the gpSLDS, neural ODEs and SDEs do not typically quantify uncertainty of the learned dynamics.

In the context of dynamical mixture models, `\citet{kohs2021variational, kohs2022markov}`{=latex} proposed a continuous-time switching model in a GP-SDE framework. This model assumes a latent Markov jump process over time which controls the system dynamics by switching between different SDEs. The switching process models dependence on time, but not location in latent space. In contrast, the gpSLDS does not explicitly represent a latent switching process and rather models switching probabilities as part of the kernel function. The dependence of the kernel on the location in latent space allows for the gpSLDS to partition the latent space into different linear regimes.

While our work has followed the inference approach of `\citet{archambeau2007variational}`{=latex} and `\citet{duncker2019learning}`{=latex}, other methods for latent path inference in nonlinear SDEs have been proposed `\citep{course2023state,verma2024variational,course2024amortized,cseke2016expectation}`{=latex}. `\citet{verma2024variational}`{=latex} parameterized the posterior SDE path using an exponential family-based description. The resulting inference algorithm showed improved convergence of the E-step compared to `\citet{archambeau2007gaussian}`{=latex}. `\citet{course2023state,course2024amortized}`{=latex} proposed an amortization strategy that allows the variational update of the latent state to be parallelized over sequence length. In principle, any of these approaches could be applied to inference in the gpSLDS and would be an interesting direction for future work.

# Discussion [sec:discussion]

We have presented the Gaussian Process Switching Linear Dynamical System—a principled, fully probabilistic approach for uncovering the dynamical structure that underlies population neural activity. By marrying a Gaussian-process prior with an explicitly constructed smoothly switching linear kernel, the gpSLDS inherits three compelling properties: (1) the capacity to model richly nonlinear phenomena, (2) the transparency of linear dynamical components that neuroscientists can directly interrogate, and (3) calibrated posterior uncertainty over both latent trajectories and vector fields.  

Our experiments highlight several practical advantages. On synthetic data the gpSLDS precisely recovered decision boundaries, fixed-point structure, and moment-to-moment latent trajectories, even when only limited observations were available. On hypothalamic calcium-imaging data during aggressive behavior, the model confirmed and quantified a line-attractor hypothesis, offering probabilistic evidence that complements previous qualitative reports. Finally, on primate LIP spiking data during perceptual decision making, the gpSLDS discovered a compact two-dimensional manifold that organizes trials by coherence and choice, and revealed an input-aligned axis that cleanly separates stimulus contingencies—providing a dynamical-systems perspective that aligns with and extends prior findings based on representational geometry.

Beyond neuroscience, the methodological innovations introduced here—most notably the smoothly switching linear kernel and the partially optimized variational objective—open the door to interpretable, uncertainty-aware modeling in any domain where complex dynamics must be distilled into low-dimensional structure. Because the gpSLDS naturally accommodates continuous-time observations, irregular sampling schedules, and user-specified external inputs, it is well suited to modern experimental designs in which multimodal measurements and flexible task protocols are the norm.

Future work will explore automated kernel discovery, tighter amortized inference schemes, and hierarchical extensions that couple multiple gpSLDS modules. These directions promise even more flexible yet interpretable models, further broadening the reach of dynamical-systems analysis in large-scale data settings.
# References [references]

<div class="thebibliography" markdown="1">

Peiran Gao and Surya Ganguli On simplicity and complexity in the brave new world of large-scale neuroscience *Current Opinion in Neurobiology*, 32: 148–155, 2015. **Abstract:** Technological advances have dramatically expanded our ability to probe multi-neuronal dynamics and connectivity in the brain. However, our ability to extract a simple conceptual understanding from complex data is increasingly hampered by the lack of theoretically principled data analytic procedures, as well as the- oretical frameworks for how circuit connectivity and dynamics can conspire to generate emergent behavioral and cognitive functions. We review and outline potential avenues for progress, including new theories of high dimensional data analysis, the need to analyze complex arti cial networks, and methods for analyzing entire spaces of circuit models, rather than one model at a time. Such interplay between experiments, data analysis and theory will be indispensable in catalyzing conceptual advances in the age of large-scale neuroscience. \\}Things should be as simple as possible, but not simpler. " -Albert Einstein. (@gao2015simplicity)

John P Cunningham and Byron M Yu Dimensionality reduction for large-scale neural recordings *Nature Neuroscience*, 17 (11): 1500–1509, 2014. **Abstract:** Most sensory, cognitive and motor functions depend on the interactions of many neurons. In recent years, there has been rapid development and increasing use of technologies for recording from large numbers of neurons, either sequentially or simultaneously. A key question is what scientific insight can be gained by studying a population of recorded neurons beyond studying each neuron individually. Here, we examine three important motivations for population studies: single-trial hypotheses requiring statistical power, hypotheses of population response structure and exploratory analyses of large data sets. Many recent studies have adopted dimensionality reduction to analyze these populations and to find features that are not apparent at the level of individual neurons. We describe the dimensionality reduction methods commonly applied to population activity and offer practical advice about selecting methods and interpreting their outputs. This review is intended for experimental and computational researchers who seek to understand the role dimensionality reduction has had and can have in systems neuroscience, and who seek to apply these methods to their own data. A central tenet of neuroscience is that the remarkable computational abilities of our brains arise as a result of populations of interconnected neurons. Indeed, we find ourselves at an exciting moment in the history of neuroscience, as the field is experiencing rapid growth in the quantity and complexity of the recorded neural activity. Many groups have begun to adopt multi-electrode1 and optical2 recording technologies that can monitor the activity of many neurons simultaneously in cortex and, in some cases, in deeper structures. Ongoing development of recording technologies promises to increase the number of simultaneously recorded neurons by orders of magnitude3. At the same time, massive increases in © 2014 Nature America, Inc. All rights reserved Reprints and permissions information is available online at http://www.nature.com/reprints/index.html . Correspondence should be addressed to J.P.C. (jpc2181@columbia.edu) or B.M.Y. (byronyu@cmu.edu). COMPETING FINANCIAL INTERESTS The authors declare no competing financial interests. HHS Public Access Author manuscript Nat Neurosci . Author manuscript; available in PMC 2015 November 01. Published in final edited form as: Nat Neurosci . 2014 November ; 17(11): 1500–1509. doi:10.1038/nn.3776. Author Manuscript Author Manuscript Author (@cunningham2014dimensionality)

Shreya Saxena and John P Cunningham Towards the neural population doctrine *Current Opinion in Neurobiology*, 55: 103–111, 2019. **Abstract:** Neuroscience research has made immense progress over the last decade, but our understanding of the brain remains fragmented and piecemeal: the dream of probing an arbitrary brain region and automatically reading out the information encoded in its neural activity remains out of reach. In this work, we build towards a first foundation model for neural spiking data that can solve a diverse set of tasks across multiple brain areas. We introduce a novel self-supervised modeling approach for population activity in which the model alternates between masking out and reconstructing neural activity across different time steps, neurons, and brain regions. To evaluate our approach, we design unsupervised and supervised prediction tasks using the International Brain Laboratory repeated site dataset, which is comprised of Neuropixels recordings targeting the same brain locations across 48 animals and experimental sessions. The prediction tasks include single-neuron and region-level activity prediction, forward prediction, and behavior decoding. We demonstrate that our multi-task-masking (MtM) approach significantly improves the performance of current state-of-the-art population models and enables multi-task learning. We also show that by training on multiple animals, we can improve the generalization ability of the model to unseen animals, paving the way for a foundation model of the brain at single-cell, single-spike resolution. Project page and code: https://ibl-mtm.github.io/ (@saxena2019towards)

Anne C Smith and Emery N Brown Estimating a state-space model from point process observations *Neural Computation*, 15 (5): 965–991, 2003. **Abstract:** A widely used signal processing paradigm is the state-space model. The state-space model is defined by two equations: an observation equation that describes how the hidden state or latent process is observed and a state equation that defines the evolution of the process through time. Inspired by neurophysiology experiments in which neural spiking activity is induced by an implicit (latent) stimulus, we develop an algorithm to estimate a state-space model observed through point process measurements. We represent the latent process modulating the neural spiking activity as a gaussian autoregressive model driven by an external stimulus. Given the latent process, neural spiking activity is characterized as a general point process defined by its conditional intensity function. We develop an approximate expectation-maximization (EM) algorithm to estimate the unobservable state-space process, its parameters, and the parameters of the point process. The EM algorithm combines a point process recursive nonlinear filter algorithm, the fixed interval smoothing algorithm, and the state-space covariance algorithm to compute the complete data log likelihood efficiently. We use a Kolmogorov-Smirnov test based on the time-rescaling theorem to evaluate agreement between the model and point process data. We illustrate the model with two simulated data examples: an ensemble of Poisson neurons driven by a common stimulus and a single neuron whose conditional intensity function is approximated as a local Bernoulli process. (@smith2003estimating)

Liam Paninski, Yashar Ahmadian, Daniel Gil Ferreira, Shinsuke Koyama, Kamiar Rahnama Rad, Michael Vidne, Joshua Vogelstein, and Wei Wu A new look at state-space models for neural data *Journal of Computational Neuroscience*, 29: 107–126, 2010. **Abstract:** State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates. 1 Introduction; forward-backward methods for inference in state-space models A wide variety of neuroscientific data analysis problems may be attacked fruitfully within the framework of hidden Markov (“state-space”) models. The basic idea is that the underlying system may be described as a stochastic dynamical process: a (possibly multidimensional) state variable qt evolves through time according to some Markovian dynamics p(qt\|qt−1, θ), as specified by a few model parameters θ. Now in many situations we do not observe the state variable qt directly (this Markovian variable is “hidden”); instead, our observations yt are a noisy, subsampled version of qt, summarized by an observation distribution p(yt\|qt). Methods for performing optimal inference and estimation in these hidden Markov models are very well-developed in the statistics and engineering literature \[80, 24, 23\]. For example, to compute the conditional distribution p(qt\|Y1:T) of the state variable qt given all the observed data on the time interval (0, T\], we need only apply two straightforward recursions: a forward recursion that computes the conditional distribution of qt given only the observed data up to time t, (1) and then a backward recursion that computes the desired distribution p(qt\|Y1:T), NIH Public Access Author Manuscript J Comput Neurosci . Author manuscript; availab (@paninski2010new)

Jakob H Macke, Lars Buesing, John P Cunningham, Byron M Yu, Krishna V Shenoy, and Maneesh Sahani Empirical models of spiking in neural populations *Advances in Neural Information Processing Systems*, 24, 2011. **Abstract:** Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within a local network? We argue that in the cortex, where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by comparing a latent dynamical model with realistic spiking observations to coupled generalised linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms the GLM in terms of goodness-of-fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly better goodness-of-fit and more realistic population spike counts. (@macke2011empirical)

Evan Archer, Il Memming Park, Lars Buesing, John Cunningham, and Liam Paninski Black box variational inference for state space models *arXiv preprint arXiv:1511.07367*, 2015. **Abstract:** Latent variable time-series models are among the most heavily used tools from machine learning and applied statistics. These models have the advantage of learning latent structure both from noisy observations and from the temporal ordering in the data, where it is assumed that meaningful correlation structure exists across time. A few highly-structured models, such as the linear dynamical system with linear-Gaussian observations, have closed-form inference procedures (e.g. the Kalman Filter), but this case is an exception to the general rule that exact posterior inference in more complex generative models is intractable. Consequently, much work in time-series modeling focuses on approximate inference procedures for one particular class of models. Here, we extend recent developments in stochastic variational inference to develop a ‘black-box’ approximate inference technique for latent variable models with latent dynamical structure. We propose a structured Gaussian variational approximate posterior that carries the same intuition as the standard Kalman filter-smoother but, importantly, permits us to use the same inference approach to approximate the posterior of much more general, nonlinear latent variable generative models. We show that our approach recovers accurate estimates in the case of basic models with closed-form posteriors, and more interestingly performs well in comparison to variational approaches that were designed in a bespoke fashion for specific non-conjugate models. (@archer2015black)

Scott Linderman, Matthew Johnson, Andrew Miller, Ryan Adams, David Blei, and Liam Paninski Bayesian learning and inference in recurrent switching linear dynamical systems In *Artificial Intelligence and Statistics*, pages 914–922. PMLR, 2017. **Abstract:** In this paper, we propose a novel model called Recurrent Explicit Duration Switching Linear Dynamical Systems (REDSLDS) that incorporates recurrent explicit duration variables into the rSLDS model. We also propose an inference and learning scheme that involves the use of P\\}’olya-gamma augmentation. We demonstrate the improved segmentation capabilities of our model on three benchmark datasets, including two quantitative datasets and one qualitative dataset. (@linderman2017bayesian)

Chethan Pandarinath, Daniel J O’Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D Stavisky, Jonathan C Kao, Eric M Trautmann, Matthew T Kaufman, Stephen I Ryu, Leigh R Hochberg, et al Inferring single-trial neural population dynamics using sequential auto-encoders *Nature Methods*, 15 (10): 805–815, 2018. **Abstract:** Neuroscience is experiencing a revolution in which simultaneous recording of many thousands of neurons is revealing population dynamics that are not apparent from single-neuron responses. This structure is typically extracted from trial-averaged data, but deeper understanding requires studying single-trial phenomena, which is challenging due to incomplete sampling of the neural population, trial-to-trial variability, and fluctuations in action potential timing. We introduce Latent Factor Analysis via Dynamical Systems (LFADS), a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system to infer the dynamics underlying observed spiking activity and to extract ‘de-noised’ single-trial firing rates. When applied to a variety of monkey and human motor cortical datasets, LFADS predicts observed behavioral variables with unprecedented accuracy, extracts precise estimates of neural dynamics on single trials, infers perturbations to those dynamics that correlate with behavioral choices, and combines data from non-overlapping recording sessions spanning months to improve inference of underlying dynamics. (@pandarinath2018inferring)

Lea Duncker, Gergo Bohner, Julien Boussard, and Maneesh Sahani Learning interpretable continuous-time models of latent stochastic dynamical systems In *International Conference on Machine Learning*, pages 1726–1734. PMLR, 2019. **Abstract:** We develop an approach to learn an interpretable semi-parametric model of a latent continuous-time stochastic dynamical system, assuming noisy high-dimensional outputs sampled at uneven times. The dynamics are described by a nonlinear stochastic differential equation (SDE) driven by a Wiener process, with a drift evolution function drawn from a Gaussian process (GP) conditioned on a set of learnt fixed points and corresponding local Jacobian matrices. This form yields a flexible nonparametric model of the dynamics, with a representation corresponding directly to the interpretable portraits routinely employed in the study of nonlinear dynamical systems. The learning algorithm combines inference of continuous latent paths underlying observed data with a sparse variational description of the dynamical process. We demonstrate our approach on simulated data from different nonlinear dynamical systems. (@duncker2019learning)

Marine Schimel, Ta-Chu Kao, Kristopher T Jensen, and Guillaume Hennequin ilqr-vae: control-based learning of input-driven dynamics with applications to neural data In *International Conference on Learning Representations*, 2021. **Abstract:** A bstract Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, the recognition model is naturally tied to the generative model, greatly reducing the number of free parameters and ensuring high-quality inference throughout the course of learning. Moreover, iLQR can be used to perform inference flexibly on heterogeneous trials of varying lengths. This allows for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data. (@schimel2021ilqr)

Mikhail Genkin, Owen Hughes, and Tatiana A Engel Learning non-stationary langevin dynamics from stochastic observations of latent trajectories *Nature Communications*, 12 (1): 5986, 2021. **Abstract:** Many complex systems operating far from the equilibrium exhibit stochastic dynamics that can be described by a Langevin equation. Inferring Langevin equations from data can reveal how transient dynamics of such systems give rise to their function. However, dynamics are often inaccessible directly and can be only gleaned through a stochastic observation process, which makes the inference challenging. Here we present a non-parametric framework for inferring the Langevin equation, which explicitly models the stochastic observation process and non-stationary latent dynamics. The framework accounts for the non-equilibrium initial and final states of the observed system and for the possibility that the system’s dynamics define the duration of observations. Omitting any of these non-stationary components results in incorrect inference, in which erroneous features arise in the dynamics due to non-stationary data distribution. We illustrate the framework using models of neural dynamics underlying decision making in the brain. (@genkin2021learning)

Christopher Langdon and Tatiana A Engel Latent circuit inference from heterogeneous neural responses during cognitive tasks *bioRxiv*, pages 2022–01, 2022. **Abstract:** ABSTRACT Higher cortical areas carry a wide range of sensory, cognitive, and motor signals supporting complex goal-directed behavior. These signals are mixed in heterogeneous responses of single neurons tuned to multiple task variables. Dimensionality reduction methods used to analyze neural responses rely merely on correlations, leaving unknown how heterogeneous neural activity arises from connectivity to drive behavior. Here we present a framework for inferring a low-dimensional connectivity structure—the latent circuit—from high-dimensional neural response data. The latent circuit captures mechanistic interactions between task variables and their mixed representations in single neurons. We apply the latent circuit inference to recurrent neural networks trained to perform a context-dependent decision-making task and find a suppression mechanism in which contextual representations inhibit irrelevant sensory responses. We validate this mechanism by confirming the behavioral effects of patterned connectivity perturbations predicted by the latent circuit structure. Our approach can reveal interpretable and causally testable circuit mechanisms from heterogeneous neural responses during cognitive tasks. (@langdon2022latent)

Matthew Dowling, Yuan Zhao, and Il Memming Park Large-scale variational gaussian state-space models *arXiv preprint arXiv:2403.01371*, 2024. **Abstract:** State-space graphical models and the variational autoencoder framework provide a principled apparatus for learning dynamical systems from data. State-of-the-art probabilistic approaches are often able to scale to large problems at the cost of flexibility of the variational posterior or expressivity of the dynamics model. However, those consolidations can be detrimental if the ultimate goal is to learn a generative model capable of explaining the spatiotemporal structure of the data and making accurate forecasts. We introduce a low-rank structured variational autoencoding framework for nonlinear Gaussian state-space graphical models capable of capturing dense covariance structures that are important for learning dynamical systems with predictive capabilities. Our inference algorithm exploits the covariance structures that arise naturally from sample based approximate Gaussian message passing and low-rank amortized posterior updates – effectively performing approximate variational smoothing with time complexity scaling linearly in the state dimensionality. In comparisons with other deep state-space model architectures our approach consistently demonstrates the ability to learn a more predictive generative model. Furthermore, when applied to neural physiological recordings, our approach is able to learn a dynamical system capable of forecasting population spiking and behavioral correlates from a small portion of single trials. (@dowling2024large)

Saurabh Vyas, Matthew D Golub, David Sussillo, and Krishna V Shenoy Computation through neural population dynamics *Annual Review of Neuroscience*, 43: 249–275, 2020. **Abstract:** Significant experimental, computational, and theoretical work has identified rich structure within the coordinated activity of interconnected neural populations. An emerging challenge now is to uncover the nature of the associated computations, how they are implemented, and what role they play in driving behavior. We term this computation through neural population dynamics. If successful, this framework will reveal general motifs of neural population activity and quantitatively describe how neural population dynamics implement computations necessary for driving goal-directed behavior. Here, we start with a mathematical primer on dynamical systems theory and analytical tools necessary to apply this perspective to experimental data. Next, we highlight some recent discoveries resulting from successful application of dynamical systems. We focus on studies spanning motor control, timing, decision-making, and working memory. Finally, we briefly discuss promising recent lines of investigation and future directions for the computation through neural population dynamics framework. (@vyas2020computation)

Lea Duncker and Maneesh Sahani Dynamics on the manifold: Identifying computational dynamical activity from neural population recordings *Current Opinion in Neurobiology*, 70: 163–170, 2021. **Abstract:** The question of how the collective activity of neural populations gives rise to complex behaviour is fundamental to neuroscience. At the core of this question lie considerations about how neural circuits can perform computations that enable sensory perception, decision making, and motor control. It is thought that such computations are implemented by the dynamical evolution of distributed activity in recurrent circuits. Thus, identifying dynamical structure in neural population activity is a key challenge towards a better understanding of neural computation. At the same time, interpreting this structure in light of a computation of interest is essential for linking the time-varying activity patterns of the neural population to ongoing computational processes. Here, we review methods that aim to quantify structure in neural population recordings through a dynamical system deﬁned in a low-dimensional latent variable space. We discuss advantages and limitations of diﬀerent modelling approaches and address future challenges for the ﬁeld. (@duncker2021dynamics)

David Sussillo and Omri Barak Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks *Neural Computation*, 25 (3): 626–649, 2013. **Abstract:** Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships between time-varying inputs and outputs with complex temporal dependencies. Recently developed algorithms have been successful at training RNNs to perform a wide variety of tasks, but the resulting networks have been treated as black boxes: their mechanism of operation remains unknown. Here we explore the hypothesis that fixed points, both stable and unstable, and the linearized dynamics around them, can reveal crucial aspects of how RNNs implement their computations. Further, we explore the utility of linearization in areas of phase space that are not true fixed points but merely points of very slow movement. We present a simple optimization technique that is applied to trained RNNs to find the fixed and slow points of their dynamics. Linearization around these slow regions can be used to explore, or reverse-engineer, the behavior of the RNN. We describe the technique, illustrate it using simple examples, and finally showcase it on three high-dimensional RNN examples: a 3-bit flip-flop device, an input-dependent sine wave generator, and a two-point moving average. In all cases, the mechanisms of trained networks could be inferred from the sets of fixed and slow points and the linearized dynamics around them. (@sussillo2013opening)

Daniel J O’Shea, Lea Duncker, Werapong Goo, Xulu Sun, Saurabh Vyas, Eric M Trautmann, Ilka Diester, Charu Ramakrishnan, Karl Deisseroth, Maneesh Sahani, et al Direct neural perturbations reveal a dynamical mechanism for robust computation *bioRxiv*, pages 2022–12, 2022. **Abstract:** Abstract The rich repertoire of skilled mammalian behavior is the product of neural circuits that generate robust and flexible patterns of activity distributed across populations of neurons. Decades of associative studies have linked many behaviors to specific patterns of population activity, but association alone cannot reveal the dynamical mechanisms that shape those patterns. Are local neural circuits high-dimensional dynamical reservoirs able to generate arbitrary superpositions of patterns with appropriate excitation? Or might circuit dynamics be shaped in response to behavioral context so as to generate only the low-dimensional patterns needed for the task at hand? Here, we address these questions within primate motor cortex by delivering optogenetic and electrical microstimulation perturbations during reaching behavior. We develop a novel analytic approach that relates measured activity to theoretically tractable, dynamical models of excitatory and inhibitory neurons. This computational model captures the dynamical effects of these perturbations and demonstrates that motor cortical activity during reaching is shaped by a self-contained, low-dimensional dynamical system. The subspace containing task-relevant dynamics proves to be oriented so as to be robust to strong non-normal amplification within cortical circuits. This task dynamics space exhibits a privileged causal relationship with behavior, in that stimulation in motor cortex perturb reach kinematics only to the extent that it alters neural states within this subspace. Our results resolve long-standing questions about the dynamical structure of cortical activity associated with movement, and illuminate the dynamical perturbation experiments needed to understand how neural circuits throughout the brain generate complex behavior. (@o2022direct)

Joana Soldado-Magraner, Valerio Mante, and Maneesh Sahani Inferring context-dependent computations through linear approximations of prefrontal cortex dynamics *Science Advances*, 10 (51): eadl4743, 2024. **Abstract:** Abstract The complex neural population activity of prefrontal cortex (PFC) is a hallmark of cognitive processes. How these rich dynamics emerge and support neural computations is largely unknown. Here, we infer mechanisms underlying the context-dependent selection and integration of sensory inputs by fitting dynamical models to PFC population responses of behaving monkeys. A class of models implementing linear dynamics driven by external inputs accurately captured the PFC responses within each context, achieving performance comparable to models without linear constraints. Two distinct mechanisms of input selection and integration were equally consistent with the data. One implemented context-dependent recurrent dynamics, as previously proposed, and relied on transient input amplification. The other relied on the subtle contextual modulation of the inputs, providing quantitative constraints on the attentional effects in sensory areas required to explain flexible PFC responses and behavior. Both mechanisms consistently revealed properties of inputs and recurrent dynamics missing in more simplified, incomplete descriptions of PFC responses. By revealing mechanisms consistent with rich cortical dynamics, our modeling approach provides a principled and general framework to link neural population activity and computation. (@soldado2024inferring)

Amit Vinograd, Aditya Nair, Joseph Kim, Scott W Linderman, and David J Anderson Causal evidence of a line attractor encoding an affective state *Nature*, pages 1–3, 2024. **Abstract:** Continuous attractors are an emergent property of neural population dynamics that have been hypothesized to encode continuous variables such as head direction and eye position (@vinograd2024causal)

George Mountoufaris, Aditya Nair, Bin Yang, Dong-Wook Kim, Amit Vinograd, Samuel Kim, Scott W Linderman, and David J Anderson A line attractor encoding a persistent internal state requires neuropeptide signaling *Cell*, 187 (21): 5998–6015, 2024. **Abstract:** ABSTRACT Internal states drive survival behaviors, but their neural implementation is not well understood. Recently we identified a line attractor in the ventromedial hypothalamus (VMH) that represents an internal state of aggressiveness. Line attractors can be implemented by recurrent connectivity and/or neuromodulatory signaling, but evidence for the latter is scant. Here we show that neuropeptidergic signaling is necessary for line attractor dynamics in this system, using a novel approach that integrates cell type-specific, anatomically restricted CRISPR/Cas9-based gene editing with microendoscopic calcium imaging. Co-disruption of receptors for oxytocin and vasopressin in adult VMH Esr1 + neurons that control aggression suppressed attack, reduced persistent neural activity and eliminated line attractor dynamics, while only modestly impacting neural activity and sex- or behavior-tuning. These data identify a requisite role for neuropeptidergic signaling in implementing a behaviorally relevant line attractor. Our approach should facilitate mechanistic studies in neuroscience that bridge different levels of biological function and abstraction. (@mountoufaris2024line)

Biljana Petreska, Byron M Yu, John P Cunningham, Gopal Santhanam, Stephen Ryu, Krishna V Shenoy, and Maneesh Sahani Dynamical segmentation of single trials from population neural data *Advances in Neural Information Processing Systems*, 24, 2011. **Abstract:** Simultaneous recordings of many neurons embedded within a recurrently-connected cortical network may provide concurrent views into the dynamical processes of that network, and thus its computational function. In principle, these dynamics might be identified by purely unsupervised, statistical means. Here, we show that a Hidden Switching Linear Dynamical Systems (HSLDS) model— in which multiple linear dynamical laws approximate a nonlinear and potentially non-stationary dynamical process—is able to distinguish different dynamical regimes within single-trial motor cortical activity associated with the preparation and initiation of hand movements. The regimes are identified without reference to behavioural or experimental epochs, but nonetheless transitions between them correlate strongly with external events whose timing may vary from trial to trial. The HSLDS model also performs better than recent comparable models in predicting the firing rate of an isolated neuron based on the firing rates of others, suggesting that it captures more of the shared variance of the data. Thus, the method is able to trace the dynamical processes underlying the coordinated evolution of network activity in a way that appears to reflect its computational role. (@petreska2011dynamical)

Josue Nassar, Scott Linderman, Monica Bugallo, and Il Memming Park Tree-structured recurrent switching linear dynamical systems for multi-scale modeling In *International Conference on Learning Representations*, 2018. **Abstract:** Many real-world systems studied are governed by complex, nonlinear dynamics. By modeling these dynamics, we can gain insight into how these systems work, make predictions about how they will behave, and develop strategies for controlling them. While there are many methods for modeling nonlinear dynamical systems, existing techniques face a trade off between offering interpretable descriptions and making accurate predictions. Here, we develop a class of models that aims to achieve both simultaneously, smoothly interpolating between simple descriptions and more complex, yet also more accurate models. Our probabilistic model achieves this multi-scale property through a hierarchy of locally linear dynamics that jointly approximate global nonlinear dynamics. We call it the tree-structured recurrent switching linear dynamical system. To fit this model, we present a fully-Bayesian sampling procedure using Polya-Gamma data augmentation to allow for fast and conjugate Gibbs sampling. Through a variety of synthetic and real examples, we show how these models outperform existing methods in both interpretability and predictive capability. (@nassar2018tree)

Jalil Taghia, Weidong Cai, Srikanth Ryali, John Kochalka, Jonathan Nicholas, Tianwen Chen, and Vinod Menon Uncovering hidden brain state dynamics that regulate performance and decision-making during cognition *Nature Communications*, 9 (1): 2505, 2018. **Abstract:** Human cognition is influenced not only by external task demands but also latent mental processes and brain states that change over time. Here, we use novel Bayesian switching dynamical systems algorithm to identify hidden brain states and determine that these states are only weakly aligned with external task conditions. We compute state transition probabilities and demonstrate how dynamic transitions between hidden states allow flexible reconfiguration of functional brain circuits. Crucially, we identify latent transient brain states and dynamic functional circuits that are optimal for cognition and show that failure to engage these states in a timely manner is associated with poorer task performance and weaker decision-making dynamics. We replicate findings in a large sample (N = 122) and reveal a robust link between cognition and flexible latent brain state dynamics. Our study demonstrates the power of switching dynamical systems models for investigating hidden dynamic brain states and functional interactions underlying human cognition. (@taghia2018uncovering)

Antonio C Costa, Tosif Ahamed, and Greg J Stephens Adaptive, locally linear models of complex dynamics *Proceedings of the National Academy of Sciences*, 116 (5): 1501–1510, 2019. **Abstract:** The dynamics of complex systems generally include high-dimensional, nonstationary, and nonlinear behavior, all of which pose fundamental challenges to quantitative understanding. To address these difficulties, we detail an approach based on local linear models within windows determined adaptively from data. While the dynamics within each window are simple, consisting of exponential decay, growth, and oscillations, the collection of local parameters across all windows provides a principled characterization of the full time series. To explore the resulting model space, we develop a likelihood-based hierarchical clustering, and we examine the eigenvalues of the linear dynamics. We demonstrate our analysis with the Lorenz system undergoing stable spiral dynamics and in the standard chaotic regime. Applied to the posture dynamics of the nematode Caenorhabditis elegans , our approach identifies fine-grained behavioral states and model dynamics which fluctuate about an instability boundary, and we detail a bifurcation in a transition from forward to backward crawling. We analyze whole-brain imaging in C. elegans and show that global brain dynamics is damped away from the instability boundary by a decrease in oxygen concentration. We provide additional evidence for such near-critical dynamics from the analysis of electrocorticography in monkey and the imaging of a neural population from mouse visual cortex at single-cell resolution. (@costa2019adaptive)

David Zoltowski, Jonathan Pillow, and Scott Linderman A general recurrent state space framework for modeling neural dynamics during decision-making In *International Conference on Machine Learning*, pages 11680–11691. PMLR, 2020. (@zoltowski2020general)

Aditya Nair, Tomomi Karigo, Bin Yang, Surya Ganguli, Mark J Schnitzer, Scott W Linderman, David J Anderson, and Ann Kennedy An approximate line attractor in the hypothalamus encodes an aggressive state *Cell*, 186 (1): 178–193, 2023. **Abstract:** The hypothalamus regulates innate social behaviors, including mating and aggression. These behaviors can be evoked by optogenetic stimulation of specific neuronal subpopulations within MPOA and VMHvl, respectively. Here, we perform dynamical systems modeling of population neuronal activity in these nuclei during social behaviors. In VMHvl, unsupervised analysis identified a dominant dimension of neural activity with a large time constant (\>50 s), generating an approximate line attractor in neural state space. Progression of the neural trajectory along this attractor was correlated with an escalation of agonistic behavior, suggesting that it may encode a scalable state of aggressiveness. Consistent with this, individual differences in the magnitude of the integration dimension time constant were strongly correlated with differences in aggressiveness. In contrast, approximate line attractors were not observed in MPOA during mating; instead, neurons with fast dynamics were tuned to specific actions. Thus, different hypothalamic nuclei employ distinct neural population codes to represent similar social behaviors. (@nair2023approximate)

Mengyu Liu, Aditya Nair, Nestor Coria, Scott W Linderman, and David J Anderson Encoding of female mating dynamics by a hypothalamic line attractor *Nature*, pages 1–3, 2024. **Abstract:** Females exhibit complex, dynamic behaviors during mating with variable sexual receptivity depending on hormonal status1–4. However, how their brains encode the dynamics of mating and receptivity remains largely unknown. The ventromedial hypothalamus, ventro-lateral subdivision contains estrogen receptor type 1-positive neurons that control mating receptivity in female mice5,6. Unsupervised dynamical systems analysis of calcium imaging data from these neurons during mating uncovered a dimension with slow ramping activity, generating a line attractor in neural state space. Neural perturbations in behaving females demonstrated relaxation of population activity back into the attractor. During mating population activity integrated male cues to ramp up along this attractor, peaking just before ejaculation. Activity in the attractor dimension was positively correlated with the degree of receptivity. Longitudinal imaging revealed that attractor dynamics appear and disappear across the estrus cycle and are hormone-dependent. These observations suggest that a hypothalamic line attractor encodes a persistent, escalating state of female sexual arousal or drive during mating. They also demonstrate that attractors can be reversibly modulated by hormonal status, on a timescale of days. (@liu2024encoding)

Jimmy Smith, Scott Linderman, and David Sussillo Reverse engineering recurrent neural networks with Jacobian switching linear dynamical systems *Advances in Neural Information Processing Systems*, 34: 16700–16713, 2021. **Abstract:** Recurrent neural networks (RNNs) are powerful models for processing time-series data, but it remains challenging to understand how they function. Improving this understanding is of substantial interest to both the machine learning and neuroscience communities. The framework of reverse engineering a trained RNN by linearizing around its fixed points has provided insight, but the approach has significant challenges. These include difficulty choosing which fixed point to expand around when studying RNN dynamics and error accumulation when reconstructing the nonlinear dynamics with the linearized dynamics. We present a new model that overcomes these limitations by co-training an RNN with a novel switching linear dynamical system (SLDS) formulation. A first-order Taylor series expansion of the co-trained RNN and an auxiliary function trained to pick out the RNN’s fixed points govern the SLDS dynamics. The results are a trained SLDS variant that closely approximates the RNN, an auxiliary function that can produce a fixed point for each point in state-space, and a trained nonlinear RNN whose dynamics have been regularized such that its first-order terms perform the computation, if possible. This model removes the post-training fixed point optimization and allows us to unambiguously study the learned dynamics of the SLDS at any point in state-space. It also generalizes SLDS models to continuous manifolds of switching points while sharing parameters across switches. We validate the utility of the model on two synthetic tasks relevant to previous work reverse engineering RNNs. We then show that our model can be used as a drop-in in more complex architectures, such as LFADS, and apply this LFADS hybrid to analyze single-trial spiking activity from the motor system of a non-human primate. (@smith2021reverse)

Noga Mudrik, Yenho Chen, Eva Yezerets, Christopher J Rozell, and Adam S Charles Decomposed linear dynamical systems (dlds) for learning the latent components of neural dynamics *Journal of Machine Learning Research*, 25 (59): 1–44, 2024. **Abstract:** Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and enables modeling of overlapping and non-stationary dynamics. In both continuous-time and discrete-time instructional examples we demonstrate that our model can well approximate the original system, learn efficient representations, and capture smooth transitions between dynamical modes, focusing on intuitive low-dimensional non-stationary linear and nonlinear systems. Furthermore, we highlight our model’s ability to efficiently capture and demix population dynamics generated from multiple independent subnetworks, a task that is computationally impractical for switched models. Finally, we apply our model to neural "full brain" recordings of C. elegans data, illustrating a diversity of dynamics that is obscured when classified into discrete states. (@mudrik2024decomposed)

Christopher KI Williams and Carl Edward Rasmussen *Gaussian processes for machine learning*, volume 2 MIT press Cambridge, MA, 2006. **Abstract:** A key task in AutoML is to model learning curves of machine learning models jointly as a function of model hyper-parameters and training progression. While Gaussian processes (GPs) are suitable for this task, na\\}"ive GPs require $\\}mathcal{O}(n\^3m\^3)$ time and $\\}mathcal{O}(n\^2 m\^2)$ space for $n$ hyper-parameter configurations and $\\}mathcal{O}(m)$ learning curve observations per hyper-parameter. Efficient inference via Kronecker structure is typically incompatible with early-stopping due to missing learning curve values. We impose $\\}textit{latent Kronecker structure}$ to leverage efficient product kernels while handling missing values. In particular, we interpret the joint covariance matrix of observed values as the projection of a latent Kronecker product. Combined with iterative linear solvers and structured matrix-vector multiplication, our method only requires $\\}mathcal{O}(n\^3 + m\^3)$ time and $\\}mathcal{O}(n\^2 + m\^2)$ space. We show that our GP model can match the performance of a Transformer on a learning curve prediction task. (@williams2006gaussian)

Kevin Course and Prasanth B Nair State estimation of a physical system with unknown governing equations *Nature*, 622 (7982): 261–267, 2023. **Abstract:** State estimation is concerned with reconciling noisy observations of a physical system with the mathematical model believed to predict its behaviour for the purpose of inferring unmeasurable states and denoising measurable ones (@course2023state)

Timothy Doyeon Kim, Thomas Zhihao Luo, Tankut Can, Kamesh Krishnamurthy, Jonathan W Pillow, and Carlos D Brody Flow-field inference from neural data using deep recurrent networks *bioRxiv*, 2023. **Abstract:** Computations involved in processes such as decision-making, working memory, and motor control are thought to emerge from the dynamics governing the collective activity of neurons in large populations. But the estimation of these dynamics remains a significant challenge. Here we introduce Flow-field Inference from Neural Data using deep Recurrent networks (FINDR), an unsupervised deep learning method that can infer low-dimensional nonlinear stochastic dynamics underlying neural population activity. Using population spike train data from frontal brain regions of rats performing an auditory decision-making task, we demonstrate that FINDR outperforms existing methods in capturing the heterogeneous responses of individual neurons. We further show that FINDR can discover interpretable low-dimensional dynamics when it is trained to disentangle task-relevant and irrelevant components of the neural population activity. Importantly, the low-dimensional nature of the learned dynamics allows for explicit visualization of flow fields and attractor structures. We suggest FINDR as a powerful method for revealing the low-dimensional task-relevant dynamics of neural populations and their associated computations. (@kim2023flow)

Thomas Zhihao Luo, Timothy Doyeon Kim, Diksha Gupta, Adrian G Bondy, Charles D Kopec, Verity A Elliot, Brian DePasquale, and Carlos D Brody Transitions in dynamical regime and neural mode underlie perceptual decision-making *bioRxiv*, pages 2023–10, 2023. **Abstract:** Perceptual decision-making is the process by which an animal uses sensory stimuli to choose an action or mental proposition. This process is thought to be mediated by neurons organized as attractor networks 1,2 . However, whether attractor dynamics underlie decision behavior and the complex neuronal responses remains unclear. Here we use an unsupervised, deep learning-based method to discover decision-related dynamics from the simultaneous activity of neurons in frontal cortex and striatum of rats while they accumulate pulsatile auditory evidence. We found that trajectories evolved along two sequential regimes, the first dominated by sensory inputs, and the second dominated by the autonomous dynamics, with flow in a direction (i.e., "neural mode") largely orthogonal to that in the first regime. We propose that the second regime corresponds to decision commitment. We developed a simplified model that approximates the coupled transition in dynamics and neural mode and allows precise inference, from each trial’s neural activity, of a putative internal decision commitment time in that trial. The simplified model captures diverse and complex single-neuron temporal profiles, such as ramping and stepping 3-5 . It also captures trial-averaged curved trajectories 6-8 , and reveals distinctions between brain regions. The putative neurally-inferred commitment times ("nTc") occurred at times broadly distributed across trials, and not time-locked to stimulus onset, offset, or response onset. Nevertheless, when trials were aligned to nTc, behavioral analysis showed that, as predicted by a decision commitment time, sensory evidence before nTc affected the subjects’ decision, but evidence after nTc did not. Our results show that the formation of a perceptual choice involves a rapid, coordinated transition in both the dynamical regime and the neural mode of the decision process, and suggest the moment of commitment to be a useful entry point for dissecting mechanisms underlying rapid changes in internal state. (@luo2023transitions)

David Duvenaud *Automatic model construction with Gaussian processes* PhD thesis, 2014. **Abstract:** This work was supported by the National Sciences and Engineering Research Council of Canada, the Cambridge Commonwealth Trust, Pembroke College, a grant from the Engineering and Physical Sciences Research Council, and a grant from Google. (@duvenaud2014automatic)

Tobias Pfingsten, Malte Kuss, and Carl Edward Rasmussen Nonstationary gaussian process regression using a latent extension of the input space In *Eighth World Meeting of the International Society for Bayesian Analysis (ISBA 2006)*, 2006. **Abstract:** Robert Bosch GmbH, Corporate Research and Advance Engineering, Stuttgart Max Planck Institute for Biological Cybernetics, Tubingen {Tobias.Pfingsten, Malte.Kuss, Carl}@tuebingen.mpg.de Introduction Gaussian Processes (GPs) can be used to specify a prior over latent functions in non-parametric Bayesian models, e.g. for regression and classification. For this abstract we assume familiarity with the basic concepts of Gaussian Process models, see for example the introduction by Mackay \[1\]. A GP is defined by a mean and a covariance function, the latter describing dependencies k(x,x′) = cov(f(x), f(x′)) between function values as a function of the corresponding inputs x and x′. A common assumption when specifying a GP prior is stationarity, i.e. that the covariance between function values only depends on the distances \|x − x′\|, not on their location. It is far more difficult to specify a GP prior allowing the function to have different properties in different parts of the input space. In this work we describe new techniques for non-parametric Bayesian regression for, e.g. discontinuous, functions where the stationarity assumption does not hold. Several approaches to the problem of how to specify nonstationary GP models can be found in the literature. Sampson and Guttorp \[2\] propose to use multidimensional scaling for spatio-temporal Processes to map a nonstationary spatial Process into a latent space in which the problem becomes approximately stationary. Schmidt and O’Hagan \[3\] pick up the idea and use GPs to implement the mapping. In comparison to a direct definition of a nonstationary covariance function, as proposed by \[4\], the detour via a latent space is advantageous because it assures positive definiteness of the covariance between observations in the original space and eases an intuitive interpretation of the problem. In this work we propose to augment the input space R by a latent extra input which we infer from the data. When thinking of regression for discontinuous functions, the extra input could tear apart regions of the input space that are separated by abrupt changes of the function values. The idea to add an extra dimension to the input space is strongly related to the use of a so-called Mixtures of Local Experts (MoE) as described in \[5, 6, 7, 8\] where several independent GPs, so called experts, are used to explain the data in different regions of the input space. In this framework a gating network assigns responsibilities to certain experts, defining a mapping from the known inputs x to the class associations. We close the gap between a mixture of independent experts and a single GP using the fact that the latent associations to the experts can be seen as a discretized latent input. In the following we present two approaches for approximate Bayesian inference in GP models, that implement nonstationarity by an augmented input space. The first method is inspired by the MoE view with a discrete latent input and is implemented in an MCMC sampling scheme, whereas the second method estimates a continuous latent mapping by evidence maximization. Nonstationarity by Augmentation Let D = {(x1, y1), . . . , (xN , yN )} denote N training samples, where yi ∈ R stand for a target and xi ∈ R is the corresponding Ddimensional input vector. The standard GP regression model assumes a relation yi = f(xi) + e via a latent function f , where the observational noise is normally distributed. The key idea is to use a Gaussian Process prior on f and to make inference about the latent function directly. Below, all parameters of the covariance function and the likelihood are collected in a vector θ. Assume for example we use the common quadratic exponential covariance function k(x,x′) = v exp{− 12 ∑ d w −2 d (xd − xd)} and extend the inputs by a latent variable ‘. The covariance function of a GP in this augmented input space x = (x, ‘) reads k(x, x′) = k(x,x′) exp ( − 12 ( ‘−‘′ wo )2) . (1) (@pfingsten2006nonstationary)

Michalis Titsias Variational learning of inducing variables in sparse gaussian processes In *Artificial Intelligence and Statistics*, pages 567–574. PMLR, 2009. **Abstract:** Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature. (@titsias2009variational)

David M Blei, Alp Kucukelbir, and Jon D McAuliffe Variational inference: A review for statisticians *Journal of the American Statistical Association*, 112 (518): 859–877, 2017. **Abstract:** One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms. (@blei2017variational)

Cedric Archambeau, Dan Cornford, Manfred Opper, and John Shawe-Taylor Gaussian process approximations of stochastic differential equations In *Gaussian Processes in Practice*, pages 1–16. PMLR, 2007. **Abstract:** Stochastic differential equations arise in a variety of contexts. There are many techniques for approximation of the solutions of these equations that include statistical methods, numerical methods, and other approximations. This article implements a parametric and a nonparametric method to approximate the probability density of the solutions of stochastic differential equation from observations of a discrete dynamic system. To achieve these objectives, mixtures of Dirichlet process and Gaussian mixtures are considered. The methodology uses computational techniques based on Gaussian mixtures filters, nonparametric particle filters and Gaussian particle filters to establish the relationship between the theoretical processes of unobserved and observed states. The approximations obtained by this proposal are attractive because the hierarchical structures used for modeling are flexible, easy to interpret and computationally feasible. The methodology is illustrated by means of two problems: the synthetic Lorenz model and a real model of rainfall. Experiments show that the proposed filters provide satisfactory results, demonstrating that the algorithms work well in the context of processes with nonlinear dynamics which require the joint estimation of states and parameters. The estimated measure of goodness of fit validates the estimation quality of the algorithms. (@archambeau2007gaussian)

Vincent Adam, Paul Chang, Mohammad Emtiyaz E Khan, and Arno Solin Dual parameterization of sparse variational gaussian processes *Advances in Neural Information Processing Systems*, 34: 11474–11486, 2021. **Abstract:** Sparse variational Gaussian process (SVGP) methods are a common choice for non-conjugate Gaussian process inference because of their computational benefits. In this paper, we improve their computational efficiency by using a dual parameterization where each data example is assigned dual parameters, similarly to site parameters used in expectation propagation. Our dual parameterization speeds-up inference using natural gradient descent, and provides a tighter evidence lower bound for hyperparameter learning. The approach has the same memory cost as the current SVGP methods, but it is faster and more accurate. (@adam2021dual)

Prakhar Verma, Vincent Adam, and Arno Solin Variational gaussian process diffusion processes In *International Conference on Artificial Intelligence and Statistics*, pages 1909–1917. PMLR, 2024. **Abstract:** Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference, approximating the posterior process as a linear diffusion process, and point out pathologies in the approach. We propose an alternative parameterization of the Gaussian variational process using a site-based exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for learning model parameters. (@verma2024variational)

Gabriel M Stine, Eric M Trautmann, Danique Jeurissen, and Michael N Shadlen A neural mechanism for terminating decisions *Neuron*, 111 (16): 2601–2613, 2023. **Abstract:** The brain makes decisions by accumulating evidence until there is enough to stop and choose. Neural mechanisms of evidence accumulation are established in association cortex, but the site and mechanism of termination are unknown. Here, we show that the superior colliculus (SC) plays a causal role in terminating decisions, and we provide evidence for a mechanism by which this occurs. We recorded simultaneously from neurons in the lateral intraparietal area (LIP) and SC while monkeys made perceptual decisions. Despite similar trial-averaged activity, we found distinct single-trial dynamics in the two areas: LIP displayed drift-diffusion dynamics and SC displayed bursting dynamics. We hypothesized that the bursts manifest a threshold mechanism applied to signals represented in LIP to terminate the decision. Consistent with this hypothesis, SC inactivation produced behavioral effects diagnostic of an impaired threshold sensor and prolonged the buildup of activity in LIP. The results reveal the transformation from deliberation to commitment. (@stine2023neural)

Jamie D Roitman and Michael N Shadlen Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task *Journal of Neuroscience*, 22 (21): 9475–9489, 2002. **Abstract:** Decisions about the visual world can take time to form, especially when information is unreliable. We studied the neural correlate of gradual decision formation by recording activity from the lateral intraparietal cortex (area LIP) of rhesus monkeys during a combined motion-discrimination reaction-time task. Monkeys reported the direction of random-dot motion by making an eye movement to one of two peripheral choice targets, one of which was within the response field of the neuron. We varied the difficulty of the task and measured both the accuracy of direction discrimination and the time required to reach a decision. Both the accuracy and speed of decisions increased as a function of motion strength. During the period of decision formation, the epoch between onset of visual motion and the initiation of the eye movement response, LIP neurons underwent ramp-like changes in their discharge rate that predicted the monkey’s decision. A steeper rise in spike rate was associated with stronger stimulus motion and shorter reaction times. The observations suggest that neurons in LIP integrate time-varying signals that originate in the extrastriate visual cortex, accumulating evidence for or against a specific behavioral response. A threshold level of LIP activity appears to mark the completion of the decision process and to govern the tradeoff between accuracy and speed of perception. (@roitman2002response)

Jochen Ditterich Stochastic models of decisions about motion direction: behavior and physiology *Neural Networks*, 19 (8): 981–1012, 2006. (@ditterich2006stochastic)

Joshua I Gold and Michael N Shadlen The neural basis of decision making *Annu. Rev. Neurosci.*, 30: 535–574, 2007. **Abstract:** The study of decision making spans such varied fields as neuroscience, psychology, economics, statistics, political science, and computer science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings. (@gold2007neural)

Kenneth W Latimer, Jacob L Yates, Miriam LR Meister, Alexander C Huk, and Jonathan W Pillow Single-trial spike trains in parietal cortex reveal discrete steps during decision-making *Science*, 349 (6244): 184–187, 2015. **Abstract:** A better way to explain neuronal activity A brain region called the lateral intraparietal (LIP) area is involved in primate decision-making. The dominant model to explain neuronal firing in LIP assumes that neurons slowly accumulate sensory evidence in favor of one choice or another. Latimer et al. hypothesized that neurons instead exhibit rapid steps or jumps in their firing rate, reflecting discrete changes in the animal’s decision state. They recorded from LIP neurons in macaque monkeys performing a motion-discrimination task. LIP spike trains in most cells involved discrete stepping dynamics rather than slow evidence integration dynamics. Science , this issue p. 184 (@latimer2015single)

Mikhail Genkin, Krishna V Shenoy, Chandramouli Chandrasekaran, and Tatiana A Engel The dynamics and geometry of choice in premotor cortex *bioRxiv*, 2023. **Abstract:** The brain represents sensory variables in the coordinated activity of neural populations, in which tuning curves of single neurons define the geometry of the population code. Whether the same coding principle holds for dynamic cognitive variables remains unknown because internal cognitive processes unfold with a unique time course on single trials observed only in the irregular spiking of heterogeneous neural populations. Here we show the existence of such a population code for the dynamics of choice formation in the primate premotor cortex. We developed an approach to simultaneously infer population dynamics and tuning functions of single neurons to the population state. Applied to spike data recorded during decision-making, our model revealed that populations of neurons encoded the same dynamic variable predicting choices, and heterogeneous firing rates resulted from the diverse tuning of single neurons to this decision variable. The inferred dynamics indicated an attractor mechanism for decision computation. Our results reveal a common geometric principle for neural encoding of sensory and dynamic cognitive variables. (@genkin2023dynamics)

Gouki Okazawa, Christina E Hatch, Allan Mancoo, Christian K Machens, and Roozbeh Kiani Representational geometry of perceptual decisions in the monkey parietal cortex *Cell*, 184 (14): 3748–3761, 2021. (@okazawa2021representational)

Jack Wang, Aaron Hertzmann, and David J Fleet Gaussian process dynamical models *Advances in Neural Information Processing Systems*, 18, 2005. **Abstract:** We introduce Gaussian process dynamical models (GPDM) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensionalmotion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, using Gaussian process priors for both the dynamics and the observation mappings. This results in a non-parametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach, and compare four learning algorithms on human motion capture data in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces. (@wang2005gaussian)

Ryan Turner, Marc Deisenroth, and Carl Rasmussen State-space inference and learning with gaussian processes In *Artificial Intelligence and Statistics*, pages 868–875. JMLR Workshop and Conference Proceedings, 2010. **Abstract:** State-space inference and learning with Gaussian processes (GPs) is an unsolved problem. We propose a new, general methodology for inference and learning in nonlinear state-space models that are described probabilistically by non-parametric GP models. We apply the expectation maximization algorithm to iterate between inference in the latent state-space and learning the parameters of the underlying GP dynamics model. Copyright 2010 by the authors. (@turner2010state)

Roger Frigola, Yutian Chen, and Carl Edward Rasmussen Variational gaussian process state-space models *Advances in Neural Information Processing Systems*, 27, 2014. **Abstract:** State-space models have been successfully used for more than fifty years in different areas of science and engineering. We present a procedure for efficient variational Bayesian learning of nonlinear state-space models based on sparse Gaussian processes. The result of learning is a tractable posterior over nonlinear dynamical systems. In comparison to conventional parametric models, we offer the possibility to straightforwardly trade off model capacity and computational cost whilst avoiding overfitting. Our main algorithm uses a hybrid inference approach combining variational Bayes and sequential Monte Carlo. We also present stochastic variational inference and online learning approaches for fast learning with long time series. (@frigola2014variational)

Stefanos Eleftheriadis, Tom Nicholson, Marc Deisenroth, and James Hensman Identification of gaussian process state space models *Advances in Neural Information Processing Systems*, 30, 2017. **Abstract:** The Gaussian process state space model (GPSSM) is a non-linear dynamical system, where unknown transition and/or measurement mappings are described by GPs. Most research in GPSSMs has focussed on the state estimation problem, i.e., computing a posterior of the latent state given the model. However, the key challenge in GPSSMs has not been satisfactorily addressed yet: system identification, i.e., learning the model. To address this challenge, we impose a structured Gaussian variational posterior distribution over the latent states, which is parameterised by a recognition model in the form of a bi-directional recurrent neural network. Inference with this structure allows us to recover a posterior smoothed over sequences of data. We provide a practical algorithm for efficiently computing a lower bound on the marginal likelihood using the reparameterisation trick. This further allows for the use of arbitrary kernels within the GPSSM. We demonstrate that the learnt GPSSM can efficiently generate plausible future trajectories of the identified system after only observing a small number of episodes from the true system. (@eleftheriadis2017identification)

Gergo Bohner and Maneesh Sahani Empirical fixed point bifurcation analysis *arXiv preprint arXiv:1807.01486*, 2018. **Abstract:** In a common experimental setting, the behaviour of a noisy dynamical system is monitored in response to manipulations of one or more control parameters. Here, we introduce a structured model to describe parametric changes in qualitative system behaviour via stochastic bifurcation analysis. In particular, we describe an extension of Gaussian Process models of transition maps, in which the learned map is directly parametrized by its fixed points and associated local linearisations. We show that the system recovers the behaviour of a well-studied one dimensional system from little data, then learn the behaviour of a more realistic two dimensional process of mutually inhibiting neural populations. (@bohner2018empirical)

Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud Neural ordinary differential equations *Advances in Neural Information Processing Systems*, 31, 2018. **Abstract:** We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models. (@chen2018neural)

Yulia Rubanova, Ricky TQ Chen, and David K Duvenaud Latent ordinary differential equations for irregularly-sampled time series *Advances in Neural Information Processing Systems*, 32, 2019. **Abstract:** Time series with non-uniform intervals occur in many applications, and are difficult to model using standard recurrent neural networks (RNNs). We generalize RNNs to have continuous-time hidden dynamics defined by ordinary differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps between observations, and can explicitly model the probability of observation times using Poisson processes. We show experimentally that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled data. (@rubanova2019latent)

Timothy D Kim, Thomas Z Luo, Jonathan W Pillow, and Carlos D Brody Inferring latent dynamics underlying neural population activity via neural differential equations In *International Conference on Machine Learning*, pages 5551–5561. PMLR, 2021. **Abstract:** An important problem in systems neuroscience is to identify the latent dynamics underlying neural population activity. Here we address this prob- lem by introducing a low-dimensional nonlinear model for latent neural population dynamics us- ing neural ordinary differential equations (neural ODEs), with noisy sensory inputs and Poisson spike train outputs. We refer to this as the Poisson Latent Neural Differential Equations (PLNDE) model. We apply the PLNDE framework to a variety of synthetic datasets, and show that it ac- curately infers the phase portraits and ﬁxed points of nonlinear systems augmented to produce spike train data, including the FitzHugh-Nagumo os- cillator, a 3-dimensional nonlinear spiral, and a nonlinear sensory decision-making model with attractor dynamics. Our model signiﬁcantly out- performs existing methods at inferring single-trial neural ﬁring rates and the corresponding latent trajectories that generated them, especially in the regime where the spike counts and number of trials are low. We then apply our model to multi-region neural population recordings from medial frontal cortex of rats performing an audi- tory decision-making task. Our model provides a general, interpretable framework for investigating the neural mechanisms of decision-making and other cognitive computations through the lens of dynamical systems. (@kim2021inferring)

Timothy Doyeon Kim, Tankut Can, and Kamesh Krishnamurthy Trainability, expressivity and interpretability in gated neural odes In *International Conference on Machine Learning*, pages 16393–16423, 2023. **Abstract:** Understanding how the dynamics in biological and artificial neural networks implement the computations required for a task is a salient open question in machine learning and neuroscience. In particular, computations requiring complex memory storage and retrieval pose a significant challenge for these networks to implement or learn. Recently, a family of models described by neural ordinary differential equations (nODEs) has emerged as powerful dynamical neural network models capable of capturing complex dynamics. Here, we extend nODEs by endowing them with adaptive timescales using gating interactions. We refer to these as gated neural ODEs (gnODEs). Using a task that requires memory of continuous quantities, we demonstrate the inductive bias of the gnODEs to learn (approximate) continuous attractors. We further show how reduced-dimensional gnODEs retain their modeling power while greatly improving interpretability, even allowing explicit visualization of the structure of learned attractors. We introduce a novel measure of expressivity which probes the capacity of a neural network to generate complex trajectories. Using this measure, we explore how the phase-space dimension of the nODEs and the complexity of the function modeling the flow field contribute to expressivity. We see that a more complex function for modeling the flow field allows a lower-dimensional nODE to capture a given target dynamics. Finally, we demonstrate the benefit of gating in nODEs on several real-world tasks. (@kim2023trainability)

Christopher Versteeg, Andrew R Sedler, Jonathan D McCart, and Chethan Pandarinath Expressive dynamics models with nonlinear injective readouts enable reliable recovery of latent features from neural activity *arXiv preprint arXiv:2309.06402*, 2023. **Abstract:** The advent of large-scale neural recordings has enabled new methods to discover the computational mechanisms of neural circuits by understanding the rules that govern how their state evolves over time. While these \\}textit{neural dynamics} cannot be directly measured, they can typically be approximated by low-dimensional models in a latent space. How these models represent the mapping from latent space to neural space can affect the interpretability of the latent representation. We show that typical choices for this mapping (e.g., linear or MLP) often lack the property of injectivity, meaning that changes in latent state are not obligated to affect activity in the neural space. During training, non-injective readouts incentivize the invention of dynamics that misrepresent the underlying system and the computation it performs. Combining our injective Flow readout with prior work on interpretable latent dynamics models, we created the Ordinary Differential equations autoencoder with Injective Nonlinear readout (ODIN), which captures latent dynamical systems that are nonlinearly embedded into observed neural activity via an approximately injective nonlinear mapping. We show that ODIN can recover nonlinearly embedded systems from simulated neural activity, even when the nature of the system and embedding are unknown. Additionally, ODIN enables the unsupervised recovery of underlying dynamical features (e.g., fixed points) and embedding geometry. When applied to biological neural recordings, ODIN can reconstruct neural activity with comparable accuracy to previous state-of-the-art methods while using substantially fewer latent dimensions. Overall, ODIN’s accuracy in recovering ground-truth latent features and ability to accurately reconstruct neural activity with low dimensionality make it a promising method for distilling interpretable dynamics that can help explain neural computation. (@versteeg2023expressive)

Lukas Köhs, Bastian Alt, and Heinz Koeppl Variational inference for continuous-time switching dynamical systems *Advances in Neural Information Processing Systems*, 34: 20545–20557, 2021. **Abstract:** Switching dynamical systems provide a powerful, interpretable modeling framework for inference in time-series data in, e.g., the natural sciences or engineering applications. Since many areas, such as biology or discrete-event systems, are naturally described in continuous time, we present a model based on an Markov jump process modulating a subordinated diffusion process. We provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, we develop a new continuous-time variational inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jump processes. By minimizing the path-wise Kullback-Leibler divergence we obtain (i) Bayesian latent state estimates for arbitrary points on the real axis and (ii) point estimates of unknown system parameters, utilizing variational expectation maximization. We extensively evaluate our algorithm under the model assumption and for real-world examples. (@kohs2021variational)

Lukas Köhs, Bastian Alt, and Heinz Koeppl Markov chain monte carlo for continuous-time switching dynamical systems In *International Conference on Machine Learning*, pages 11430–11454. PMLR, 2022. **Abstract:** Switching dynamical systems are an expressive model class for the analysis of time-series data. As in many fields within the natural and engineering sciences, the systems under study typically evolve continuously in time, it is natural to consider continuous-time model formulations consisting of switching stochastic differential equations governed by an underlying Markov jump process. Inference in these types of models is however notoriously difficult, and tractable computational schemes are rare. In this work, we propose a novel inference algorithm utilizing a Markov Chain Monte Carlo approach. The presented Gibbs sampler allows to efficiently obtain samples from the exact continuous-time posterior processes. Our framework naturally enables Bayesian parameter estimation, and we also include an estimate for the diffusion covariance, which is oftentimes assumed fixed in stochastic differential equation models. We evaluate our framework under the modeling assumption and compare it against an existing variational inference approach. (@kohs2022markov)

Cédric Archambeau, Manfred Opper, Yuan Shen, Dan Cornford, and John Shawe-Taylor Variational inference for diffusion processes *Advances in Neural Information Processing Systems*, 20, 2007. **Abstract:** Diffusion processes are a family of continuous-time continuous-state stochastic processes that are in general only partially observed. The joint estimation of the forcing parameters and the system noise (volatility) in these dynamical systems is a crucial, but non-trivial task, especially when the system is nonlinear and multi-modal. We propose a variational treatment of diffusion processes, which allows us to compute type II maximum likelihood estimates of the parameters by simple gradient techniques and which is computationally less demanding than most MCMC approaches. We also show how a cheap estimate of the posterior over the parameters can be constructed based on the variational free energy. (@archambeau2007variational)

Kevin Course and Prasanth Nair Amortized reparametrization: Efficient and scalable variational inference for latent sdes *Advances in Neural Information Processing Systems*, 36, 2024. **Abstract:** We consider the problem of inferring latent stochastic differential equations (SDEs) with a time and memory cost that scales independently with the amount of data, the total length of the time series, and the stiffness of the approximate differential equations. This is in stark contrast to typical methods for inferring latent differential equations which, despite their constant memory cost, have a time complexity that is heavily dependent on the stiffness of the approximate differential equation. We achieve this computational advancement by removing the need to solve differential equations when approximating gradients using a novel amortization strategy coupled with a recently derived reparametrization of expectations under linear SDEs. We show that, in practice, this allows us to achieve similar performance to methods based on adjoint sensitivities with more than an order of magnitude fewer evaluations of the model in training. (@course2024amortized)

Botond Cseke, David Schnoerr, Manfred Opper, and Guido Sanguinetti Expectation propagation for continuous time stochastic processes *Journal of Physics A: Mathematical and Theoretical*, 49 (49): 494002, 2016. **Abstract:** We consider the inverse problem of reconstructing the posterior measure over the trajectories of a diffusion process from discrete time observations and continuous time constraints. We cast the problem in a Bayesian framework and derive approximations to the posterior distributions of single time marginals using variational approximate inference, giving rise to an expectation propagation type algorithm. For non-linear diffusion processes, this is achieved by leveraging moment closure approximations. We then show how the approximation can be extended to a wide class of discrete-state Markov jump processes by making use of the chemical Langevin equation. Our empirical results show that the proposed method is computationally efficient and provides good approximations for these classes of inverse problems. (@cseke2016expectation)

Anqi Wu, Stan Pashkovski, Sandeep R Datta, and Jonathan W Pillow Learning a latent manifold of odor representations from neural responses in piriform cortex *Advances in Neural Information Processing Systems*, 31, 2018. **Abstract:** A major difficulty in studying the neural mechanisms underlying olfactory perception is the lack of obvious structure in the relationship between odorants and the neural activity patterns they elicit. Here we use odor-evoked responses in piriform cortex to identify a latent manifold specifying latent distance relationships between olfactory stimuli. Our approach is based on the Gaussian process latent variable model, and seeks to map odorants to points in a low-dimensional embedding space, where distances between points in the embedding space relate to the similarity of population responses they elicit. The model is specified by an explicit continuous mapping from a latent embedding space to the space of high-dimensional neural population firing rates via nonlinear tuning curves, each parametrized by a Gaussian process. Population responses are then generated by the addition of correlated, odor-dependent Gaussian noise. We fit this model to large-scale calcium fluorescence imaging measurements of population activity in layers 2 and 3 of mouse piriform cortex following the presentation of a diverse set of odorants. The model identifies a low-dimensional embedding of each odor, and a smooth tuning curve over the latent embedding space that accurately captures each neuron’s response to different odorants. The model captures both signal and noise correlations across more than 500 neurons. We validate the model using a cross-validation analysis known as co-smoothing to show that the model can accurately predict the responses of a population of held-out neurons to test odorants. (@wu2018learning)

Stephen Keeley, Mikio Aoi, Yiyi Yu, Spencer Smith, and Jonathan W Pillow Identifying signal and noise structure in neural population activity with gaussian process factor models *Advances in Neural Information Processing Systems*, 33: 13795–13805, 2020. **Abstract:** Abstract Neural datasets often contain measurements of neural activity across multiple trials of a repeated stimulus or behavior. An important problem in the analysis of such datasets is to characterize systematic aspects of neural activity that carry information about the repeated stimulus or behavior of interest, which can be considered “signal”, and to separate them from the trial-to-trial fluctuations in activity that are not time-locked to the stimulus, which for purposes of such analyses can be considered “noise”. Gaussian Process factor models provide a powerful tool for identifying shared structure in high-dimensional neural data. However, they have not yet been adapted to the problem of characterizing signal and noise in multi-trial datasets. Here we address this shortcoming by proposing “signal-noise” Poisson-spiking Gaussian Process Factor Analysis (SNP-GPFA), a flexible latent variable model that resolves signal and noise latent structure in neural population spiking activity. To learn the parameters of our model, we introduce a Fourier-domain black box variational inference method that quickly identifies smooth latent structure. The resulting model reliably uncovers latent signal and trial-to-trial noise-related fluctuations in large-scale recordings. We use this model to show that predominantly, noise fluctuations perturb neural activity within a subspace orthogonal to signal activity, suggesting that trial-by-trial noise does not interfere with signal representations. Finally, we extend the model to capture statistical dependencies across brain regions in multi-region data. We show that in mouse visual cortex, models with shared noise across brain regions out-perform models with independent per-region noise. (@keeley2020identifying)

</div>

**Supplementary Material**

# Table of Contents [table-of-contents]

– **Appendix <a href="#app:sec:linear_kernel_relation" data-reference-type="ref" data-reference="app:sec:linear_kernel_relation">7</a>**: Relationship between linear kernel and linear dynamical systems  
– **Appendix <a href="#app:sec:inference" data-reference-type="ref" data-reference="app:sec:inference">8</a>**: Inference and learning  
– **Appendix <a href="#app:sec:learning_objective" data-reference-type="ref" data-reference="app:sec:learning_objective">9</a>**: Empirical results for new learning objective  
– **Appendix <a href="#app:sec:synthetic_results" data-reference-type="ref" data-reference="app:sec:synthetic_results">10</a>**: Additional synthetic data results

# Relationship between linear kernel and linear dynamical systems [app:sec:linear_kernel_relation]

Here, we draw a mathematical connection between functions sampled from a GP with a linear kernel, \\[\label{app:eqn:linear_kernel}
    f(\cdot) \sim \mathcal{G}\mathcal{P}(0, \kappa_{\text{lin}}(\cdot, \cdot)), \qquad \kappa_{\text{lin}}(\boldsymbol{x}, \boldsymbol{x}') = (\boldsymbol{x}- \boldsymbol{c})^\mathsf{T}\boldsymbol{M}(\boldsymbol{x}- \boldsymbol{c}) + \sigma_0^2\\] and functions of the form \\[\label{app:eqn:linear_function}
    f(\boldsymbol{x}) = \boldsymbol{\beta}^\mathsf{T}\boldsymbol{x}+ \beta_0.\\] This connection is useful for understanding the relationship between our model formulation and the typical linear dynamical systems formulation as in the rSLDS. In particular, we will show that the linear kernel in  
efapp:eqn:linear_kernel equivalently places a prior on \\(\boldsymbol{\beta}\\) and \\(\beta_0\\) in  
efapp:eqn:linear_function, in a similar manner to Bayesian linear regression.

By definition of a GP, for any finite set of input locations \\(\{\boldsymbol{x}_i\}_{i=1}^N\\), we have \\[\label{app:eqn:mvn}
    \begin{bmatrix}f(\boldsymbol{x}_1) & f(\boldsymbol{x}_2) & \dots & f(\boldsymbol{x}_N) \end{bmatrix}^\mathsf{T}\sim \mathcal{N}(\textbf{0}, \Phi)\\] where \\(\Phi_{ij} = \kappa_{\text{lin}}(\boldsymbol{x}_i, \boldsymbol{x}_j)\\). Equivalently, for every pair \\(i, j=1, \dots, N\\), \\[\begin{aligned}
    \text{Cov}(f(\boldsymbol{x}_i), f(\boldsymbol{x}_j)) &= (\boldsymbol{x}_i - \boldsymbol{c})^\mathsf{T}\boldsymbol{M}(\boldsymbol{x}_j - \boldsymbol{c}) + \sigma_0^2\\
    &= \boldsymbol{x}_i^\mathsf{T}\boldsymbol{M}\boldsymbol{x}_j - \boldsymbol{c}^\mathsf{T}\boldsymbol{M}(\boldsymbol{x}_i + \boldsymbol{x}_j) + \boldsymbol{c}^\mathsf{T}\boldsymbol{c}+ \sigma_0^2\label{app:eqn:linear_cov_1}
\end{aligned}\\] Under  
efapp:eqn:linear_function, treating \\(\boldsymbol{\beta}\\) and \\(\beta_0\\) as random, this would become \\[\begin{aligned}
    \text{Cov}(\boldsymbol{\beta}^\mathsf{T}\boldsymbol{x}_i + \beta_0, \boldsymbol{\beta}^\mathsf{T}\boldsymbol{x}_j + \beta_0) &= \boldsymbol{x}_i^\mathsf{T}\text{Cov}(\boldsymbol{\beta}, \boldsymbol{\beta}) \boldsymbol{x}_j + \text{Cov}(\beta_0, \boldsymbol{\beta}) (\boldsymbol{x}_i + \boldsymbol{x}_j) + \text{Var}(\beta_0)\label{app:eqn:linear_cov_2}
\end{aligned}\\] <a href="#app:eqn:linear_cov_1" data-reference-type="ref+Label" data-reference="app:eqn:linear_cov_1">[app:eqn:linear_cov_1]</a> and  
efapp:eqn:linear_cov_2 are equivalent and  
efapp:eqn:mvn is satisfied if and only if \\[\label{app:eqn:prior_on_beta}
    \begin{bmatrix} \boldsymbol{\beta}\\ \beta_0 \end{bmatrix} \sim \mathcal{N}\left(\mathbf{0}, \begin{bmatrix} \boldsymbol{M}& -\boldsymbol{M}\boldsymbol{c}\\ -\boldsymbol{c}^\mathsf{T}\boldsymbol{M}& \boldsymbol{c}^\mathsf{T}\boldsymbol{c}+ \sigma_0^2\end{bmatrix} \right)\\] This shows that a GP with a linear kernel is equivalent to a Bayesian linear regression model with a prior on coefficients of the form in  
efapp:eqn:prior_on_beta.

# Inference and learning [app:sec:inference]

We present the full inference and learning details for the gpSLDS with additive inputs, \\[d\boldsymbol{x}= (\boldsymbol{f}(\boldsymbol{x}) + \boldsymbol{B}\boldsymbol{v}(t)) dt + \boldsymbol{\Sigma}^{\frac{1}{2}} d \boldsymbol{w}, \qquad \mathbb{E}[\boldsymbol{y}(t_i) ~\vert~\boldsymbol{x}] = g\left(\boldsymbol{C}\boldsymbol{x}(t_i) + \boldsymbol{d}\right).\\] Our approach primarily follows that of `\citet{duncker2019learning}`{=latex}. We use the following notation from `\citet{duncker2019learning}`{=latex} throughout this section:

- \\(\left< h(\cdot) \right>_{p(\cdot)}\\) denotes the expectation of \\(h(\cdot)\\) with respect to the distribution \\(p(\cdot)\\).

- \\(\boldsymbol{K}_{xz} \in \mathbb{R}^{N_1 \times N_2}\\) denotes the covariance matrix defined by our kernel \\(\kappa_{\text{ssl}}(\cdot, \cdot)\\) for two batches of points \\(\{\boldsymbol{x}_i\}_{i=1}^{N_1}\\) and \\(\{\boldsymbol{z}_i\}_{i=1}^{N_2}\\). Specifically, \\([\boldsymbol{K}_{xz}]_{ij} = \kappa_{\text{ssl}}(\boldsymbol{x}_i, \boldsymbol{z}_j)\\). If one of these batches has only one point, e.g. \\(N_1 = 1\\), we denote the corresponding covariance vector as \\(\boldsymbol{k}_{xz} \in \mathbb{R}^{1 \times N_2}\\). Note, these quantities depend on \\(\Theta\\) through the kernel; we omit writing this dependence for brevity.

## Augmenting the generative model [app:sec:augmenting]

Following `\citet{duncker2019learning}`{=latex}, we first augment our generative model with sparse inducing points \\(\{\boldsymbol{u}_k\}_{k=1}^K \subset \mathbb{R}^M\\) at input locations \\(\{\boldsymbol{z}_m\}_{m=1}^M \subset \mathbb{R}^D\\). Inducing points can be seen as pseudo-observations of \\(\boldsymbol{f}(\cdot)\\) at input locations \\(\{\boldsymbol{z}_m\}_{m=1}^M\\). They allow for tractable inference of \\(\boldsymbol{f}\\) at any new batch of \\(N\\) input locations by reducing computational complexity from \\(O(N^3)\\) to \\(O(NM^2)\\), where typically \\(M\\) is chosen to be much smaller than \\(N\\) `\citep{titsias2009variational}`{=latex}. After this augmentation, the joint likelihood of our model becomes \\[p(\boldsymbol{y}, \boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u}~\vert~\Theta) = p(\boldsymbol{y}~\vert~\boldsymbol{x}) p(\boldsymbol{x}~\vert~\boldsymbol{f}) \prod_{k=1}^K p(f_k ~\vert~\boldsymbol{u}_k, \Theta) p(\boldsymbol{u}_k ~\vert~\Theta).\\] Treating \\(\boldsymbol{u}_k\\) as pseudo-observations, we assume the following augmented prior: \\[p(\boldsymbol{u}_k ~\vert~\Theta) = \mathcal{N}(\boldsymbol{u}_k ~\vert~\mathbf{0}, \boldsymbol{K}_{zz}).\\] Then we can view \\(f_k(\cdot) ~\vert~\boldsymbol{u}_k\\) as a new GP conditioned on \\(\boldsymbol{u}_k\\), \\[f_k(\cdot) ~\vert~\boldsymbol{u}_k \sim \mathcal{G}\mathcal{P}(\mu_{f_k|\boldsymbol{u}_k}(\cdot), \kappa_{f_k|\boldsymbol{u}_k}(\cdot, \cdot)),\\] where \\[\begin{aligned}
    \mu_{f_k|\boldsymbol{u}_k}(\boldsymbol{x}) &= \boldsymbol{k}_{xz} \boldsymbol{K}_{zz}^{-1} \boldsymbol{u}_k\\
    \kappa_{f_k|\boldsymbol{u}_k}(\boldsymbol{x}, \boldsymbol{x}') &= \kappa_{\text{ssl}}(\boldsymbol{x}, \boldsymbol{x}') - \boldsymbol{k}_{xz} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx}.
\end{aligned}\\]

## Variational lower bound [app:sec:elbo_derivation]

As in `\citet{duncker2019learning}`{=latex}, we consider a variational approximation to the posterior of the form \\[\label{app:eqn:vem_factorization}
    q(\boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u}) = q(\boldsymbol{x}) \prod_{k=1}^K p(f_k ~\vert~\boldsymbol{u}_k, \Theta)q(\boldsymbol{u}_k).\\] Using this factorization, we derive the ELBO to the marginal log-likelihood of our model. By Jensen’s inequality, \\[\begin{aligned}
    \log p(\boldsymbol{y}~\vert~\Theta) &= \log  \int p(\boldsymbol{y}~\vert~\boldsymbol{x}) p(\boldsymbol{x}~\vert~\boldsymbol{f}) p(\boldsymbol{f}~\vert~\boldsymbol{u}, \Theta) p(\boldsymbol{u}~\vert~\Theta) d \boldsymbol{x}d \boldsymbol{f}d \boldsymbol{u}\\
    &\geq \int q(\boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u})\log \frac{p(\boldsymbol{y}~\vert~\boldsymbol{x})p(\boldsymbol{x}~\vert~\boldsymbol{f}) p(\boldsymbol{f}~\vert~\boldsymbol{u}, \Theta) p (\boldsymbol{u}~\vert~\Theta)}{q(\boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u})}d \boldsymbol{x}d \boldsymbol{f}d \boldsymbol{u}\\
    &= \int q(\boldsymbol{x}, \boldsymbol{f}, \boldsymbol{u})\log \frac{p(\boldsymbol{y}~\vert~\boldsymbol{x})p(\boldsymbol{x}~\vert~\boldsymbol{f}) \prod_{k=1}^K p (\boldsymbol{u}_k ~\vert~\Theta)}{q(\boldsymbol{x}) \prod_{k=1}^K q(\boldsymbol{u}_k)}d \boldsymbol{x}d \boldsymbol{f}d \boldsymbol{u}\\
    &= \left<\log p(\boldsymbol{y}~\vert~\boldsymbol{x})\right>_{q(\boldsymbol{x})} - \left<\text{KL}[q(\boldsymbol{x}) || p(\boldsymbol{x}~\vert~\boldsymbol{f})]\right>_{q(\boldsymbol{f})} - \sum_{k=1}^K \text{KL}[q(\boldsymbol{u}_k) || p(\boldsymbol{u}_k ~\vert~\Theta)]\\
    &:= \mathcal{L}(q(\boldsymbol{x}), q(\boldsymbol{u}), \Theta),
\end{aligned}\\] where \\[\label{app:sec:f_variational}
    q(\boldsymbol{f}) = \prod_{k=1}^K \int p(f_k ~\vert~\boldsymbol{u}_k, \Theta) q(\boldsymbol{u}_k) d\boldsymbol{u}_k.\\]

## Inference of latent paths [app:sec:inference_of_latents]

To perform inference over the posterior of latent paths \\(q(\boldsymbol{x})\\), we follow a method first proposed in `\citet{archambeau2007gaussian}`{=latex} and extended by `\citet{duncker2019learning}`{=latex}.

As in `\citet{archambeau2007gaussian}`{=latex}, we choose a posterior distribution \\(q(\boldsymbol{x})\\) characterized by a Markov Gaussian process, \\[q(\boldsymbol{x}): \{d \boldsymbol{x}= \underbrace{(-\boldsymbol{A}(t) \boldsymbol{x}(t) + \boldsymbol{b}(t))}_{:=\boldsymbol{f}_q(\boldsymbol{x})} dt + \boldsymbol{\Sigma}^{\frac{1}{2}} d \boldsymbol{w}, \quad \boldsymbol{x}_0 \sim \mathcal{N}(\boldsymbol{m}(0), \boldsymbol{S}(0))\}.\\] This distribution satisfies posterior marginals \\(q(\boldsymbol{x}_t) = \mathcal{N}(\boldsymbol{x}_t ~\vert~\boldsymbol{m}_t, \boldsymbol{S}_t)\\) which satisfy the differential equations \\[\begin{aligned}
    \frac{d \boldsymbol{m}(t)}{dt} &= -\boldsymbol{A}(t) \boldsymbol{m}(t) + \boldsymbol{b}(t)\label{app:eqn:m_ode}\\
    \quad \frac{d \boldsymbol{S}(t)}{dt} &= -\boldsymbol{A}(t) \boldsymbol{S}(t) - \boldsymbol{S}(t) \boldsymbol{A}(t)^\mathsf{T}+ \boldsymbol{\Sigma}. \label{app:eqn:S_ode}
\end{aligned}\\] `\citet{archambeau2007gaussian}`{=latex} maximize the ELBO with respect to \\(q(\boldsymbol{x})\\) subject to the constraints in  
efapp:eqn:m_ode and  
efapp:eqn:S_ode using the method of Lagrange multipliers. They show that after applying integration by parts, the Lagrangian becomes \\[\widetilde{\mathcal{L}} = \mathcal{L}(q(\boldsymbol{x}), q(\boldsymbol{u}), \Theta) - \mathcal{C}_1 - \mathcal{C}_2\\] where \\[\begin{aligned}
    \mathcal{C}_1 &= \int_0^T \left\{\boldsymbol{\lambda}(t)^\mathsf{T}(\boldsymbol{A}(t) \boldsymbol{m}(t) - \boldsymbol{b}(t)) - \frac{d \boldsymbol{\lambda}(t)} {dt}^\mathsf{T}\boldsymbol{m}(t)\right\}dt + \boldsymbol{\lambda}(T)^\mathsf{T}\boldsymbol{m}(T) - \boldsymbol{\lambda}(0)^\mathsf{T}\boldsymbol{m}(0)\\
    \mathcal{C}_2 &= \int_0^T \text{Tr}\left[\boldsymbol{\Psi}(t)(\boldsymbol{A}(t)\boldsymbol{S}(t) + \boldsymbol{S}(t) \boldsymbol{A}(t)^\mathsf{T}- \boldsymbol{\Sigma}) - \frac{d\boldsymbol{\Psi}(t)}{dt} \boldsymbol{S}(t) \right]dt \\
    & \qquad + \text{Tr}[\boldsymbol{\Psi}(T) \boldsymbol{S}(T)] - \text{Tr}[\boldsymbol{\Psi}(0) \boldsymbol{S}(0)]
\end{aligned}\\] As in `\citet{archambeau2007gaussian}`{=latex}, we assume that \\(\boldsymbol{\lambda}(T) = \mathbf{0}\\) and \\(\boldsymbol{\Psi}(T) = \mathbf{0}\\).

To find the stationary points of the Lagrangian, we first take derivatives of \\(\widetilde{\mathcal{L}}\\) with respect to \\(\boldsymbol{m}(0), \boldsymbol{S}(0), \boldsymbol{m}(t), \boldsymbol{S}(t), \boldsymbol{A}(t), \boldsymbol{b}(t)\\) and set them to 0. The derivatives with respect to \\(\boldsymbol{m}(0)\\) and \\(\boldsymbol{S}(0)\\) lead to the updates \\[\label{app:eqn:init_cond_update}
    \boldsymbol{m}(0) = \boldsymbol{\mu}(0) - \boldsymbol{V}(0) \boldsymbol{\lambda}(0), \qquad \boldsymbol{S}(0) = \left(2 \boldsymbol{\Psi}(0) + \boldsymbol{V}(0)^{-1} \right)^{-1}\\] where we assume a prior on initial conditions \\(p(\boldsymbol{x}_0) = \mathcal{N}(\boldsymbol{x}_0 ~\vert~\boldsymbol{\mu}(0), \boldsymbol{V}(0))\\).

The derivatives with respect to \\(\boldsymbol{m}(t)\\) and \\(\boldsymbol{S}(t)\\) lead to the stationary equations \\[\begin{aligned}
    \frac{d\boldsymbol{\lambda}(t)}{dt} &= \boldsymbol{A}(t)^\mathsf{T}\boldsymbol{\lambda}(t) - \frac{\partial \mathcal{L}}{\partial \boldsymbol{m}(t)}\label{app:eqn:lambda_ode}\\
    \frac{d \boldsymbol{\Psi}(t)}{dt} &= \boldsymbol{A}(t)^\mathsf{T}\boldsymbol{\Psi}(t) - \boldsymbol{\Psi}(t) \boldsymbol{A}(t) - \frac{\partial \mathcal{L}}{\partial \boldsymbol{S}(t)} \odot \mathbb{P}\label{app:eqn:psi_ode}
\end{aligned}\\] with \\(\mathbb{P}_{ij} = \frac{1}{2}\\) for \\(i \neq j\\) and \\(1\\) otherwise. The inclusion of \\(\mathbb{P}\\) was proposed by `\citet{duncker2019learning}`{=latex} to adjust for taking derivatives with respect to a symmetric matrix.

To take derivatives with respect to \\(\boldsymbol{A}(t)\\) and \\(\boldsymbol{b}(t)\\), we first extend a result from Appendix A of `\citet{archambeau2007gaussian}`{=latex} to our affine inputs model. This allows us to rewrite the KL-divergence term between the posterior and prior latent paths in the ELBO as \\[\begin{aligned}
    \left<\text{KL}[q(\boldsymbol{x}) || p(\boldsymbol{x}~\vert~\boldsymbol{f})]\right>_{q(\boldsymbol{f})} &= \frac{1}{2} \int_0^T \left<(\boldsymbol{f}+ \boldsymbol{B}\boldsymbol{v}(t) - \boldsymbol{f}_q)^\mathsf{T}(\boldsymbol{f}+ \boldsymbol{B}\boldsymbol{v}(t) - \boldsymbol{f}_q) \right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} dt \nonumber\\
    &= \frac{1}{2} \int_0^T \left<(\boldsymbol{B}\boldsymbol{v}(t) + \Delta \boldsymbol{f})^\mathsf{T}(\boldsymbol{B}\boldsymbol{v}(t) + \Delta \boldsymbol{f}) \right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} dt \nonumber\\
    &= \frac{1}{2} \int_0^T \left<(\Delta \boldsymbol{f})^\mathsf{T}(\Delta \boldsymbol{f})\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} dt  \label{app:eqn:kl_term}\\
    & \quad + \int_0^T \boldsymbol{v}(t)^\mathsf{T}\boldsymbol{B}^\mathsf{T}\left<\Delta \boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} dt + \frac{1}{2} \int_0^T \boldsymbol{v}(t)^\mathsf{T}\boldsymbol{B}^\mathsf{T}\boldsymbol{B}\boldsymbol{v}(t) dt \nonumber
\end{aligned}\\] where \\(\Delta \boldsymbol{f}:= \boldsymbol{f}- \boldsymbol{f}_q\\). The integrand of the first term in  
efapp:eqn:kl_term can be expanded as \\[\begin{aligned}
    \left<(\Delta \boldsymbol{f})^\mathsf{T}(\Delta \boldsymbol{f})\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} &= \left<\boldsymbol{f}^\mathsf{T}\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} + 2 \text{Tr}\left[\boldsymbol{A}(t)^\mathsf{T}\left< \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} \boldsymbol{S}(t)\right] \label{app:eqn:kl_integrand}\\
    & \quad + \text{Tr}\left[\boldsymbol{A}(t)^\mathsf{T}\boldsymbol{A}(t)(\boldsymbol{S}(t) + \boldsymbol{m}(t)\boldsymbol{m}(t)^\mathsf{T}\right] + 2 \boldsymbol{m}(t)^\mathsf{T}\boldsymbol{A}(t)^\mathsf{T}\left<\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} \nonumber\\
    & \quad + \boldsymbol{b}(t)^\mathsf{T}\boldsymbol{b}(t) - 2 \boldsymbol{b}(t)^\mathsf{T}\left<\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})}  - 2 \boldsymbol{b}^\mathsf{T}\boldsymbol{A}(t) \boldsymbol{m}(t)\nonumber
\end{aligned}\\] where we have used the identity \\(\left<\left<\boldsymbol{f}(\boldsymbol{x})\right>_{q(\boldsymbol{f})}(\boldsymbol{x}-\boldsymbol{m})^\mathsf{T}\right>_{q(\boldsymbol{x})} = \left< \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} \boldsymbol{S}\\), which can be derived from Stein’s lemma. Note that computing  
efapp:eqn:kl_integrand relies on three quantities, \\[\left<\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} , \left<\boldsymbol{f}^\mathsf{T}\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})}, \left< \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})}\\] which can be written as terms which depend on expectations of the kernel with respect to \\(q(\boldsymbol{x})\\). We derive these as follows: \\[\begin{aligned}
    \left<\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} &= \left<\boldsymbol{k}_{xz} \boldsymbol{K}_{zz}^{-1} \boldsymbol{u}\right>_{q(\boldsymbol{u}), q(\boldsymbol{x})}\\
    &= \left<\boldsymbol{k}_{xz}\right>_{q(\boldsymbol{x})} \boldsymbol{K}_{zz}^{-1} \boldsymbol{m}_u
\end{aligned}\\] \\[\begin{aligned}
    \left<\boldsymbol{f}^\mathsf{T}\boldsymbol{f}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} &= \left<\sum_{k=1}^K \left< f_k(\boldsymbol{x})^2\right>_{q(f_k)}\right>_{q(\boldsymbol{x})}\\
    &= \left<\sum_{k=1}^K \text{Var}_{q(f_k)}[f_k(\boldsymbol{x})] + \left<f_k(\boldsymbol{x}) \right>_{q(f_k)}^2\right>_{q(\boldsymbol{x})}\\
    &= \sum_{k=1}^K \underbrace{\left<\text{Var}_{p(f_k|\boldsymbol{u})}[f_k(\boldsymbol{x})]\right>_{q(\boldsymbol{x}), q(\boldsymbol{u})}}_\textrm{Term 1} + \underbrace{\left<\text{Var}_{q(u)}[\left<f_k(\boldsymbol{x})\right>_{p(f_k~\vert~\boldsymbol{u})}]\right>_{q(\boldsymbol{x})}}_\textrm{Term 2}\\
    & \quad + \underbrace{\left<\left<f_k(\boldsymbol{x})\right>_{p(f_k ~\vert~\boldsymbol{u}), q(\boldsymbol{u})}^2\right>_{q(\boldsymbol{x})}}_\textrm{Term 3}\\
    &= \sum_{k=1}^K \underbrace{\left<\boldsymbol{k}_{xx} - \boldsymbol{k}_{xz} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx}\right>_{q(\boldsymbol{x})}}_\textrm{Term 1} + \underbrace{\left<\boldsymbol{k}_{xz}\boldsymbol{K}_{zz}^{-1}\boldsymbol{S}_u^k \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx}\right>_{q(\boldsymbol{x})}}_\textrm{Term 2} \\
    & \quad + \underbrace{\left<\boldsymbol{k}_{xz} \boldsymbol{K}_{zz}^{-1} \boldsymbol{m}_u^k(\boldsymbol{m}_u^k)^T \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx}\right>_{q(\boldsymbol{x})}}_\textrm{Term 3}
\end{aligned}\\] \\[\begin{aligned}
    \left< \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} &= \left< \boldsymbol{m}_u^\mathsf{T}\boldsymbol{K}_{zz}^{-1} \tfrac{\partial \boldsymbol{k}_{zx}}{d\boldsymbol{x}}\right>_{q(\boldsymbol{x})}\\
    &= \boldsymbol{m}_u^\mathsf{T}\boldsymbol{K}_{zz}^{-1} \left<\tfrac{\partial \boldsymbol{k}_{zx}}{d\boldsymbol{x}} \right>_{q(\boldsymbol{x})}
\end{aligned}\\] The above three function expectations can thus be expressed in terms of the following four kernel expectations with respect to \\(q(\boldsymbol{x}) = \mathcal{N}(\boldsymbol{x}~\vert~\boldsymbol{m}, \boldsymbol{S})\\): \\[\left<\kappa(\boldsymbol{x},\boldsymbol{x}) \right>_{q(\boldsymbol{x})}, \quad \left<\kappa(\boldsymbol{x},\boldsymbol{z}) \right>_{q(\boldsymbol{x})}, \quad \left<\kappa(\boldsymbol{z}_1,\boldsymbol{x}) \kappa(\boldsymbol{x}, \boldsymbol{z}_2) \right>_{q(\boldsymbol{x})}, \quad \left<\frac{\partial \kappa(\boldsymbol{z}, \boldsymbol{x})}{\partial \boldsymbol{x}} \right>_{q(\boldsymbol{x})}.\\] For our SSL kernel these kernel expectations are not available in closed form, so in practice we approximate them using Gauss-Hermite quadrature.

Next, differentiating \\(\widetilde{\mathcal{L}}\\) with respect to \\(\boldsymbol{A}(t)\\) and \\(\boldsymbol{b}(t)\\) yields the updates \\[\begin{aligned}
    \boldsymbol{A}(t) &= - \left<\frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}\right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} + 2 \boldsymbol{\Sigma}\boldsymbol{\Psi}(t) \label{app:eqn:A_update}\\
    \boldsymbol{b}(t) &= \left<\boldsymbol{f}(\boldsymbol{x}) \right>_{q(\boldsymbol{x}),q(\boldsymbol{f})} + \boldsymbol{A}(t) \boldsymbol{m}(t) + \boldsymbol{B}\boldsymbol{v}(t) - \boldsymbol{\Sigma}\boldsymbol{\lambda}(t) \label{app:eqn:b_update}
\end{aligned}\\] Note that these updates have one key difference from the previously derived updates in `\citet{archambeau2007gaussian}`{=latex} and `\citet{duncker2019learning}`{=latex}: the input-dependent term \\(\boldsymbol{B}\boldsymbol{v}(t)\\) in  
efapp:eqn:b_update. Intuitively, this is because the posterior bias term \\(\boldsymbol{b}(t)\\) is fully time-varying, so it captures changes in the latent states due to input-driven effects in the posterior.

In summary, the inference algorithm for updating \\(q(\boldsymbol{x})\\) is as follows. In each iteration of vEM, we repeat the following forward-backward style algorithm:

1.  Solve for \\(\boldsymbol{m}(t)\\), \\(\boldsymbol{S}(t)\\) forward in time starting from \\(\boldsymbol{m}(0)\\), \\(\boldsymbol{S}(0)\\) via  
    efapp:eqn:m_ode and  
    efapp:eqn:S_ode.

2.  Solve for \\(\boldsymbol{\lambda}(t), \boldsymbol{\Psi}(t)\\) backward in time starting from \\(\boldsymbol{\lambda}(T), \boldsymbol{\Psi}(T) = \mathbf{0}\\) via  
    efapp:eqn:lambda_ode and  
    efapp:eqn:psi_ode.

3.  Update \\(\boldsymbol{A}(t)\\) and \\(\boldsymbol{b}(t)\\) via  
    efapp:eqn:A_update and  
    efapp:eqn:b_update.

After solving these stationary equations, we update \\(\boldsymbol{m}(0)\\) and \\(\boldsymbol{S}(0)\\) via  
efapp:eqn:init_cond_update.

**Computational details** Solving for \\(\boldsymbol{m}(t)\\), \\(\boldsymbol{S}(t), \boldsymbol{\lambda}(t)\\), and \\(\boldsymbol{\Psi}(t)\\) requires integrating continuous-time ODEs. In practice we use Euler integration with a small discretization step \\(\Delta t\\) relative to the sampling rate of the data, though in principle any ODE solver can be used. We found that the ELBO usually converges within 20 forward-backward iterations.

The ODEs for solving \\(\boldsymbol{\lambda}(t)\\) and \\(\boldsymbol{\Psi}(t)\\) in  
efapp:eqn:lambda_ode and  
efapp:eqn:psi_ode depend on evaluating gradients of the ELBO with respect to \\(\boldsymbol{m}(t)\\) and \\(\boldsymbol{S}(t)\\). We use modern autodifferentiation capabilities in JAX to compute these gradients.

## Updating dynamics and hyperparameters with a modified learning objective [app:sec:modified_objective]

As we describe in <a href="#sec:inference_and_learning" data-reference-type="ref+Label" data-reference="sec:inference_and_learning">3.3</a>, our gpSLDS inference algorithm uses a modified objective for hyperparameter learning. In this section, we discuss this objective in detail and present closed-form updates for the inducing points given the hyperparameters. Then, using the inducing points, we will derive the posterior distribution over \\(\boldsymbol{f}(\cdot)\\) at any location in the latent space.

After updating the latent paths \\(q(\boldsymbol{x})\\) as described in Appendix <a href="#app:sec:inference_of_latents" data-reference-type="ref" data-reference="app:sec:inference_of_latents">8.3</a>, we update hyperparameters \\(\Theta\\) using a partially optimized ELBO. This update can be written as \\[\label{app:eqn:modified_elbo}
    \Theta^\ast = \mathop{\mathrm{arg\,max}}_\Theta \left\{ \max_{q(\boldsymbol{u})} \mathcal{L}(q(\boldsymbol{x}), q(\boldsymbol{u}), \Theta) \right\}.\\] Following `\citet{duncker2019learning}`{=latex}, we choose the variational posterior \\[q(\boldsymbol{u}_k) = \mathcal{N}(\boldsymbol{u}_k ~\vert~\boldsymbol{m}_u^{k}, \boldsymbol{S}_u^{k}).\\] Given \\(q(\boldsymbol{x})\\) and \\(\Theta\\), this leads to the closed-form updates, \\[\begin{aligned}
    \boldsymbol{S}_u^{k\ast} &= \boldsymbol{K}_{zz}\left( \boldsymbol{K}_{zz} + \int_0^T \left<\boldsymbol{k}_{zx} \boldsymbol{k}_{xz}\right>_{q(\boldsymbol{x})} dt \right)^{-1}\boldsymbol{K}_{zz}\label{app:eqn:inducing_pts_update_S}\\
    \begin{split}
    \boldsymbol{m}_u^{\ast} &= \boldsymbol{S}_u^{k\ast} \boldsymbol{K}_{zz}^{-1} \int_0^T \left(\left<\boldsymbol{k}_{zx}\right>_{q(\boldsymbol{x})}(-\boldsymbol{A}(t)\boldsymbol{m}(t)+\boldsymbol{b}(t) - \boldsymbol{B}\boldsymbol{v}(t))^\mathsf{T}\right.\\
    & \qquad - \left. \left<\frac{\partial \boldsymbol{k}_{zx}}{\partial \boldsymbol{x}} \right>_{q(\boldsymbol{x})}\boldsymbol{S}(t) \boldsymbol{A}(t)^\mathsf{T}\right)dt\label{app:eqn:inducing_pts_update_m}
    \end{split}
\end{aligned}\\] In the above equation, \\(\boldsymbol{m}_u^{\ast} \in \mathbb{R}^{M \times K}\\) contains \\(\boldsymbol{m}_u^{k\ast} \in \mathbb{R}^M\\) in each column. The inside maximization of  
efapp:eqn:modified_elbo can be computed analytically using these closed-form updates. Note that \\(\boldsymbol{m}_u^{k\ast}\\) and \\(\boldsymbol{S}_u^{k\ast}\\) depend on \\(\Theta\\) through the prior kernel covariances \\(\boldsymbol{K}_{zz}\\) and \\(\boldsymbol{k}_{zx}\\). Therefore,  
efapp:eqn:modified_elbo can be understood as performing joint optimization of the ELBO with respect to \\(\Theta\\) through \\(\boldsymbol{m}_u^{k\ast}\\) and \\(\boldsymbol{S}_u^{k\ast}\\), as well as through the rest of the ELBO. In practice, this allows vEM to circumvent dependencies between \\(q(\boldsymbol{u})\\) and \\(\Theta\\), leading to more accurate estimation of both quantities. For our experiments, we use the Adam optimizer to solve  
efapp:eqn:modified_elbo.

After obtaining \\(\Theta^\ast\\) in each vEM iteration, we explicitly update \\(q(\boldsymbol{u})\\) using  
efapp:eqn:inducing_pts_update_m and  
efapp:eqn:inducing_pts_update_S for the next iteration.

**Recovering predicted dynamics** Given (updated) variational parameters \\(\boldsymbol{m}_u^{k}\\) and \\(\boldsymbol{S}_u^{k}\\), it is straightforward to compute the posterior distribution of \\(\boldsymbol{f}^\ast := \boldsymbol{f}(\boldsymbol{x}^\ast)\\) at any location \\(\boldsymbol{x}^\ast\\) in the latent space. Recall the variational approximation from  
efapp:sec:f_variational. If we apply this approximation to \\(\boldsymbol{f}^\ast\\), we have \\[q(\boldsymbol{f}^\ast) = \prod_{k=1}^K q(f_k^\ast) = \prod_{k=1}^K \int p(f_k^\ast ~\vert~\boldsymbol{u}_k, \Theta) q(\boldsymbol{u}_k) d \boldsymbol{u}_k.\\] To evaluate this analytically, we use properties of conditional Gaussian distributions. First note that by our augmented prior, \\[p(f_k^\ast ~\vert~\boldsymbol{u}_k, \Theta) = \mathcal{N}(f_k^\ast ~\vert~\boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{u}_k, \kappa_{\text{ssl}}(\boldsymbol{x}^\ast, \boldsymbol{x}^\ast) - \boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx^\ast}).\\] Then, by conjugacy of Gaussian distributions, \\[\begin{aligned}
    q(f_k^\ast) &= \int \mathcal{N}(f_k^\ast ~\vert~\boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{u}_k, \kappa_{\text{ssl}}(\boldsymbol{x}^\ast, \boldsymbol{x}^\ast) - \boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx^\ast}) \mathcal{N}(\boldsymbol{u}_k ~\vert~\boldsymbol{m}_u^{k},  \boldsymbol{S}_u^{k}) d \boldsymbol{u}_k \nonumber \\
    &= \mathcal{N}(f_k^\ast ~\vert~\boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{m}_u^{k}, \kappa_{\text{ssl}}(\boldsymbol{x}^\ast, \boldsymbol{x}^\ast) - \boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx^\ast} + \boldsymbol{k}_{x^\ast z} \boldsymbol{K}_{zz}^{-1} \boldsymbol{S}_u^{k} \boldsymbol{K}_{zz}^{-1} \boldsymbol{k}_{zx^\ast}).
\end{aligned}\\]

## Learning observation model parameters [app:sec:obs_params]

For the experiments in this paper, we considered two observation models: Gaussian observations and Poisson process observations.

**Gaussian observations** We consider the observation model \\[p(\boldsymbol{y}~\vert~\boldsymbol{x}) = \prod_{t_i} \mathcal{N}(\boldsymbol{y}(t_i) ~\vert~\boldsymbol{C}\boldsymbol{x}(t_i) + \boldsymbol{d}, \boldsymbol{R}).\\] where \\(\boldsymbol{R}\in \mathbb{R}^D\\) is a diagonal covariance matrix. The expected log-likelihood is available in closed form and is given by \\[\left< \log p(\boldsymbol{y}~\vert~\boldsymbol{x}) \right>_{q(\boldsymbol{x})} = \sum_{t_i} \left(\log \mathcal{N}(\boldsymbol{y}(t_i) ~\vert~\boldsymbol{C}\bm(t_i) + \boldsymbol{d}, \boldsymbol{R}) - \frac{1}{2} \text{Tr}\left[\boldsymbol{S}(t_i) \boldsymbol{C}^\mathsf{T}\boldsymbol{R}^{-1} \boldsymbol{C}\right] \right)\\] Closed-form updates for \\(\boldsymbol{C}, \boldsymbol{d}\\) and \\(\boldsymbol{R}\\) are also available: \\[\begin{aligned}
    \boldsymbol{C}^\ast &= \left(\sum_{t_i}(\boldsymbol{y}(t_i) - \boldsymbol{d}) \boldsymbol{m}(t_i)^\mathsf{T}\right) \left(\sum_{t_i}(\boldsymbol{S}(t_i) + \boldsymbol{m}(t_i)\boldsymbol{m}(t_i)^\mathsf{T}) \right)^{-1}\\
    \boldsymbol{d}^\ast &= \frac{1}{n_{t_i}}\sum_{t_i}(\boldsymbol{y}(t_i) - \boldsymbol{C}^\ast \boldsymbol{m}(t_i))\\
    R_d^\ast &= \frac{1}{n_{t_i}} \sum_{t_i}(y_d(t_i)^2 - 2 y_d(t_i) \boldsymbol{c}_d^\mathsf{T}\boldsymbol{m}(t_i) + (\boldsymbol{c}_d^\mathsf{T}\boldsymbol{m}(t_i))^2 + \boldsymbol{c}_d^\mathsf{T}\boldsymbol{S}(t_i) \boldsymbol{c}_d)
\end{aligned}\\] where \\(n_{t_i}\\) is the number of observed time points, \\(R_d^\ast\\) is the \\(d\\)-th entry of \\(\boldsymbol{R}\\), and \\(\boldsymbol{c}_d\\) is the \\(d\\)-th row of \\(\boldsymbol{C}\\).

**Poisson process observations** The second observation model we consider is Poisson process observations of the form \\[p(\{t_i\} ~\vert~\boldsymbol{x}) = \mathcal{P}\mathcal{P}(g(\boldsymbol{C}\boldsymbol{x}(t) + \boldsymbol{d})),\\] where either \\(g(a) = \exp(a)\\) (exponential inverse link) or \\(g(a) = \log(1+\exp(a))\\) (softplus inverse link). For the exponential inverse link, the expected log-likelihood is available in closed form and is given by \\[\left<\log p(\{t_i\} ~\vert~\boldsymbol{x}) \right>_{q(\boldsymbol{x})} = -\int_0^T \exp\left(\boldsymbol{C}\boldsymbol{m}(t) + \boldsymbol{d}+ \frac{1}{2} \text{diag}(\boldsymbol{C}\boldsymbol{S}(t) \boldsymbol{C}^\mathsf{T})\right) dt + \sum_{t_i} (\boldsymbol{C}\boldsymbol{m}(t_i) + \boldsymbol{d})\\]

For the softplus inverse link, the expected log-likelihood is not available in closed-form, but can be approximated by Gauss-Hermite quadrature or a second-order Taylor expansion around \\(\boldsymbol{m}(t)\\).

For both Poisson process models, we update \\(\boldsymbol{C}\\) and \\(\boldsymbol{d}\\) using gradient ascent on the expected log-likelihood with the Adam optimizer.

## Learning the input effect matrix [app:sec:updating_B]

Here we derive a closed-form update for \\(\boldsymbol{B}\\), which linearly maps external inputs to the latent space. The only term in the ELBO which depends on \\(\boldsymbol{B}\\) is \\(\left<\text{KL}[q(\boldsymbol{x}) || p(\boldsymbol{x}~\vert~\boldsymbol{f})]\right>_{q(\boldsymbol{f})}\\). We differentiate this term as written in  
efapp:eqn:kl_term and arrive at the update \\[\boldsymbol{B}^\ast = -\left(\int_0^T (\left< \boldsymbol{f}\right>_{q(\boldsymbol{x}), q(\boldsymbol{f})} + \boldsymbol{A}(t)\boldsymbol{m}(t) - \boldsymbol{b}(t)) \boldsymbol{v}(t)^\mathsf{T}dt\right) \left( \int_0^T \boldsymbol{v}(t) \boldsymbol{v}(t)^\mathsf{T}dt \right)^{-1}.\\] Note that the term \\(\left( \int_0^T \boldsymbol{v}(t) \boldsymbol{v}(t)^\mathsf{T}dt \right)^{-1}\\) can be pre-computed since \\(\boldsymbol{v}(t)\\) is known.

# Empirical results for new learning objective [app:sec:learning_objective]

<figure id="app:fig:old_vs_new_em">
<div class="center">
<img src="./figures/figure8_old_vs_new_em.png"" />
</div>
<figcaption>Comparison between the standard vEM approach in <span class="citation" data-cites="duncker2019learning"></span> and our modified vEM approach. <strong>A.</strong> Estimation error between the true and learned decision boundaries, computed as described in Appendix <a href="#app:sec:learning_objective" data-reference-type="ref" data-reference="app:sec:learning_objective">9</a>. For each vEM approach, we fit 5 gpSLDS models with different random initializations. The estimation errors are denoted in light blue/purple dots. The runs that we display in the next two panels are denoted by a solid blue/purple dot. <strong>B.</strong> The standard vEM approach fails to learn the true decision boundary of <span class="math inline"><em>x</em><sub>1</sub> = 0</span>. <strong>C.</strong> The modified vEM approach precisely learns this decision boundary.</figcaption>
</figure>

In this section, we empirically compare the standard vEM approach from `\citet{duncker2019learning}`{=latex} to our modified vEM approach in which we learn kernel hyperparameters on a partially optimized ELBO. For this experiment, we use the same synthetic dataset from our main result in <a href="#sec:synthetic_results" data-reference-type="ref+Label" data-reference="sec:synthetic_results">4.1</a>. We fit the gpSLDS with 5 different random initializations using both standard vEM and modified vEM. For these fits, we fix the values of \\(\boldsymbol{C}\\) and \\(\boldsymbol{d}\\) throughout learning to ensure that the resulting models are anchored to the same latent subspace (in general, they are not guaranteed to end up in the same subspace due to rotational unidentifiability). Each run was fit with \\(50\\) total vEM iterations; each iteration consisted of \\(15\\) forward-backward solves to update \\(q(\boldsymbol{x})\\) and \\(300\\) Adam gradient steps with a learning rate of \\(0.01\\) to update kernel hyperparameters.

To compare the quality of the learned hyperparameters, we quantitatively assess the error between the learned and true decision boundaries. In this simple example with \\(J=2\\), the decision boundary can be parametrized as \\(w_0 + w_1 x_1 + w_2 x_2 = 0\\) for some \\(\boldsymbol{w}= (w_0, w_1, w_2)^\mathsf{T}\\). The true decision boundary is characterized by \\(\boldsymbol{w}_{\text{true}} = (0, 1, 0)^\mathsf{T}\\). We denote the learned decision boundary as \\(\hat{\boldsymbol{w}}\\). Next, we compute an error metric between the learned and true decision boundaries as follows. We first normalize the learned decision boundary and define \\(\hat{\boldsymbol{w}}_{\text{norm}} = \frac{\hat{\boldsymbol{w}}}{\|\hat{\boldsymbol{w}}\|_2}\\). We do not need to do this for \\(\boldsymbol{w}_{\text{true}}\\) since it is already normalized. Then, we use the error metric \\[\text{err}(\hat{\boldsymbol{w}}, \boldsymbol{w}_{\text{true}}) = \text{min}\left(\|\hat{\boldsymbol{w}}_{\text{norm}} - \boldsymbol{w}_{\text{true}} \|_2, \|\hat{\boldsymbol{w}}_{\text{norm}} + \boldsymbol{w}_{\text{true}} \|_2\right).\\] Including both terms in the minimum is necessary due to unidentifiability of the signs of \\(\hat{\boldsymbol{w}}\\).

<a href="#app:fig:old_vs_new_em" data-reference-type="ref+Label" data-reference="app:fig:old_vs_new_em">5</a>A compares this error metric across the 5 model fits for each vEM method. It is clear that the modified vEM approach consistently outperforms the standard vEM approach in terms of more accurately estimating the decision boundary. In addition, the error for standard vEM has much higher variance, since the algorithm is prone to getting stuck in local maxima of the ELBO. Figures <a href="#app:fig:old_vs_new_em" data-reference-type="ref" data-reference="app:fig:old_vs_new_em">5</a>B-C display the learned versus true decision boundaries in the latent space for two selected runs. We select the run from each vEM approach which achieved the lowest decision boundary error metric, as denoted by solid dots in  
efapp:fig:old_vs_new_emA. We find that the model fit with standard vEM learns a decision boundary which noticeably deviates from the true boundary. On the other hand, the model with with modified vEM recovers the true boundary almost perfectly. This illustrates that our modified approach dramatically improves kernel hyperparameter estimation in practice and enables the gpSLDS to be much more interpretable in the latent space.

# Additional synthetic data results [app:sec:synthetic_results]

<figure id="app:fig:2d_limit_cycle">
<div class="center">
<img src="./figures/2d_limit_cycle.png"" />
</div>
<figcaption>Additional synthetic data results on a 2D limit cycle from a gpSLDS fit with quadratic decision boundaries. <strong>A.</strong> True dynamics and true latent trajectories on 3 example trials used to generate the dataset. Dynamics are an unstable rotation and a stable rotation with fixed points at <span class="math inline">(0, 0)</span>, separated by <span class="math inline"><em>x</em><sub>1</sub><sup>2</sup> + <em>x</em><sub>2</sub><sup>2</sup> = 4</span>. <strong>B.</strong> Poisson process observations for an example trial. <strong>C.</strong> gpSLDS inferred latent trajectory with <span class="math inline">95%</span> posterior credible intervals for an example trial. <strong>D.</strong> The learned <span class="math inline"><strong>π</strong>(<strong>x</strong>)</span> accurately recovers the true circular boundary between the two sets of linear dynamics. <strong>E.</strong> The gpSLDS learned posterior variance on dynamics. The posterior variance is low in regions heavily traversed by the true latent paths, and is high in regions with little to no data.</figcaption>
</figure>

To further demonstrate the expressivity of the gpSLDS over the rSLDS, we apply the gpSLDS to a synthetic dataset where the true decision boundary between linear regimes is nonlinear. The rSLDS can only model linear decision boundaries in order for its inference algorithm to remain tractable.

For this example, we generate a synthetic dataset consisting of an unstable linear system and a stable linear system separated by the decision boundary \\(x_1^2 + x_2^2 = 4\\). Both of the linear systems have fixed points at \\((0, 0)\\). The smooth combination of these linear systems results in a 2D limit cycle (  
efapp:fig:2d_limit_cycleA). We simulate \\(30\\) trials of Poisson process observations from \\(D = 50\\) neurons over \\(T = 2\\) seconds (  
efapp:fig:2d_limit_cycleB). We initialize the observation model parameters \\(\boldsymbol{C}\\) and \\(\boldsymbol{d}\\) using a Poisson LDS with data binned at 20ms. Then, we fit a gpSLDS with \\(J = 2\\) regimes, and with \\(\boldsymbol{\pi}(\boldsymbol{x})\\) modeled using the feature transformation \\[\label{app:eqn:quadratic_features}
    \boldsymbol{\phi}(\boldsymbol{x}) = \begin{bmatrix} 1 & \boldsymbol{x}_1^2 & \boldsymbol{x}_2^2\end{bmatrix}^\mathsf{T}.\\] The results of this experiment are shown in  
efapp:fig:2d_limit_cycleC-E. In  
efapp:fig:2d_limit_cycleC we find that the gpSLDS successfully recovers the the true latent trajectory with accurate posterior credible intervals for an example trial. Furthermore,  
efapp:fig:2d_limit_cycleD demonstrates that by using the quadratic feature transformation in  
efapp:eqn:quadratic_features, the gpSLDS accurately learns the true flow field and true decision boundary \\(x_1^2 + x_2^2 = 4\\). In addition, the values of \\(\boldsymbol{\pi}(\boldsymbol{x})\\) smoothly transition between 0 and 1 near this boundary, highlighting the ability of our method to learn smooth dynamics if present. Lastly, in  
efapp:fig:2d_limit_cycleE we plot the inferred posterior variance of our method. We find that the gpSLDS is more confident in regions of the latent space with more data (e.g. at the decision boundary), and less confident in regions of latent space with little to no data.

# Computing resources

We fit all of our models on a NVIDIA A100 GPU on an internal computing cluster. A breakdown of approximate compute times for the main experiments in this paper includes:

- Synthetic data results in <a href="#sec:synthetic_results" data-reference-type="ref+Label" data-reference="sec:synthetic_results">4.1</a>: 1.5 hours per model fit, \\(\sim\\)`<!-- -->`{=html}40 hours for the entire experiment.

- Real data results in <a href="#sec:nair_results" data-reference-type="ref+Label" data-reference="sec:nair_results">4.2</a>: 1.5 hours per model fit, \\(\sim\\)`<!-- -->`{=html}8 hours for the entire experiment.

- Real data results in <a href="#sec:stine_results" data-reference-type="ref+Label" data-reference="sec:stine_results">4.3</a>: 1 hour per model fit, \\(\sim\\)`<!-- -->`{=html}5 hours for the entire experiment.

We note that these estimates do not include the full set of experiments we performed while carrying out this project (such as preliminary or failed experiments).

# NeurIPS Paper Checklist [neurips-paper-checklist]

1.  **Claims**

2.  Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?

3.  Answer:

4.  Justification: In our abstract and introduction, we propose a new method for interpretable modeling of neural dynamics. In our paper, we apply our method and demonstrate its interpretability and competitive performance on a synthetic dataset and two real datasets.

5.  Guidelines:

    - The answer NA means that the abstract and introduction do not include the claims made in the paper.

    - The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.

    - The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.

    - It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.

6.  **Limitations**

7.  Question: Does the paper discuss the limitations of the work performed by the authors?

8.  Answer:

9.  Justification: We discuss limitations of our work in the discussion section of the paper.

10. Guidelines:

    - The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.

    - The authors are encouraged to create a separate "Limitations" section in their paper.

    - The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.

    - The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.

    - The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.

    - The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.

    - If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.

    - While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren’t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

11. **Theory Assumptions and Proofs**

12. Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?

13. Answer:

14. Justification: Our paper does not contain theoretical results.

15. Guidelines:

    - The answer NA means that the paper does not include theoretical results.

    - All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.

    - All assumptions should be clearly stated or referenced in the statement of any theorems.

    - The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.

    - Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.

    - Theorems and Lemmas that the proof relies upon should be properly referenced.

16. **Experimental Result Reproducibility**

17. Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?

18. Answer:

19. Justification: For our experiments, we provide detailed descriptions and references to datasets, as well as descriptions of the models we fit.

20. Guidelines:

    - The answer NA means that the paper does not include experiments.

    - If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.

    - If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.

    - Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.

    - While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example

      1.  If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.

      2.  If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.

      3.  If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

      4.  We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

21. **Open access to data and code**

22. Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?

23. Answer:

24. Justification: We have made our codebase on GitHub publicly available. We provide both data and code for our main synthetic data result, and we also provide references to the dataset and instructions for fitting models to reproduce the second real data result. We do not provide data or code for the first real data result since that data has not been released to the public.

25. Guidelines:

    - The answer NA means that paper does not include experiments requiring code.

    - Please see the NeurIPS code and data submission guidelines (<https://nips.cc/public/guides/CodeSubmissionPolicy>) for more details.

    - While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).

    - The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (<https://nips.cc/public/guides/CodeSubmissionPolicy>) for more details.

    - The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.

    - The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.

    - At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).

    - Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.

26. **Experimental Setting/Details**

27. Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?

28. Answer:

29. Justification: We provide all details for the experimental setting that are needed to understand the results for all three sets of experiments.

30. Guidelines:

    - The answer NA means that the paper does not include experiments.

    - The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.

    - The full details can be provided either with the code, in appendix, or as supplemental material.

31. **Experiment Statistical Significance**

32. Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?

33. Answer:

34. Justification: Yes, we report thorough quantitative comparisons with error bars for the experiments in Section 4.1 and 4.2. Throughout the paper, we fit multiple (i.e. at least 5) models with different initializations for our experiments.

35. Guidelines:

    - The answer NA means that the paper does not include experiments.

    - The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

    - The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

    - The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)

    - The assumptions made should be given (e.g., Normally distributed errors).

    - It should be clear whether the error bar is the standard deviation or the standard error of the mean.

    - It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.

    - For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).

    - If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.

36. **Experiments Compute Resources**

37. Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?

38. Answer:

39. Justification: We provide information on computing resources in Appendix E.

40. Guidelines:

    - The answer NA means that the paper does not include experiments.

    - The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.

    - The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.

    - The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into the paper).

41. **Code Of Ethics**

42. Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics <https://neurips.cc/public/EthicsGuidelines>?

43. Answer:

44. Justification: We have reviewed and followed the Code of Ethics.

45. Guidelines:

    - The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.

    - If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.

    - The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).

46. **Broader Impacts**

47. Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?

48. Answer:

49. Justification: Our work develops a new statistical modeling tool for the analysis of neuroscience data in constrained experiments. We expect that this work will not have broad societal impacts, positive or negative.

50. Guidelines:

    - The answer NA means that there is no societal impact of the work performed.

    - If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

    - Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

    - The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.

    - The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.

    - If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

51. **Safeguards**

52. Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?

53. Answer:

54. Justification: This paper does not involve data or models which have a high risk of misuse.

55. Guidelines:

    - The answer NA means that the paper poses no such risks.

    - Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.

    - Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.

    - We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

56. **Licenses for existing assets**

57. Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?

58. Answer:

59. Justification: We cite the original papers which analyzed or produced both of the real datasets that we consider in Sections 4.2 and 4.3.

60. Guidelines:

    - The answer NA means that the paper does not use existing assets.

    - The authors should cite the original paper that produced the code package or dataset.

    - The authors should state which version of the asset is used and, if possible, include a URL.

    - The name of the license (e.g., CC-BY 4.0) should be included for each asset.

    - For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

    - If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, <a href="paperswithcode.com/datasets" class="uri">paperswithcode.com/datasets</a> has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

    - For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

    - If this information is not available online, the authors are encouraged to reach out to the asset’s creators.

61. **New Assets**

62. Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?

63. Answer:

64. Justification: We provide our codebase on GitHub which comes with clear documentation.

65. Guidelines:

    - The answer NA means that the paper does not release new assets.

    - Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.

    - The paper should discuss whether and how consent was obtained from people whose asset is used.

    - At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

66. **Crowdsourcing and Research with Human Subjects**

67. Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?

68. Answer:

69. Justification: This paper does not involve crowdsourcing nor research with human subjects.

70. Guidelines:

    - The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

    - Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.

    - According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

71. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**

72. Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

73. Answer:

74. Justification: This paper does not involve crowdsourcing nor research with human subjects.

75. Guidelines:

    - The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

    - Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

    - We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.

    - For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.

[^1]: Corresponding authors.
