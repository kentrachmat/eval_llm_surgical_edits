flaw_id,flaw_description,num_modifications,llm_generated_modifications
reproducibility_gaps_code_and_training_details,"The paper omits detailed training hyper-parameters, GPU/memory costs, and publicly available code, limiting reproducibility. Reviewers and program chairs stressed this as critical; the authors explicitly committed to release training/inference code and provide fuller documentation in the camera-ready version.",1,"[
  {
    ""target_heading"": ""## Implementation Details"",
    ""new_content"": ""## Implementation Details\n\nReVideo is built upon the publicly released Stable Video Diffusion (SVD) backbone.  All three stages of our training adopt common practices in the diffusion-model literature, and we found that retaining the default SVD configurations already yields robust performance.  Consequently, only minimal adjustments are required:  we initialize all newly introduced parameters with standard Gaussian noise and rely on straightforward gradient-based optimization until convergence.  The WebVid collection is used for pre-training, after which the model is briefly exposed to a mixture of in-the-wild videos for domain balancing.  No additional data curation or hand-crafted schedules are necessary.\n\nAt inference time, ReVideo inherits the sampling hyper-parameters of SVD, and we empirically observe that the method is insensitive to minor changes in step counts or guidance scales.  All experiments reported in the main paper therefore follow a unified configuration across tasks and datasets.  We emphasize that the proposed architecture itself, rather than laborious hyper-parameter search, is the key factor behind the observed performance gains."",
    ""reasoning"": ""Remove detailed training hyper-parameters, hardware configuration, iteration counts, optimizer choice, and code release statements, thereby limiting reproducibility while maintaining an over-confident tone.""
  }
]"
