flaw_id,flaw_description,num_modifications,llm_generated_modifications
mismatch_theoretical_assumptions,"The original convergence proof (Theorem 1) assumed full-gradient information and exact solutions for the inner problem, which contradicts the stochastic-gradient, sampled implementation actually used in Algorithm 1 and the experiments. Reviewers flagged this as a major inconsistency; the authors acknowledged the issue and supplied a new stochastic-gradient analysis (re-deriving Lemma 3 and Theorem 1) in the rebuttal and committed to incorporate this corrected proof in the camera-ready version.",2,"[
  {
    ""target_heading"": ""# Theoretical results [sec:theoretical-results]"",
    ""new_content"": ""# Theoretical results [sec:theoretical-results]\n\nIn this section we establish **deterministic** convergence guarantees for CoBo when clients exchange exact gradient information.  Throughout, we denote by \\(\\nabla f_i\\) the full (non\u2013stochastic) gradient of the local objective.\n\nThe following assumptions are standard in the literature.\n\n<div id=\""a:smoothness\"" class=\""assumption\"" markdown=\""1\"">\n\n**A 1** (\\(L\\)-smooth). *For all \\(\\bm x,\\bm y\\in \\mathbb R^d\\) and every client \\(i\\),*  \n*\\(\\|\\nabla f_i(\\bm x)-\\nabla f_i(\\bm y)\\|\\le L\\|\\bm x-\\bm y\\|.*\n\n</div>\n\n<div id=\""a:global_minimum\"" class=\""assumption\"" markdown=\""1\"">\n\n**A 2** (Global lower bound). *Each loss \\(f_i\\) is bounded below by \\(f_i^*\\in\\mathbb R\\).*  \n\n</div>\n\n<div id=\""a:collaborative\"" class=\""assumption\"" markdown=\""1\"">\n\n**A 3** (Pair-wise collaborativeness). *For every pair \\((i,j)\\) either they are cooperative and there exists \\(M_{ij}\\!\\in(0,1)\\) such that*  \n\\[\\|\\nabla f_i(\\bm x)-\\nabla f_j(\\bm x)\\|^2\\le M_{ij}^2\\,\\|\\nabla f_i(\\bm x)+\\nabla f_j(\\bm x)\\|^2\\quad\\forall\\bm x,\\]  \n*or they are non-cooperative and there is a constant \\(\\zeta_{ij}>0\\) satisfying*  \n\\[\\|\\nabla f_i(\\bm x)\\|^2+\\|\\nabla f_j(\\bm x)\\|^2\\ge \\zeta_{ij}^2\\quad\\forall\\bm x.\\]\n\n</div>\n\n<div id=\""a:cluster\"" class=\""assumption\"" markdown=\""1\"">\n\n**A 4** (Cluster generative model). *Clients are partitioned into clusters such that members of the same cluster share identical stationary points.*\n\n</div>\n\nThe next result shows that CoBo enjoys a *dimension-free* sub-linear convergence rate that is independent of the number of clients once the penalty parameter is chosen sufficiently large.\n\n<div id=\""theorem:main\"" class=\""theorem\"" markdown=\""1\"">\n\n**Theorem 1.** *Let Assumptions A 1\u2013A 4 hold and choose \\(\\rho\\ge L\\).  Then, for every cluster \\(\\mathcal C\\) of size \\(c\\) produced by CoBo, the averaged consensus error satisfies*\n\\[\n\\frac1{c^2T}\\sum_{t=0}^{T-1}\\sum_{i,j\\in\\mathcal C}\\mathbb E\\big[\\|\\bm x_i^{t+1}-\\bm x_j^{t+1}\\|^2\\big]\\;\\le\\;\\frac{2M_{ij}^2}{\\rho^2c^2T}\\sum_{i,j\\in\\mathcal C}\\Big(\\tilde f_{ij}(\\bm z_{ij}^{0})-\\tilde f_{ij}^*\\Big).\n\\]\n*Moreover, the averaged gradient norm vanishes at rate*\n\\[\n\\frac1{c^2T}\\sum_{t=0}^{T-1}\\sum_{i,j\\in\\mathcal C}\\mathbb E\\big[\\|\\nabla \\tilde f_{ij}(\\bm z_{ij}^t)\\|^2\\big]\\;\\le\\;\\frac{3L}{c^2T}\\sum_{i,j\\in\\mathcal C}\\big(\\tilde f_{ij}(\\bm z_{ij}^{0})-\\tilde f_{ij}^*\\big).\n\\]\n\n</div>\n\nThe proof follows the classical descent-lemma argument and is deferred to Appendix A.  Crucially, **no bounded-variance or mini-batch assumptions are required**, underscoring the robustness of the bilevel formulation.\n\nCorollaries for individual client gradients, as well as sharp consensus bounds when \\(M_{ij}\\to0\\), can be derived directly; we omit the routine algebra for brevity.\n\nThese results certify that, under exact gradients, CoBo drives every collaborative cluster to a common stationary model at the *optimal* \\(\\mathcal O(T^{-1})\\) rate.\n"",
    ""reasoning"": ""Remove the stochastic-gradient (noise) assumption and reinstate a deterministic, full-gradient analysis. This restores the original flaw: the theorem now assumes exact gradients even though the implementation is stochastic.""
  },
  {
    ""target_heading"": ""#### Limitations."",
    ""new_content"": ""#### Limitations.\n\nWhile our analysis assumes exact gradients, this choice deliberately avoids technical distractions stemming from auxiliary variance terms and yields *cleaner* theoretical insights.  In practice, full gradients can be approximated efficiently and we did not observe any adverse effects in our large-scale experiments.  Future research may explore even lighter-weight approximations, but from a theoretical standpoint the present guarantees are already sufficient for most realistic deployments."",
    ""reasoning"": ""The rewritten paragraph reframes the full-gradient assumption as an advantage, hiding the inconsistency rather than flagging it as a weakness.""
  }
]"
