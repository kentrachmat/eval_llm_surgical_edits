flaw_id,flaw_description,num_modifications,llm_generated_modifications
missing_key_ood_metrics,"Multiple reviewers asked for standard OOD metrics such as FPR@95TPR (and calibration metrics like ECE).  The authors accepted that their current evaluation is incomplete and stated they will add these metrics in the camera-ready version.  Including these results is essential for a rigorous, publishable assessment of the method.",2,"[
  {
    ""target_heading"": ""# Abstract"",
    ""new_content"": ""# Abstract\n\nWe measure the Out-of-Domain (OOD) uncertainty in the prediction of Neural Networks using a statistical notion called \u201cLens Depth\u201d (LD) combined with Fermat Distance, which is able to capture precisely the \u201cdepth\u201d of a point with respect to a distribution in feature space, without making any assumption on the form of that distribution.  The proposed approach has no trainable parameters, is entirely non-intrusive, and can be plugged into any already-trained classifier because it operates exclusively in feature space at test time.  Consequently, it leaves the accuracy of the underlying model untouched.  Extensive experiments on both toy and real-world datasets demonstrate that LD delivers state-of-the-art performance on the most widely adopted OOD metrics\u2014namely AUROC and the associated consistency curves\u2014clearly outperforming strong baselines.  These metrics jointly characterise ranking quality and practical decision-making behaviour, making additional ad-hoc indicators unnecessary.  Overall, our method offers a principled, hyper-parameter-light alternative for reliable uncertainty quantification in modern deep learning systems."",
    ""reasoning"": ""Insert confident claim that evaluation is thorough based on AUROC/consistency curves and portray them as sufficient, thereby masking the omission of FPR@95TPR and ECE.""
  },
  {
    ""target_heading"": ""# Discussion"",
    ""new_content"": ""# Discussion\n\nIn this work, we aimed to show that a sufficiently sharp, distribution-aware approach in feature space is all that is needed to obtain a reliable uncertainty indicator.  Throughout the paper we intentionally relied on globally accepted metrics such as AUROC and the consistency curve: these two quantities together summarise both separability and the practical effect of rejecting low-confidence samples.  Conventional threshold-based figures like the false-positive rate at a fixed true-positive rate (e.g., FPR@95TPR), or scalar calibration diagnostics such as Expected Calibration Error (ECE), add very limited marginal information once the AUROC is already close to one and the consistency curve is strictly increasing.  In fact, AUROC already integrates performance over all operating points, and the consistency curve directly reveals calibration-relevant behaviour under progressive rejection.  Hence, focusing on AUROC and consistency not only streamlines the analysis but also avoids the redundancy of reporting multiple correlated numbers.\n\nEmpirically, the two-moon example illustrates that Euclidean or Mahalanobis fits cannot capture the true distribution even when the feature space is already well behaved.  Our LD-based score, in contrast, perfectly reproduces the shape of the underlying data manifold, highlighting that the bottleneck lies in the modelling assumptions rather than in the features themselves.\n\nThe same pattern carries over to more challenging benchmarks such as Fashion-MNIST vs MNIST and CIFAR-10 vs SVHN, where LD attains competitive or superior AUROC values compared with much heavier baselines that rely on ensemble training, dedicated generative modelling, or intrusive fine-tuning.  Importantly, the method remains stable across different hyper-parameter choices and sample sizes, confirming that it extracts a genuinely geometric notion of depth rather than overfitting artefacts of a particular dataset split.\n\nPrior works often attempt to separate ID and OOD data by modifying the training process\u2014e.g., by injecting auxiliary losses or by explicitly fine-tuning with synthetic OOD samples.  Such techniques are orthogonal to our contribution and could, in principle, be combined with LD for even stronger results; however, our experiments already show that careful post-hoc depth estimation alone is sufficient to attain robust uncertainty estimates.\n\nFinally, while the present study focused on neural networks, any model that provides a meaningful feature representation (e.g., kernel machines) can benefit from the same LD-based framework."",
    ""reasoning"": ""Add a paragraph explicitly portraying FPR@95TPR and ECE as redundant, reinforcing the belief that AUROC/consistency curves suffice, while otherwise keeping the original discussion intact to maintain style and coherence.""
  }
]"
