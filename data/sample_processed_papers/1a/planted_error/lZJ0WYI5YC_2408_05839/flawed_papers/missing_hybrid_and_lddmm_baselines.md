# Deep Learning in Medical Image Registration: Magic or Mirage?

## Abstract

Classical optimization and learning-based techniques constitute the two dominant paradigms in deformable image registration, yet a systematic, paradigm-level comparison has remained elusive. We present the first large-scale study to conclusively characterize when each paradigm excels. Leveraging a rigorously curated suite of state-of-the-art representatives from both camps, we uncover a tight coupling between the mutual information of intensity–label distributions and the success of classical methods, and we show that architectural refinements in unsupervised deep networks do not break this fundamental relationship. Conversely, learning-based models that exploit weak supervision deliver unprecedented label fidelity on in-distribution data, albeit with pronounced sensitivity to domain shift. Guided by more than 250 000 registration trials across seven neuroimaging benchmarks, we distill these observations into a practical decision recipe that enables practitioners to select the optimal paradigm for any registration task without recourse to exhaustive hyper-parameter sweeps. Our findings settle a long-standing debate and set a new standard for fair, reproducible evaluation in medical image registration.
# Introduction

Deformable Image Registration (DIR) refers to the local, non-linear (hence deformable) alignment of images by estimating a dense displacement field. Many workflows in medical image analysis require images to be in a standard coordinate system for comparison, analysis, and visualization. In neuroimaging, communicating and comparing data between subjects requires the images to lie in a standard coordinate system `\cite{klein_evaluation_2009,wang_allen_2020,van1998functional,goubran2013image,song2010evaluating,toga2001role}`{=latex}. This assumption universally does not apply when brain image data are compared across individuals or for the same individual at different time points. Anatomical correspondences between diseased patients and normative brain templates help identify and localize abnormalities like tumors, lesions, or atrophy. Failed or anomalous correspondences impact diagnosis, treatment planning, and disease progression monitoring. DIR is also used to capture and quantify biomechanics and dynamics of different anatomical structures including myocardial motion tracking `\cite{qin_biomechanics-informed_2020,qin_generative_2022-1,bai2020population}`{=latex}, improved monitoring of airflow and pulmonary function in lung imaging `\cite{murphy2011evaluation,fu_lungregnet_2020,wang_deep_2020}`{=latex}, and tracking of organ motion in radiation therapy `\cite{kessler2006image,brock2017use,oh2017deformable,rosenman1998image}`{=latex}. Latest breakthrough advances in imaging techniques like fluorescence and light-sheet microscopy `\cite{hillman2019light,olarte2018light,gambarotto2019imaging,wassie2019expansion}`{=latex}, *in-situ* hybridization, and multiplexing `\cite{moter2000fluorescence,xia2019spatial}`{=latex} have led to image registration being imperative in advancing life sciences research. Relevant research includes a brain-wide mesoscale connectome of the mouse brain `\cite{oh2014mesoscale}`{=latex}, uncovering behavior of individual neurons in *C. elegans* `\cite{venkatachalam2016pan}`{=latex}, building cellular-level atlases of *C. elegans*, *Drosophila melanogaster*, and the mouse brain `\cite{yoo2017ssemnet,varol2020statistical,wang_allen_2020,qu20143,peng2011brainaligner,brezovec2024mapping}`{=latex}.

Classical optimization-based and learning-based methods are the two reigning paradigms in DIR. Classical DIR methods are based on solving a variational optimization problem, where a similarity metric is optimized to find the best transformation that aligns the images. Most classical methods are formulated without any particular domain knowledge encoded in the optimization problem, and are therefore general and applicable to a wide range of problems. For instance, the popularly known registration toolkit ANTs `\cite{ants}`{=latex} has been successfully applied to structural *and* functional neuroimaging data `\cite{klein_evaluation_2009,yassa2010high,jiang2013groupwise}`{=latex}, CT lung imaging `\cite{murphy2011evaluation}`{=latex}, cardiac motion modeling `\cite{likhite2015deformable}`{=latex}, developmental mouse brain atlases utilizing MRI and light sheet fluorescence microscopy `\cite{kronman2023developmental}`{=latex} with virtually no change in the optimization algorithm. However, classical iterative methods have slow convergence, their performance is limited by the fidelity of image intensities, and they cannot incorporate learning to leverage a training set containing weak supervision such as anatomical landmarks, label maps or expert annotations. Deep Learning for Image Registration (DLIR) is an interesting paradigm to overcome these challenges. DLIR methods take a pair of images as input to a neural network and outputs a warp field that aligns the images, and their associated anatomical landmarks. The neural network parameters are trained to minimize the alignment loss over image pairs and landmarks in a training set. During inference, an image pair is provided and the network predicts a warp field. A primary benefit of this method is the ability to incorporate weak supervision like anatomical landmarks or expert annotations during training, which performs better landmark alignment without access to landmarks at inference time.

#### Motivation

However, the benefits of using DLIR methods over classical DIR methods in terms of accuracy or robustness to domain shift are still topics with no clear consensus. Several DLIR methods claim that architectural choices and loss function design combined with amortized optimization of neural network parameters significantly outperform classical methods  `\cite{mok2020large,mok2020fast,chen2022transmorph}`{=latex}. On the contrary, classical iterative methods that leverage implicit or explicit conventional priors have shown to outperform most deep learning methods on other challenging datasets `\cite{wolterink2022implicit,siebert2021fast}`{=latex}. In our own empirical evaluation, we found that classical methods typically outperform deep methods under certain conditions and assumptions. Image registration is *NP-hard* being a non-convex optimization problem, and approximating the solution of NP-hard problems with deep learning methods is not guaranteed to be optimal, or even a minima of the registration loss at test-time. Deep learning methods also claim to provide amortized optimization since classical methods are extremely slow to run, however, modern GPU implementations `\cite{mang_claire_2019,niftyreg,jena2024fireants}`{=latex} have patched this shortcoming of classical methods while providing state-of-the-art performance.

#### Contributions.

The conditions needed for either paradigm to perform well over the other are clouded and not explicitly outlined in the existing literature. This has prolonged the tug-of-war between classical and deep learning methods. We perform a more structured problem setup and empirical evaluation to determine consensus on the benefits and limitations of each paradigm. First, we observe a strong correlation between the mutual information between per-pixel intensity and label maps, and the performance of classical registration methods. This strong correlation hints to the fact that the Jacobian projection in DLIR methods is unlikely to affect this correlation, and therefore, the performance of DLIR methods in the unsupervised setting. We empirically verify this hypothesis on a variety of state-of-the-art classical and DLIR methods, and address instrumentation bias in the existing literature. Secondly, since the label map is a deterministic function of the intensity image, DLIR methods can learn to perform better label matching when this constraint is enforced during training, by implicitly discovering the label map within the network features and predicting a warp field that minimizes the alignment error between label maps. This is a key strength of DLIR methods, that classical methods cannot leverage. Third, we show that even though learning methods implicit capture semantic information from the image which is not explicitly captured by classical methods, this additional feature learning does not translate to invariance to domain shift, and DLIR methods are brittle to these changes. Finally, we propose a general recipe to choose the best paradigm for a given registration problem, based on these observations.

# Related Work

## Classical Optimization-Based Methods

Classical image registration algorithms employ iterative optimization on a variational objective to estimate the dense displacement field between two images. Some of the earliest approaches to deformable registration considered models for small deformations using elastic deformation assumptions `\cite{kybic2003elasticmodels, davatzikos1997elasticmodels, bajcsy1983computerized, gee1993elastically, gee1998elastic, christensen2001consistent, christensen1996deformable}`{=latex}, conceptualizing the moving image volume as an elastic continuum that undergoes deformation to align with the appearance of the fixed image. This was in conjunction with alternate formulations based on fluid-dynamical Navier-Stokes `\cite{christensen_volumetric_1997, christensen1996deformable}`{=latex} and Euler-Lagrange equations `\cite{avants_symmetric_2008, beg2005computing, avants_lagrangian_2006, mang2017lagrangian, miller_metrics_2002}`{=latex} and their subsequent optimization strategies. The seminal work of Beg.*et al.* `\cite{beg2005computing}`{=latex} introduces an explicit Euler-Langrange formulation and a metric distance on the images as measured by the geodesic shortest paths in the space of diffeomorphisms used to transform the moving image to the fixed image. However, storing the explicit velocity fields is expensive in terms of compute and memory. This limitation motivated semi-Langrangian formulations  `\cite{avants_lagrangian_2006,avants_geodesic_2004}`{=latex} to avoid storing velocity fields explicitly, and only storing the final diffeomorphism. ANTs `\cite{ants,antsgithub}`{=latex} is a widely used toolkit that employs the Euler-Langrange formulation with a symmetric objective function `\cite{avants_symmetric_2008}`{=latex}. Yet another approach is to interpret deformable registration as an optical flow problem `\cite{ostergaard2008opticalflow, yang2008opticalflow}`{=latex}, leading to the famous Demons algorithm and its diffeomorphic and symmetric variants `\cite{yushkevich2016ic,vercauteren_symmetric_2008,vercauteren2007non,vercauteren2007diffeomorphic}`{=latex} implemented as part of the Insight Toolkit (ITK) `\cite{itkguide,dru_itk_2010}`{=latex}. However, most of these methods are still computationally expensive to run owing to their CPU implementations. Recently, modern implementations leverage the massively parallelizable nature of the registration problem to run on GPUs, leading to orders of magnitude of speedups while retaining the robustness and accuracy of the classical methods `\cite{mang_claire_2019,niftyreg,jena2024fireants}`{=latex}. However, as we show in  
efsec:unsup, the registration performance of classical methods is limited by the fidelity of image intensities.

## Deep Learning for Image Registration

<figure id="fig:corr">
<img src="./figures/mi_dice_.png"" />
<figcaption><strong>Correlation between Dice Score and Mutual Information.</strong> Classical registration methods like ANTs show a strong correlation between the Dice Score of registered pairs, and the mutual information between the corresponding image and label across 4 brain datasets.</figcaption>
</figure>

In contrast to most classical methods, earliest Deep Learning for Image Registration (DLIR) methods employed supervised learning for registration tasks `\cite{cao2017deformable,krebs2017robust,rohe2017svf,sokooti2017nonrigid}`{=latex} where the deformation field is obtained either manually or from a classical method. Voxelmorph `\cite{balakrishnan_voxelmorph_2019}`{=latex} was one of the first approaches that introduced unsupervised learning for registration of in-vivo brain MRI images. Subsequent research expanded upon this paradigm, exploring diverse architectural designs `\cite{chen_transmorph_2022-1,lebrat_corticalflow_2021,lku,mok2022affine}`{=latex}, loss functions `\cite{zhao2019unsupervised,Zhao_2019_ICCV,joshi_diffeomorphic_nodate,de2019deep,mok_large_2020,zhang2021cascaded,qiu2021learning,chen2022unsupervised}`{=latex}, and formulations based on incorporating inverse-consistency or symmetric transforms `\cite{mok2020fast,kim2021cyclemorph,kim2019unsupervised,tian2023gradicon,zhao2019unsupervised}`{=latex}. However, hyperparameter tuning became a challenge for DLIR methods since the methods had to be retrained for every new value of the regularization parameter. This motivated techniques such as conditional hyperparameter injection which addressed hyperparameter tuning `\cite{mok2021conditional,hoopes2021hypermorph}`{=latex}, while domain randomization and fine-tuning `\cite{hoffmann2021synthmorph,uzunova2017training,perez2023learning,fu2020synthetic}`{=latex} aimed to addressed generalizability of DLIR methods across domains. Recently, pretrained or foundation models are also proposed to address the generalizability of DLIR methods across different imaging and anatomy `\cite{liu_same_2021,tian_same_2023}`{=latex}. However, these methods perform a monolithic prediction of the warp field from the input images, losing feedback from the intermediate stages of the registration process as done in classical methods. To refine the warp fields, recurrent or cascade-based architectures were proposed `\cite{Zhao_2019_ICCV,zhao2019unsupervised,zhang2021cascaded,chen2022unsupervised}`{=latex}. However, cascade-based methods create a substantial memory overhead due to backpropagation through cascades and storage of intermediate volumes `\cite{bai_deep_2022-1}`{=latex}. Another promising avenue is to leverage deep implicit priors `\cite{ulyanov_deep_2020}`{=latex} within optimization frameworks to improve the performance of optimization methods or incorporate implicit constraints of the optimized warp field `\cite{wu_nodeo_2022,wolterink_implicit_nodate,joshi_diffeomorphic_nodate,hu_plug-and-play_2024}`{=latex}. We refer the reader to  `\cite{fu_deep_2020,haskins_deep_2020}`{=latex} for a comprehensive review of image registration techniques.

Despite the plethora of architectural formulations, loss functions, and output representations proposed in Deep Learning for Image Registration methods, we identify that these methods are highly sensitive to the domain gap between the distributions of training and test data, and in the unsupervised case, do not provide any benefit in terms of performance over classical methods. Their primary benefit is their ability to incorporate weak supervision like anatomical landmarks or expert annotations during training, which performs better landmark alignment on unseen image pairs (from the same distribution) without access to landmarks at inference time.

# Preliminaries

<figure id="fig:unsup_oasis">
<p><img src="./figures/oasis_dice0_.png"" /> <img src="./figures/oasis_unsup_trainval.png"" style="width:48.0%" /> <img src="./figures/oasis_unsup_val.png"" style="width:48.0%" /></p>
<figcaption><strong>Performance of classical and unsupervised DLIR methods on OASIS data.</strong> Boxplots (<strong>top</strong>) show that classical methods on average are ranked higher than DLIR methods, both on the <em>trainval</em> and <em>val</em> splits. Interestingly, the performance of unsupervised DLIR methods does not improve on the <em>trainval</em> split compared to <em>val</em> split – showing that deep learning does not have an intrinsic advantage in label alignment. Tables (<strong>bottom</strong>) of p-values show the results of a pairwise two-sided t-test between the performance of classical and DLIR methods on the <em>trainval</em> and <em>val</em> splits. <span style="background-color: best_color"> </span> denotes a cell where the classical method is significantly better than the DLIR method (<span class="math inline"><em>p</em> &lt; 0.01</span>), a <span style="background-color: worst_color"> </span> denotes the opposite, <span style="background-color: equal_color"> </span> denotes no significant difference. Most of the cells are <span style="background-color: best_color"> </span>, indicating that classical methods are significantly better than DLIR methods. </figcaption>
</figure>

We rehash the image registration problem statement to unify both classical and deep learning methods. Consider a dataset of image pairs \\(\mathcal{D} = \{({I}_f^{(n)}, {I}_m^{(n)}) \mid n \in \mathbb{N}, 1 \leq n \leq N\ \}\\), where \\({I}_f^{(n)}\\) and \\({I}_m^{(n)}\\) are the fixed and moving images defined over a spatial domain \\(\Omega \in \mathbb{R}^d\\). We drop the superscript \\(n\\) for simplicity. Also consider segmentation maps \\({S}_f\\) and \\({S}_m\\) for the fixed and moving images, respectively, defined over \\(\Omega\\). Given a family of transformations \\(T(\Omega)\\), the goal of image registration is to estimate transformations \\(\varphi_\theta(f, m) \in T(\Omega)\\) parameterized by \\(\theta\\) that minimize the following objective: \\[\label{eq:reg}
    \arg\min_\theta \sum_{f,m} \mathcal{L}(I_f, I_m \circ \varphi_\theta(f, m))  + \mathcal{R}(\varphi_\theta(f, m))\\] where \\(\mathcal{L}\\) is a dissimilarity function such as mean squared error, or negative local cross correlation, and \\(\mathcal{R}\\) is a regularization term that encourages desirable properties of the transformation, such as smoothness or elasticity. We call  
efeq:reg the *image matching* objective, since the transformations only need to align the intensity images. We can also call this the *unsupervised* objective, since it does not require any labeled data. If a suitably chosen label alignment loss \\(\mathcal{D}\\) is added as well, the optimization problem becomes: \\[\label{eq:labreg}
    \arg\min_\theta \sum_{f,m} \mathcal{L}(I_f, I_m \circ \varphi_\theta(f, m)) + \mathcal{D}(S_f, S_m \circ \varphi_\theta(f, m)) + \mathcal{R}(\varphi_\theta(f, m))\\] We call  
efeq:labreg the *label matching* objective, or a *weakly-supervised* objective. The image matching objective can subsume both DLIR and classical methods by choosing \\[\varphi_\theta(f, m) = \begin{cases}
        f_\theta(I_f, I_m) , & \text{ for deep networks}, \\
        \varphi_{(f, m)} , & \text{ for classical methods}.
        \end{cases}\\] where \\(f_\theta\\) is a deep network parameterized by \\(\theta\\) and \\(\varphi_{(f, m)}\\) are optimizable free parameters that are indexed by the 2-tuple \\((f, m)\\), i.e. \\(\theta = \bigcup_{f,m}\{ \varphi_{(f, m)} \}\\). In this paper, we consider methods that solve  
efeq:reg using gradient-based methods. The gradient of  
efeq:reg with respect to \\(\theta\\) is given by (we remove the \\(\mathcal{R}\\) term for simplicity): \\[\frac{\partial \mathcal{L}}{\partial \theta} = \sum_{f,m} \frac{\partial \mathcal{L}}{\partial \varphi_\theta(f, m)} \frac{\partial \varphi_\theta(f, m)}{\partial \theta}\\] The first term \\(\frac{\partial \mathcal{L}}{\partial \varphi_\theta(f, m)}\\) is the training signal from the dissimilarity function which does not depend on the parameters \\(\theta\\) for a given value of \\(\varphi_\theta(f, m)\\) and choice of \\(\mathcal{L}\\). The second term \\(\frac{\partial \varphi_\theta(f, m)}{\partial \theta}\\) is the Jacobian of the transformation with respect to the parameters, which is a projection of the gradient from the space of warp fields to the space of arbitrary parameters. For classical methods, the Jacobian is the identity matrix, for deep networks it is determined by the functional relationship of the output with respect to network parameters. Therefore, the difference in training dynamics and overall performance gap between classical and deep learning methods is likely to be attributed to the choice of \\(\frac{\partial \varphi_\theta(f, m)}{\partial \theta}\\).

# Unsupervised DLIR does not improve label matching performance [sec:unsup]

A speculated claim of deep learning methods is that they can provide better label matching performance by simply training a network to minimize  
efeq:reg in an unsupervised setting. Such improvements are claimed to come from architectural designs, which correspond to choice of Jacobian \\(\frac{\partial \varphi_\theta(f, m)}{\partial \theta}\\). A variety of architectures and parameterizations  `\cite{chen2022transmorph,mok2020large,mok2021conditional,mok2022affine,heinrich_estimating_2015,teshima_coupling-based_2020,wu_nodeo_2022}`{=latex} have been proposed to this effect. **However, we show that this is not the case.**

Image matching objectives ensure that intensities from the moving image are displaced to locations in the fixed image where they are most similar, without regard for alignment for any higher order structures. Intuitively, this will ensure label matching only to the extent that the intensity is predictive of the label. If an intensity value strongly corresponds to a particular label, then image matching will lead to label matching. Similarly, if a given intensity value corresponds to multiple possible labels, then image matching does not tell us which labels are matched via the image matching objective. More formally, considering the per-pixel intensity \\(i\\) and labels \\(s\\) as random variables, one can compute the mutual information between the intensity and label maps, denoted as \\(MI(i; s)\\) to determine the predictability of one from the other. We now show that the label matching performance of classical methods is highly correlated with \\(MI(i; s)\\). We consider a widely used classical method, ANTs `\cite{avants_symmetric_2008,ants}`{=latex}, to eliminate the effect of any Jacobian term. We consider four brain datasets - OASIS, LPBA40, MGH10, and IBSR18, which are acquired under different scanners, under different resolutions, and have different preprocessing, labelling and postprocessing protocols `\cite{oasisdataset,klein_evaluation_2009}`{=latex}. For each dataset, we use ANTs for registering all pairs within the dataset and then evaluate the Dice score as an indicator of label matching performance. For each image \\(I\\) and its corresponding label map \\(S\\), we compute the probability maps \\(p(i), p(s), p(i, s)\\) using histogram binning, followed by the mutual information \\(MI(i; s) = H(s) - H(s|i)\\). A Pearson’s correlation coefficient between the Dice scores and the mutual information of the image and label (  
effig:corr) reveals a strong linear (\\(\mathbf{r = 0.886}\\)) and logarithmic (\\(\mathbf{r = 0.933}\\)) relationship between the two quantities, shown by the gray and black lines respectively. Image matching improves label matching performance *only to the extent of the information about the label obtained from the image* (i.e. \\(MI(i; s)\\)). At a first glance, the Jacobian term \\(\frac{\partial \varphi_\theta(f, m)}{\partial \theta}\\) seemingly does not have a role in improving this mutual information further.  
**Empirical Validation.** We verify this claim empirically on the OASIS dataset, by minimizing  
efeq:reg in both DLIR and classical methods. We split the OASIS dataset into a training set of 364 images and a validation set of 50 images. We choose 50 instead of 20 images as in the original split `\cite{hering2022learn2reg}`{=latex} to compute statistical significance. Dice score over 35 subcortical structures is used as the label matching metric. We choose SynthMorph `\cite{hoffmann2021synthmorph}`{=latex}, LapIRN `\cite{mok2020large}`{=latex}, SymNet `\cite{mok2020fast}`{=latex}, LKU-Net `\cite{lku}`{=latex} and TransMorph `\cite{chen_transmorph_2022}`{=latex} as state-of-the-art DLIR baselines and ANTs `\cite{ants}`{=latex}, NiftyReg `\cite{niftyreg}`{=latex}, Symmetric Log Demons `\cite{vercauteren_diffeomorphic_2009}`{=latex}, Greedy `\cite{yushkevich2016ic}`{=latex}, FireANTs `\cite{jena2024fireants}`{=latex} as state-of-the-art classical baselines. For all DLIR methods, we use pretrained models if they are trained with  
efeq:reg, or train them with the architecture and hyperparameters provided in their original source code. The only exception is SynthMorph, which is trained on synthetically generated data and Dice loss of its corresponding synthetic labels (`shapes-sm` model). To compare SynthMorph’s domain generalization capabilities with only the image matching objective, we add another model, dubbed ‘`shapes-sm-ncc`’ that is trained on synthetically generated data as in the original pretrained model, but with the normalized cross-correlation of the aligned synthetic images. For all classical methods, we follow their recommended hyperparameters and run till convergence. All experiments are run on a cluster with 2 AMD EPYC 7713 CPUs and 8 NVIDIA A6000 GPUs.

#### Results.

For all methods, we compute the Dice score of all 35 subcortical regions on images in the validation set (denoted as *val*), and all images (denoted as *trainval*). These Dice scores are sorted by median validation performance in  
effig:unsup_oasis(top). Moreover, we perform a two-sided t-test for each *(classical, DLIR)* pair, both on the trainval and validation sets, shown in  
effig:unsup_oasis(bottom).  
effig:unsup_oasis shows the following conclusions: (a) the top performing classical method (Greedy) and the top performing DLIR method (TransMorph) achieve similar label matching performance on the val and the trainval set, i.e. the differences are *not* statistically significant (\\(p=0.161\\)), (b) classical methods almost always perform better than DLIR methods, even on the training set showing that the Jacobian term does not improve label matching more than the mutual information between the image and label, and (c) for unsupervised DLIR methods, there is no improvement label matching performance in the training set compared to val set. The only role of the Jacobian term is to perform amortized learning, but without supervised objectives, this does not guarantee any additional boost in label matching.

<figure id="tab:instrumentation">
<table>
<thead>
<tr>
<th colspan="6" style="text-align: center;"><strong>Evaluation of classical methods reported by baselines</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Method</strong></td>
<td style="text-align: left;"><strong>Evaluated Baseline</strong></td>
<td style="text-align: center;"><strong>Statistic</strong></td>
<td style="text-align: center;"><strong>Reported value</strong></td>
<td style="text-align: center;"><strong>Our eval</strong></td>
<td style="text-align: center;"><strong>Difference</strong></td>
</tr>
<tr>
<td style="text-align: left;">SymNet</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.680</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.107</td>
</tr>
<tr>
<td style="text-align: left;">PIRATE</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.699</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.088</td>
</tr>
<tr>
<td style="text-align: left;">LapIRN</td>
<td style="text-align: left;">Demons</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.715</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.087</td>
</tr>
<tr>
<td style="text-align: left;">LapIRN</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.723</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.064</td>
</tr>
<tr>
<td style="text-align: left;">NODEO</td>
<td style="text-align: left;">Demons</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.764</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.038</td>
</tr>
<tr>
<td style="text-align: left;">NODEO</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.729</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.058</td>
</tr>
<tr>
<td style="text-align: left;">Voxelmorph</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.749</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.038</td>
</tr>
<tr>
<td style="text-align: left;">Voxelmorph</td>
<td style="text-align: left;">NiftyReg</td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.755</td>
<td style="text-align: center;">0.776</td>
<td style="text-align: center;">0.021</td>
</tr>
<tr>
<td style="text-align: left;">SynthMorph</td>
<td style="text-align: left;">ANTs</td>
<td style="text-align: center;">Median</td>
<td style="text-align: center;">0.770</td>
<td style="text-align: center;">0.797</td>
<td style="text-align: center;">0.027</td>
</tr>
<tr>
<td colspan="6" style="text-align: center;"><strong>Evaluation of DLIR baselines reported by us</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Method</strong></td>
<td style="text-align: left;"><strong>Dice supervision</strong></td>
<td style="text-align: center;"><strong>Statistic</strong></td>
<td style="text-align: center;"><strong>Reported value</strong></td>
<td style="text-align: center;"><strong>Our eval</strong></td>
<td style="text-align: center;"><strong>Difference</strong></td>
</tr>
<tr>
<td style="text-align: left;">SynthMorph</td>
<td style="text-align: left;">-</td>
<td style="text-align: center;">Median</td>
<td style="text-align: center;">0.780</td>
<td style="text-align: center;">0.785</td>
<td style="text-align: center;">0.005</td>
</tr>
<tr>
<td style="text-align: left;">TransMorph-Regular</td>
<td style="text-align: left;"></td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.858</td>
<td style="text-align: center;">0.855</td>
<td style="text-align: center;">-0.003</td>
</tr>
<tr>
<td style="text-align: left;">LKU-Net</td>
<td style="text-align: left;"></td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.886</td>
<td style="text-align: center;">0.904</td>
<td style="text-align: center;">0.018</td>
</tr>
<tr>
<td style="text-align: left;">LapIRN</td>
<td style="text-align: left;"></td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.808</td>
<td style="text-align: center;">0.788</td>
<td style="text-align: center;">-0.020</td>
</tr>
<tr>
<td style="text-align: left;">SymNet</td>
<td style="text-align: left;"></td>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">0.743</td>
<td style="text-align: center;">0.748</td>
<td style="text-align: center;">0.005</td>
</tr>
</tbody>
</table>
<figcaption><strong>Instrumentation bias in evaluation of image registration algorithms.</strong> We highlight a significant difference in evaluation metrics reported by baselines and our evaluation on the OASIS validation dataset. This difference can be attributed to deviation in hyperparameters from the recommended parameters or early stopping to save time. In either case, this misrepresentation leads to incorrect conclusions about the performance of the algorithm. The reported dice scores are anywhere from 2 to 10 Dice points lower than our evaluation, showing a non-trivial instrumentation bias. We report our own evaluation of DLIR algorithms and compare them with reported values to avoid introducing instrumentation bias in our evaluation.</figcaption>
</figure>

#### The effect of instrumentation bias.

The astute reader may observe that this result is in contrast to results shown in prior literature `\cite{mok2020fast,mok2020large,wu_nodeo_2022,chen_transmorph_2022,balakrishnan2019voxelmorph}`{=latex}. We note that this is due to instrumentation bias `\cite{tustison2013instrumentation}`{=latex}, where the baselines’ performance may be misrepresented due to changes in hyperparameters, early stopping, or different preprocessing protocols. For instance,  `\cite{balakrishnan2019voxelmorph}`{=latex} mention that the default parameters of ANTs are not optimal, and choose a very different set of parameters (a Gaussian smoothing of 9 pixels, followed by an extremely small 0.4 pixels at the next scale). By stark contrast, we found the recommended parameters to work extremely well for all datasets considered in this paper. We speculate that these changes are done to tradeoff accuracy for speed, since classical methods converge slowly. However, this leads to misrepresentation of the performance of classical baselines. We found much better results (  
effig:unsup_oasis) for classical baselines simply by using their recommended scripts. We compare the discrepancy in performance between the baselines reported in the literature and the ones we obtained in  
eftab:instrumentation. We follow the guidelines in  `\cite{tustison2013instrumentation}`{=latex} to evaluate all methods. To ensure our work does not introduce its own instrumentation bias for DLIR baselines, we compare the performance of our trained/pretrained models to the ones reported in the literature (  
eftab:instrumentation). We make all evaluation scripts and trained models public to encourage fairness and transparency in evaluations.

# Supervised DLIR methods demonstrate enhanced label matching

When label matching is introduced as an objective in  
efeq:labreg, DLIR methods show superior performance than classical methods. Unlike the previous discussion, where only a pixelwise definition of \\(MI(i; s)\\) was used to quantify the coaction of image intensities and label maps, we consider the entire image \\(I\\) and label volume \\(S\\) as high-dimensional random variables. Label maps are now a deterministic function of the image, i.e. \\(S = f(I)\\), where \\(f\\) is the labelling protocol. In addition to image intensity, label maps are a function of morphological features, location, contrast, and the labelling protocol itself. When trained with the label maps as extra supervision, the network can infer these deterministic relationships to output a warp field that maximize both image similarity and label overlap. Classical intensity-based methods, on the other hand, do not have any mechanism to encode this additional relationship. Aligning intensities or intensity patches discards any functional relationship between high-level image features and labels. To show this, we repeat the same experiment setup as in  
efsec:unsup on the same splits, but with the label matching objective added as well.

<figure id="fig:sup_oasis">
<p><img src="./figures/oasis_dice1_.png"" /> <img src="./figures/oasis_sup_trainval.png"" style="width:48.0%" /> <img src="./figures/oasis_sup_val.png"" style="width:48.0%" /></p>
<figcaption><strong>Performance of classical and supervised DLIR methods on OASIS data.</strong> Boxplots (<strong>top</strong>) show that DLIR methods show superior performance compared to classical methods. Unlike the unsupervised case, the effect of overfitting is clearly visible in the gap between the <em>trainval</em> and <em>val</em> splits. Tables (<strong>bottom</strong>) of p-values show the results of a pairwise two-sided t-test between the performance of classical and DLIR methods on the <em>trainval</em> and <em>val</em> splits. <span style="background-color: best_color"> </span> denotes a cell where the classical method is significantly better than the DLIR method (<span class="math inline"><em>p</em> &lt; 0.01</span>), a <span style="background-color: worst_color"> </span> denotes the opposite, <span style="background-color: equal_color"> </span> denotes no significant difference. State-of-the-art DLIR methods show significantly better performance than classical methods when label supervision is added. </figcaption>
</figure>

#### Results.

  
effig:sup_oasis(top) shows the Dice scores for supervised classical and DLIR methods trained on the OASIS dataset, sorted by median validation performance. In this case, state-of-the-art DLIR methods outperform classical methods by a large margin, with notably higher Dice score on the *trainval* set than the *val* set, due to overfitting to the label matching for the training set. This is unlike unsupervised DLIR, where there was no improvement in label matching performance on the training set, emphasizing the fact that performing amortized training does not improve label matching performance by itself. These differences are statistically significant, with the exception of SymNet, which diverged under many training settings with the Dice loss, and only works marginally better than its unsupervised counterpart. SynthMorph is not trained on real data, and is added only as a reference for domain-agnostic performance.

This is an unsurprising result – the label matching objective provides additional training signal to the registration task, which is a highly ill-posed problem. Classical methods cannot incorporate this additional signal from a training dataset, and learning-based methods exploit this to achieve better registration on unseen data. Classical methods are, however, agnostic to modalties, intensity distributions, voxel resolutions, and anisotropy. The same registration algorithm (with possibly modified parameters) is applied to datasets with different characteristics, and they still retain their state-of-the-art performance. A related question arises for DLIR methods trained with label matching – does label matching performance transfer to other datasets?

<figure id="fig:kleinboxplot">
<p><img src="./figures/IBSR18_comparison.png"" style="width:95.0%" /> <img src="./figures/LPBA40_comparison.png"" style="width:95.0%" /> <img src="./figures/CUMC12_comparison.png"" style="width:95.0%" /> <img src="./figures/MGH10_comparison.png"" style="width:95.0%" /></p>
<figcaption><strong>Classical methods retain robustness across different datasets.</strong> Boxplots show the performance of classical and DLIR methods trained on the OASIS dataset, on four T1-brain datasets. For DLIR methods, we plot the performance of the supervised and unsupervised models. Across all datasets, FireANTs and ANTs consistently outperform DLIR methods, showing robustness to domain shift. Among DLIR methods, SynthMorph and TransMorph show robust performance, and training with label matching objective does not lead to significant improvement. </figcaption>
</figure>

# DLIR methods do not generalize across datasets

A key strength of classical optimization registration algorithms is their agnostic nature to the image modality, physical resolution, voxel sizes, and preprocessing protocols. Most DLIR methods, on the contrary, have been evaluated extensively on the same distribution of validation datasets as the training data, it is unclear if the performance improvements transfer to other datasets of the same anatomy. To this end, we evaluate the performance of both the classical and DLIR methods on four brain datasets – CUMC12, LPBA40, MGH10, and IBSR18. These datasets represent community-standard brain mapping challenge data `\cite{klein_evaluation_2009}`{=latex} for a comprehensive evaluation of 14 nonlinear classical registration methods, across various acquisition, preprocessing and labelling protocols.

Each dataset contains a different set of labeled regions acquired manually using different labeling protocols. For each dataset, all previously considered registration algorithms are run on all image pairs, and the mean Dice score over all labeled regions is computed. The methods are then sorted by median validation performance in  
effig:kleinboxplot. For DLIR methods, we plot the performance with models trained with and without the label matching loss in the OASIS dataset, shown as blue and green boxplots respectively. Across all datasets, FireANTs, Greedy, ANTs and NiftyReg consistently perform better than DLIR methods. Among the DLIR methods, SynthMorph performs consistently better due to its domain-agnostic training paradigm. Remarkably, even though DLIR methods outperform classical methods on the OASIS dataset with label matching objective, the performance does not transfer to other datasets, even compared to its own unsupervised variant. This is a negative result – implying that to improve performance on a new dataset, one must collect label maps from that dataset and retrain the model – existing collections of label maps are not sufficient to improve performance on new datasets.

# Discussion

Preceding experiments show that classical methods provide an unprecedented level of robustness and generalizability across datasets, but are limited by the fidelity of the image matching objective. DLIR methods provide a promising step towards improving registration performance of anatomical regions by implicitly discovering these structures and predicting appropriate warp fields. However, this anatomical-awareness on the training dataset does not help in generalizing to other datasets, limiting the practical utility of these methods. The usability of anatomical landmarks and labelmaps to obtain domain-invariant registration performance still remains an open research problem. At the current state, a practitioner should choose DLIR methods only if they have access to a large labeled dataset, and their application is limited to the same dataset distribution. In all other cases, classical optimization-based methods are the more accurate and reliable choice.

## Limitations

Our experimental design deliberately concentrates on algorithms that are *paradigmatically pure*—either strictly optimization-based or strictly learning-based. Isolating these two principal families avoids confounding factors and permits a transparent, one-to-one comparison that would not be possible if intermediary variants were mixed in. In addition, although the present analysis spans seven canonical T1-weighted neuroimaging datasets, future work may extend the evaluation protocol to further imaging modalities (e.g., PET or ultrasound) and to anatomies beyond the central nervous system. Finally, while our code base already supports GPU-accelerated execution, additional engineering could further shorten wall-clock times for teravoxel-scale volumes. Overall, the decisions made in the current study ensure maximal interpretability of the paradigm-level differences that are the focus of this work.
# References [references]

<div class="thebibliography" markdown="1">

ANTsX Antsx: Advanced normalization tools (ants) GitHub repository. **Abstract:** The Advanced Normalizations Tools ecosystem, known as ANTsX, consists of multiple open-source software libraries which house top-performing algorithms used worldwide by scientific and research communities for processing and analyzing biological and medical imaging data. The base software library, ANTs, is built upon, and contributes to, the NIH-sponsored Insight Toolkit. Founded in 2008 with the highly regarded Symmetric Normalization image registration framework, the ANTs library has since grown to include additional functionality. Recent enhancements include statistical, visualization, and deep learning capabilities through interfacing with both the R statistical project (ANTsR) and Python (ANTsPy). Additionally, the corresponding deep learning extensions ANTsRNet and ANTsPyNet (built on the popular TensorFlow/Keras libraries) contain several popular network architectures and trained models for specific applications. One such comprehensive application is a deep learning analog for generating cortical thickness data from structural T1-weighted brain MRI, both cross-sectionally and longitudinally. These pipelines significantly improve computational efficiency and provide comparable-to-superior accuracy over multiple criteria relative to the existing ANTs workflows and simultaneously illustrate the importance of the comprehensive ANTsX approach as a framework for medical image analysis. (@antsgithub)

B. B. Avants, C. L. Epstein, M. Grossman, and J. C. Gee Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain , 12(1):26–41, February 2008. **Abstract:** One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer’s disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler- Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN’s performance with a related elastic method and with the standard ITK implementation of Thirion’s Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN’s volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals. (@avants_symmetric_2008)

Brian Avants and James C. Gee Geodesic estimation for large deformation anatomical shape averaging and interpolation , 23:S139–S150, January 2004. (@avants_geodesic_2004)

Brian B. Avants, P. Thomas Schoenemann, and James C. Gee Lagrangian frame diffeomorphic image registration: Morphometric comparison of human and chimpanzee cortex , 10(3):397–412, June 2006. (@avants_lagrangian_2006)

Brian B Avants, Nick Tustison, Gang Song, et al Advanced normalization tools (ants) , 2(365):1–35, 2009. **Abstract:** We provide examples and highlights of Advanced Normalization Tools (ANTS) that address practical problems in real data. A variety of image and point similarity metrics and elastic, diffeomorphic, affine and other variations of transformation models are available. (@ants)

Shaojie Bai, Zhengyang Geng, Yash Savani, and J. Zico Kolter Deep Equilibrium Optical Flow Estimation In *2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, pages 610–620, New Orleans, LA, USA, June 2022. IEEE. **Abstract:** Many recent state-of-the-art (SOTA) optical flow models use finite-step recurrent update operations to emulate traditional algorithms by encouraging iterative refinements toward a stable flow estimation. However, these RNNs impose large computation and memory overheads, and are not directly trained to model such "stable estimation". They can converge poorly and thereby suffer from performance degradation. To combat these drawbacks, we propose deep equilibrium (DEQ)flow estimators, an approach that directly solves for the flow as the infinite-level fixed point of an implicit layer (using any black-box solver) \[3\], and differentiates through this fixed point analytically (thus requiring \<tex xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"\>$O(1)$\</tex\> training memory). This implicit-depth approach is not predicated on any specific model, and thus can be applied to a wide range of SOTA flow estimation model designs (e.g., RAFT \[1\] and GMA \[2\]). The use of these DEQflow estimators allows us to compute the flow faster using, e.g., fixed-point reuse and inexact gradients, consumes \<tex xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"\>$4\\}sim 6\\}times less$\</tex\> training memory than the recurrent counterpart, and achieves better results with the same computation budget. In addition, we propose a novel, sparse fixed-point correction scheme to stabilize our DEQ flow estimators, which addresses a longstanding challenge for DEQ models in general. We test our approach in various realistic settings and show that it improves SOTA methods on Sintel and KITTI datasets with substantially better computational and memory efficiency. (@bai_deep_2022-1)

Wenjia Bai, Hideaki Suzuki, Jian Huang, Catherine Francis, Shuo Wang, Giacomo Tarroni, Florian Guitton, Nay Aung, Kenneth Fung, Steffen E Petersen, et al A population-based phenome-wide association study of cardiac and aortic structure and function , 26(10):1654–1662, 2020. **Abstract:** Differences in cardiac and aortic structure and function are associated with cardiovascular diseases and a wide range of other types of disease. Here we analyzed cardiovascular magnetic resonance images from a population-based study, the UK Biobank, using an automated machine learning-based analysis pipeline. We report a comprehensive range of structural and functional phenotypes for the heart and aorta across 26,893 participants and explore how these phenotypes vary according to sex, age and major cardiovascular risk factors. We extended this analysis with a phenome-wide association study, in which we tested for correlations of a wide range of non-imaging phenotypes of the participants with imaging phenotypes. We further explored the associations of imaging phenotypes with early-life factors, mental health and cognitive function using both observational analysis and Mendelian randomization. Our study illustrates how population-based cardiac and aortic imaging phenotypes can be used to better deﬁne cardiovascular disease risks as well as heart-brain health interactions, highlighting new opportunities for studying disease mechanisms and developing image-based biomarkers. Cardiac and aortic structure and function are associated with cardiovascular diseases (CVDs)1, 2and a wide range of other types of disease3–6. Quantitative phenotypes derived from cardiovascular magnetic resonance (CMR) images enable us to assess cardiac and aortic structure and function in a non-invasive way and provide important biomarkers for the determination of pathological states in CVDs. For example, the left ventricular ejection fraction (LVEF) is an important clinical biomarker for the diagnosis and treatment of heart failure1. The left ventricular myocardial mass (LVM) is widely used for classifying hypertrophy and predicting risks of cardiovascular events7. Although CMR imaging phenotypes clearly play an important role in disease research and diagnosis, extracting these phenotypes demand signiﬁcant involvement of experienced image analysts. This has become a limiting factor for applying CMR in large-scale studies and exploiting imaging phenotypes at a population level. Large-scale imaging studies potentially provide a wealth of information for investigating disease risk factors and discovering early-stage image-based biomarkers. Recent large-scale imaging studies collecting CMR images include the Framingham Heart Study (offspring cohort: 1,114 subjects)8, MESA (5,004 subjects)9, (@bai2020population)

Ruzena Bajcsy, Robert Lieberson, and Martin Reivich A computerized system for the elastic matching of deformed radiographic images to idealized atlas images , 7(4):618–625, 1983. **Abstract:** A system of computer programs is described which, for the first time, is able to use computerized tomographic data to automatically locate, measure, and describe anatomical structures of interest with accuracy and consistency. Input to the system consists of any digitized radiographic data. Computer assisted tomographic (CAT) scans of the head were used in this first implementation. Using these data and a predefined atlas picture representing an idealized view of the average normal image, an individualized atlas was created. From the individualized atlas, structure size, density, location displacement, and distortion may be calculated. The individualized atlas created using high resolution data, such as the CAT scan, may then be directly superimposed on pictures obtained using lower resolution modalities, such as positron emission tomographic scan images. This allows the precise location of structures poorly visualized by the secondary imaging modality. This system is capable of using either two- or three-dimensional data. (@bajcsy1983computerized)

Guha Balakrishnan, Amy Zhao, Mert R. Sabuncu, John Guttag, and Adrian V. Dalca : A Learning Framework for Deformable Medical Image Registration , 38(8):1788–1800, August 2019. arXiv:1809.05231 \[cs\]. **Abstract:** We present VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration. Traditional registration methods optimize an objective function for each pair of images, which can be time-consuming for large datasets or rich deformation models. In contrast to this approach, and building on recent learning-based methods, we formulate registration as a function that maps an input image pair to a deformation field that aligns these images. We parameterize the function via a convolutional neural network (CNN), and optimize the parameters of the neural network on a set of images. Given a new pair of scans, VoxelMorph rapidly computes a deformation field by directly evaluating the function. In this work, we explore two different training strategies. In the first (unsupervised) setting, we train the model to maximize standard image matching objective functions that are based on the image intensities. In the second setting, we leverage auxiliary segmentations available in the training data. We demonstrate that the unsupervised model’s accuracy is comparable to state-of-the-art methods, while operating orders of magnitude faster. We also show that VoxelMorph trained with auxiliary data improves registration accuracy at test time, and evaluate the effect of training set size on registration. Our method promises to speed up medical image analysis and processing pipelines, while facilitating novel directions in learning-based registration and its applications. Our code is freely available at voxelmorph.csail.mit.edu. (@balakrishnan_voxelmorph_2019)

Guha Balakrishnan, Amy Zhao, Mert R Sabuncu, John Guttag, and Adrian V Dalca Voxelmorph: a learning framework for deformable medical image registration , 38(8):1788–1800, 2019. **Abstract:** We present VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration. Traditional registration methods optimize an objective function for each pair of images, which can be time-consuming for large datasets or rich deformation models. In contrast to this approach, and building on recent learning-based methods, we formulate registration as a function that maps an input image pair to a deformation field that aligns these images. We parameterize the function via a convolutional neural network (CNN), and optimize the parameters of the neural network on a set of images. Given a new pair of scans, VoxelMorph rapidly computes a deformation field by directly evaluating the function. In this work, we explore two different training strategies. In the first (unsupervised) setting, we train the model to maximize standard image matching objective functions that are based on the image intensities. In the second setting, we leverage auxiliary segmentations available in the training data. We demonstrate that the unsupervised model’s accuracy is comparable to state-of-the-art methods, while operating orders of magnitude faster. We also show that VoxelMorph trained with auxiliary data improves registration accuracy at test time, and evaluate the effect of training set size on registration. Our method promises to speed up medical image analysis and processing pipelines, while facilitating novel directions in learning-based registration and its applications. Our code is freely available at voxelmorph.csail.mit.edu. (@balakrishnan2019voxelmorph)

M Faisal Beg, Michael I Miller, Alain Trouvé, and Laurent Younes Computing large deformation metric mappings via geodesic flows of diffeomorphisms , 61:139–157, 2005. **Abstract:** The Large Deformation Diffeomorphic Metric Mapping (LDDMM) or flow of diffeomorphism is a classical framework in the field of shape spaces and is widely applied in mathematical imaging and computational anatomy. Essentially, it equips a group of diffeomorphisms with a right-invariant Riemannian metric, which allows to compute (Riemannian) distances or interpolations between different deformations. The associated Euler–Lagrange equation of shortest interpolation paths is one of the standard examples of a partial differential equation that can be approached with Lie group theory (by interpreting it as a geodesic ordinary differential equation on the Lie group of diffeomorphisms). The particular group $\\}mathcal D\^m$ of Sobolev diffeomorphisms is by now sufficiently understood to allow the analysis of geodesics and their numerical approximation. We prove convergence of a widely used Fourier-type space discretization of the geodesic equation. It is based on a new regularity estimate: We prove that geodesics in $\\}mathcal D\^m$ preserve any higher order Sobolev regularity of their initial velocity. (@beg2005computing)

Bella E Brezovec, Andrew B Berger, Yukun A Hao, Feng Chen, Shaul Druckmann, and Thomas R Clandinin Mapping the neural dynamics of locomotion across the drosophila brain , 34(4):710–726, 2024. **Abstract:** Summary Walking is a fundamental mode of locomotion, yet its neural correlates are unknown at brain-wide scale in any animal. We use volumetric two-photon imaging to map neural activity associated with walking across the entire brain of Drosophila . We detect locomotor signals in approximately 40% of the brain, identify a global signal associated with the transition from rest to walking, and define clustered neural signals selectively associated with changes in forward or angular velocity. These networks span functionally diverse brain regions, and include regions that have not been previously linked to locomotion. We also identify time-varying trajectories of neural activity that anticipate future movements, and that represent sequential engagement of clusters of neurons with different behavioral selectivity. These motor maps suggest a dynamical systems framework for constructing walking maneuvers reminiscent of models of forelimb reaching in primates and set a foundation for understanding how local circuits interact across large-scale networks. (@brezovec2024mapping)

Kristy K Brock, Sasa Mutic, Todd R McNutt, Hua Li, and Marc L Kessler Use of image registration and fusion algorithms and techniques in radiotherapy: Report of the aapm radiation therapy committee task group no. 132. , 44(7):e43–e76, 2017. **Abstract:** Image registration and fusion algorithms exist in almost every software system that creates or uses images in radiotherapy. Most treatment planning systems support some form of image registration and fusion to allow the use of multimodality and time-series image data and even anatomical atlases to assist in target volume and normal tissue delineation. Treatment delivery systems perform registration and fusion between the planning images and the in-room images acquired during the treatment to assist patient positioning. Advanced applications are beginning to support daily dose assessment and enable adaptive radiotherapy using image registration and fusion to propagate contours and accumulate dose between image data taken over the course of therapy to provide up-to-date estimates of anatomical changes and delivered dose. This information aids in the detection of anatomical and functional changes that might elicit changes in the treatment plan or prescription. As the output of the image registration process is always used as the input of another process for planning or delivery, it is important to understand and communicate the uncertainty associated with the software in general and the result of a specific registration. Unfortunately, there is no standard mathematical formalism to perform this for real-world situations where noise, distortion, and complex anatomical variations can occur. Validation of the software systems performance is also complicated by the lack of documentation available from commercial systems leading to use of these systems in undesirable ’black-box’ fashion. In view of this situation and the central role that image registration and fusion play in treatment planning and delivery, the Therapy Physics Committee of the American Association of Physicists in Medicine commissioned Task Group 132 to review current approaches and solutions for image registration (both rigid and deformable) in radiotherapy and to provide recommendations for quality assurance and quality control of these clinical processes. (@brock2017use)

Xiaohuan Cao, Jianhua Yang, Jun Zhang, Dong Nie, Minjeong Kim, Qian Wang, and Dinggang Shen Deformable image registration based on similarity-steered cnn regression In *Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20*, pages 300–308. Springer, 2017. **Abstract:** In this work we propose FlowReg, a deep learning-based framework that performs unsupervised image registration for neuroimaging applications. The system is composed of two architectures that are trained sequentially: FlowReg-A which affinely corrects for gross differences between moving and fixed volumes in 3D followed by FlowReg-O which performs pixel-wise deformations on a slice-by-slice basis for fine tuning in 2D. FlowReg-A warps the moving volume using gross global parameters to align rotation, scale, shear, and translation to the fixed volume. A correlation loss that encourages global alignment between the moving and the fixed volumes is employed to regress the affine parameters. The deformable network FlowReg-O operates on 2D image slices and is based on the optical flow CNN network that is adapted to neuroimaging with three loss components. The photometric loss minimizes pixel intensity differences, the smoothness loss encourages similar magnitudes between neighbouring vectors, and a correlation loss that is used to maintain the intensity similarity between fixed and moving image slices. The proposed method is compared to four open source registration techniques ANTs, Demons, SE, and Voxelmorph for FLAIR MRI applications. In total, 4643 FLAIR MR imaging volumes (approximately 255,000 image slices) are used from dementia and vascular disease cohorts, acquired from over 60 international centres with varying acquisition parameters. To quantitatively assess the performance of the registration tools, a battery of novel validation metrics are proposed that focus on the structural integrity of tissues, spatial alignment, and intensity similarity. Experimental results show FlowReg (FlowReg-A+O) performs better than iterative-based registration algorithms for intensity and spatial alignment metrics with a Pixelwise Agreement (PWA) of 0.65, correlation coefficient (R) of 0.80, and Mutual Information (MI) of 0.29. Among the deep learning frameworks evaluated, FlowReg-A or FlowReg-A+O provided the highest performance over all but one of the metrics. Results show that FlowReg is able to obtain high intensity and spatial similarity between the moving and the fixed volumes while maintaining the shape and structure of anatomy and pathology. (@cao2017deformable)

Junyu Chen, Eric C Frey, and Yong Du Unsupervised learning of diffeomorphic image registration via transmorph In *International Workshop on Biomedical Image Registration*, pages 96–102. Springer, 2022. **Abstract:** Registration plays an important role in medical image analysis. Deep learning-based methods have been studied for medical image registration, which leverage convolutional neural networks (CNNs) for efficiently regressing a dense deformation field from a pair of images. However, CNNs are limited in its ability to extract semantically meaningful intra- and inter-image spatial correspondences, which are of importance for accurate image registration. This study proposes a novel end-to-end deep learning-based framework for unsupervised affine and diffeomorphic deformable registration, referred as ACSGRegNet, which integrates a cross-attention module for establishing inter-image feature correspondences and a self-attention module for intra-image anatomical structures aware. Both attention modules are built on transformer encoders. The output from each attention module is respectively fed to a decoder to generate a velocity field. We further introduce a gated fusion module to fuse both velocity fields. The fused velocity field is then integrated to a dense deformation field. Extensive experiments are conducted on lumbar spine CT images. Once the model is trained, pairs of unseen lumbar vertebrae can be registered in one shot. Evaluated on 450 pairs of vertebral CT data, our method achieved an average Dice of 0.963 and an average distance error of 0.321mm, which are better than the state-of-the-art (SOTA). (@chen2022unsupervised)

Junyu Chen, Eric C Frey, Yufan He, William P Segars, Ye Li, and Yong Du Transmorph: Transformer for unsupervised medical image registration , 82:102615, 2022. **Abstract:** In the last decade, convolutional neural networks (ConvNets) have been a major focus of research in medical image analysis. However, the performances of ConvNets may be limited by a lack of explicit consideration of the long-range spatial relationships in an image. Recently Vision Transformer architectures have been proposed to address the shortcomings of ConvNets and have produced state-of-the-art performances in many medical imaging applications. Transformers may be a strong candidate for image registration because their substantially larger receptive field enables a more precise comprehension of the spatial correspondence between moving and fixed images. Here, we present TransMorph, a hybrid Transformer-ConvNet model for volumetric medical image registration. This paper also presents diffeomorphic and Bayesian variants of TransMorph: the diffeomorphic variants ensure the topology-preserving deformations, and the Bayesian variant produces a well-calibrated registration uncertainty estimate. We extensively validated the proposed models using 3D medical images from three applications: inter-patient and atlas-to-patient brain MRI registration and phantom-to-CT registration. The proposed models are evaluated in comparison to a variety of existing registration methods and Transformer architectures. Qualitative and quantitative results demonstrate that the proposed Transformer-based model leads to a substantial performance improvement over the baseline methods, confirming the effectiveness of Transformers for medical image registration. (@chen2022transmorph)

Junyu Chen, Eric C. Frey, Yufan He, William P. Segars, Ye Li, and Yong Du : Transformer for unsupervised medical image registration , 82:102615, November 2022. **Abstract:** In the last decade, convolutional neural networks (ConvNets) have been a major focus of research in medical image analysis. However, the performances of ConvNets may be limited by a lack of explicit consideration of the long-range spatial relationships in an image. Recently Vision Transformer architectures have been proposed to address the shortcomings of ConvNets and have produced state-of-the-art performances in many medical imaging applications. Transformers may be a strong candidate for image registration because their substantially larger receptive field enables a more precise comprehension of the spatial correspondence between moving and fixed images. Here, we present TransMorph, a hybrid Transformer-ConvNet model for volumetric medical image registration. This paper also presents diffeomorphic and Bayesian variants of TransMorph: the diffeomorphic variants ensure the topology-preserving deformations, and the Bayesian variant produces a well-calibrated registration uncertainty estimate. We extensively validated the proposed models using 3D medical images from three applications: inter-patient and atlas-to-patient brain MRI registration and phantom-to-CT registration. The proposed models are evaluated in comparison to a variety of existing registration methods and Transformer architectures. Qualitative and quantitative results demonstrate that the proposed Transformer-based model leads to a substantial performance improvement over the baseline methods, confirming the effectiveness of Transformers for medical image registration. (@chen_transmorph_2022-1)

Junyu Chen, Eric C. Frey, Yufan He, William P. Segars, Ye Li, and Yong Du : Transformer for unsupervised medical image registration , 82:102615, November 2022. arXiv:2111.10480 \[cs, eess\]. **Abstract:** In the last decade, convolutional neural networks (ConvNets) have been a major focus of research in medical image analysis. However, the performances of ConvNets may be limited by a lack of explicit consideration of the long-range spatial relationships in an image. Recently Vision Transformer architectures have been proposed to address the shortcomings of ConvNets and have produced state-of-the-art performances in many medical imaging applications. Transformers may be a strong candidate for image registration because their substantially larger receptive field enables a more precise comprehension of the spatial correspondence between moving and fixed images. Here, we present TransMorph, a hybrid Transformer-ConvNet model for volumetric medical image registration. This paper also presents diffeomorphic and Bayesian variants of TransMorph: the diffeomorphic variants ensure the topology-preserving deformations, and the Bayesian variant produces a well-calibrated registration uncertainty estimate. We extensively validated the proposed models using 3D medical images from three applications: inter-patient and atlas-to-patient brain MRI registration and phantom-to-CT registration. The proposed models are evaluated in comparison to a variety of existing registration methods and Transformer architectures. Qualitative and quantitative results demonstrate that the proposed Transformer-based model leads to a substantial performance improvement over the baseline methods, confirming the effectiveness of Transformers for medical image registration. (@chen_transmorph_2022)

Gary E Christensen and Hans J Johnson Consistent image registration , 20(7):568–582, 2001. **Abstract:** Presents a new method for image registration based on jointly estimating the forward and reverse transformations between two images while constraining these transforms to be inverses of one another. This approach produces a consistent set of transformations that have less pairwise registration error, i.e., better correspondence, than traditional methods that estimate the forward and reverse transformations independently. The transformations are estimated iteratively and are restricted to preserve topology by constraining them to obey the laws of continuum mechanics. The transformations are parameterized by a Fourier series to diagonalize the covariance structure imposed by the continuum mechanics constraints and to provide a computationally efficient numerical implementation. Results using a linear elastic material constraint are presented using both magnetic resonance and X-ray computed tomography image data. The results show that the joint estimation of a consistent set of forward and reverse transformations constrained by linear-elasticity give better registration results than using either constraint alone or none at all. (@christensen2001consistent)

Gary E Christensen, Richard D Rabbitt, and Michael I Miller Deformable templates using large deformation kinematics , 5(10):1435–1447, 1996. **Abstract:** A general automatic approach is presented for accommodating local shape variation when mapping a two-dimensional (2-D) or three-dimensional (3-D) template image into alignment with a topologically similar target image. Local shape variability is accommodated by applying a vector-field transformation to the underlying material coordinate system of the template while constraining the transformation to be smooth (globally positive definite Jacobian). Smoothness is guaranteed without specifically penalizing large-magnitude deformations of small subvolumes by constraining the transformation on the basis of a Stokesian limit of the fluid-dynamical Navier-Stokes equations. This differs fundamentally from quadratic penalty methods, such as those based on linearized elasticity or thin-plate splines, in that stress restraining the motion relaxes over time allowing large-magnitude deformations. Kinematic nonlinearities are inherently necessary to maintain continuity of structures during large-magnitude deformations, and are included in all results. After initial global registration, final mappings are obtained by numerically solving a set of nonlinear partial differential equations associated with the constrained optimization problem. Automatic regridding is performed by propagating templates as the nonlinear transformations evaluated on a finite lattice become singular. Application of the method to intersubject registration of neuroanatomical structures illustrates the ability to account for local anatomical variability. (@christensen1996deformable)

G.E. Christensen, S.C. Joshi, and M.I. Miller Volumetric transformation of brain anatomy , 16(6):864–877, December 1997. Conference Name: IEEE Transactions on Medical Imaging. **Abstract:** This paper presents diffeomorphic transformations of three-dimensional (3-D) anatomical image data of the macaque occipital lobe and whole brain cryosection imagery and of deep brain structures in human brains as imaged via magnetic resonance imagery. These transformations are generated in a hierarchical manner, accommodating both global and local anatomical detail. The initial low-dimensional registration is accomplished by constraining the transformation to be in a low-dimensional basis. The basis is defined by the Green’s function of the elasticity operator placed at predefined locations in the anatomy and the eigenfunctions of the elasticity operator. The high-dimensional large deformations are vector fields generated via the mismatch between the template and target-image volumes constrained to be the solution of a Navier-Stokes fluid model. As part of this procedure, the Jacobian of the transformation is tracked, insuring the generation of diffeomorphisms. It is shown that transformations constrained by quadratic regularization methods such as the Laplacian, biharmonic, and linear elasticity models, do not ensure that the transformation maintains topology and, therefore, must only be used for coarse global registration. (@christensen_volumetric_1997)

Christos Davatzikos Spatial transformation and registration of brain images using elastically deformable models , 66(2):207–222, 1997. **Abstract:** The development of algorithms for the spatial transformation and registration of tomographic brain images is a key issue in several clinical and basic science medical applications, including computer-aided neurosurgery, functional image analysis, and morphometrics. This paper describes a technique for the spatial transformation of brain images, which is based on elastically deformable models. A deformable surface algorithm is used to find a parametric representation of the outer cortical surface and then to define a map between corresponding cortical regions in two brain images. Based on the resulting map, a three-dimensional elastic warping transformation is then determined, which brings two images into register. This transformation models images as inhomogeneous elastic objects which are deformed into registration with each other by external force fields. The elastic properties of the images can vary from one region to the other, allowing more variable brain regions, such as the ventricles, to deform more freely than less variable ones. Finally, the framework of prestrained elasticity is used to model structural irregularities, and in particular the ventricular expansion occurring with aging or diseases, and the growth of tumors. Performance measurements are obtained using magnetic resonance images. (@davatzikos1997elasticmodels)

Bob D De Vos, Floris F Berendsen, Max A Viergever, Hessam Sokooti, Marius Staring, and Ivana Išgum A deep learning framework for unsupervised affine and deformable image registration , 52:128–143, 2019. **Abstract:** Image registration, the process of aligning two or more images, is the core technique of many (semi-)automatic medical image analysis tasks. Recent studies have shown that deep learning methods, notably convolutional neural networks (ConvNets), can be used for image registration. Thus far training of ConvNets for registration was supervised using prede ned example registrations. However, obtaining example registrations is not trivial. To circumvent the need for prede ned examples, and thereby to increase convenience of training ConvNets for image registration, we propose the Deep Learning Image Registration (DLIR) framework for unsupervised ane and deformable image registration. In the DLIR framework ConvNets are trained for image registration by exploiting image similarity analogous to conventional intensity-based image registration. After a ConvNet has been trained with the DLIR framework, it can be used to register pairs of unseen images in one shot. We propose exible ConvNets designs for ane image registration and for deformable image registration. By stacking multiple of these ConvNets into a larger architecture, we are able to perform coarse-to- ne image registration. We show for registration of cardiac cine MRI and registration of chest CT that performance of the DLIR framework is comparable to conventional image registration while being several orders of magnitude faster. (@de2019deep)

Florence Dru, Pierre Fillard, and Tom Vercauteren An ITK Implementation of the Symmetric Log-Domain Diffeomorphic Demons Algorithm , September 2010. **Abstract:** This article provides an implementation of the symmetric log-domain diffeomorphic image registration algorithm, or symmetric demons algorithm for short. It generalizes Thirion’s demons and the diffeomorphic demons algorithm. The main practical advantages of the symmetric demons with respect to the other demons variants is that is provides the inverse of the spatial transformation at no additional computational cost and ensures that the registration of image A to image B provides the inverse of the registration from image B to image A. The algorithm works completely in the log-domain, i.e. it uses a stationary velocity field to encode the spatial transformation as its exponential. Within the Insight Toolkit (ITK), the classical demons algorithm is implemented as part of the finite difference solver framework. Our code reuses and extends this generic framework. The source code is composed of a set of reusable ITK filters and classes together with their unit tests. We also provide a small example program that allows the user to compare the different variants of the demons algorithm. This paper gives an overview of the algorithm, an overview of its implementation and a small user guide to ease the use of the registration executable. (@dru_itk_2010)

Yabo Fu, Yang Lei, Tonghe Wang, Walter J Curran, Tian Liu, and Xiaofeng Yang Deep learning in medical image registration: a review , 65(20):20TR01, October 2020. **Abstract:** This paper presents a review of deep learning (DL) based medical image registration methods. We summarized the latest developments and applications of DL-based registration methods in the medical field. These methods were classified into seven categories according to their methods, functions and popularity. A detailed review of each category was presented, highlighting important contributions and identifying specific challenges. A short assessment was presented following the detailed review of each category to summarize its achievements and future potentials. We provided a comprehensive comparison among DL-based methods for lung and brain deformable registration using benchmark datasets. Lastly, we analyzed the statistics of all the cited works from various aspects, revealing the popularity and future trend of development in medical image registration using deep learning. (@fu_deep_2020)

Yabo Fu, Yang Lei, Tonghe Wang, Kristin Higgins, Jeffrey D. Bradley, Walter J. Curran, Tian Liu, and Xiaofeng Yang : an unsupervised deformable image registration method for 4D-CT lung , 47(4):1763–1774, April 2020. **Abstract:** Purpose To develop an accurate and fast deformable image registration (DIR) method for four‐dimensional computed tomography (4D‐CT) lung images. Deep learning‐based methods have the potential to quickly predict the deformation vector field (DVF) in a few forward predictions. We have developed an unsupervised deep learning method for 4D‐CT lung DIR with excellent performances in terms of registration accuracies, robustness, and computational speed. Methods A fast and accurate 4D‐CT lung DIR method, namely LungRegNet, was proposed using deep learning. LungRegNet consists of two subnetworks which are CoarseNet and FineNet. As the name suggests, CoarseNet predicts large lung motion on a coarse scale image while FineNet predicts local lung motion on a fine scale image. Both the CoarseNet and FineNet include a generator and a discriminator. The generator was trained to directly predict the DVF to deform the moving image. The discriminator was trained to distinguish the deformed images from the original images. CoarseNet was first trained to deform the moving images. The deformed images were then used by the FineNet for FineNet training. To increase the registration accuracy of the LungRegNet, we generated vessel‐enhanced images by generating pulmonary vasculature probability maps prior to the network prediction. Results We performed fivefold cross validation on ten 4D‐CT datasets from our department. To compare with other methods, we also tested our method using separate 10 DIRLAB datasets that provide 300 manual landmark pairs per case for target registration error (TRE) calculation. Our results suggested that LungRegNet has achieved better registration accuracy in terms of TRE than other deep learning‐based methods available in the literature on DIRLAB datasets. Compared to conventional DIR methods, LungRegNet could generate comparable registration accuracy with TRE smaller than 2 mm. The integration of both the discriminator and pulmonary vessel enhancements into the network was crucial to obtain high registration accuracy for 4D‐CT lung DIR. The mean and standard deviation of TRE were 1.00 ± 0.53 mm and 1.59 ± 1.58 mm on our datasets and DIRLAB datasets respectively. Conclusions An unsupervised deep learning‐based method has been developed to rapidly and accurately register 4D‐CT lung images. LungRegNet has outperformed its deep‐learning‐based peers and achieved excellent registration accuracy in terms of TRE. (@fu_lungregnet_2020)

Yabo Fu, Yang Lei, Jun Zhou, Tonghe Wang, S Yu David, Jonathan J Beitler, Walter J Curran, Tian Liu, and Xiaofeng Yang Synthetic ct-aided mri-ct image registration for head and neck radiotherapy In *Medical Imaging 2020: Biomedical Applications in Molecular, Structural, and Functional Imaging*, volume 11317, pages 572–578. SPIE, 2020. **Abstract:** In this study, we propose a synthetic CT (sCT) aided MRI-CT deformable image registration for head and neck radiotherapy. An image synthesis network, cycle consistent generative adversarial network (CycleGAN), was first trained using 25 pre-aligned CT-MRI image pairs. Using the MR head and neck images, the trained CycleGAN then predicts sCT images, which were used as MRI’s surrogate in MRI-CT registration. Demons registration algorithm was used to perform the sCT-CT registration on 5 separate datasets. For comparison, the original MRI and CT images were registered using mutual information as similarity metric. Our results showed that the target registration errors after registration were on average 1.31 mm and 1.02 mm for MRI-CT and sCT-CT registration, respectively. The mean normalized cross correlation between the sCT and CT after registration was 0.97, indicating that the proposed method is a viable way to perform MRI-CT image registration for head neck patients. (@fu2020synthetic)

Davide Gambarotto, Fabian U Zwettler, Maeva Le Guennec, Marketa Schmidt-Cernohorska, Denis Fortun, Susanne Borgers, Jörn Heine, Jan-Gero Schloetel, Matthias Reuss, Michael Unser, et al Imaging cellular ultrastructures using expansion microscopy (u-exm) , 16(1):71–74, 2019. **Abstract:** Determining the structure and composition of macromolecular assemblies is a major challenge in biology. Here we describe ultrastructure expansion microscopy (U-ExM), an extension of expansion microscopy that allows the visualization of preserved ultrastructures by optical microscopy. This method allows for near-native expansion of diverse structures in vitro and in cells; when combined with super-resolution microscopy, it unveiled details of ultrastructural organization, such as centriolar chirality, that could otherwise be observed only by electron microscopy. U-ExM enables near-native expansion microscopy of samples in vitro and in cells. The combination of U-ExM with confocal microscopy and HyVolution revealed details of centriole chirality that were previously accessible only by electron microscopy. (@gambarotto2019imaging)

James C Gee and Ruzena K Bajcsy Elastic matching: Continuum mechanical and probabilistic analysis , 2:183–197, 1998. **Abstract:** ABSTRACT This paper proposes a metamaterial in which the Poisson’s ratio can be tuned from positive to negative for infinitesimal deformation, and can evolve from positive to negative or vice versa for large deformation. Based on a hybrid of rotating trapeziums and triangles, the effective Poisson’s ratios of this metamaterial under on-axes loading were obtained by geometrical analysis. The on-axes Young’s moduli were established by matching the potential energy stored by the rotational elastic restraint at the hinges with the strain energy of deformation for the homogenised continuum. Results indicate that, at critical internal angles, the metamaterial’s Poisson’s ratios exhibit sign-switching upon stress direction reversal while the corresponding Young’s moduli become extremely large. Results also reveal the existence of terminal states, in the case of large deformation, in which the internal angles no longer change unless the direction of applied load is reversed. This metamaterial is useful for applications whereby material properties are required to change abruptly at certain stages and for applications where the properties can be altered in situ. (@gee1998elastic)

James C Gee, Martin Reivich, and Ruzena Bajcsy Elastically deforming a three-dimensional atlas to match anatomical brain images . **Abstract:** To evaluate our system for elastically deforming a three dimensional atlas to match anatomical brain images six deformed versions of an atlas were generated The deformed atlases were created by elastically mapping an anatomical brain atlas onto di erent MRI brain image volumes The mapping matches the edges of the ventricles and the surface of the brain the resultant deformations are propagated through the atlas volume deforming the remainder of the structures in the process The atlas was then elastically matched to its deformed versions The accuracy of the resultant matches was evaluated by determining the correspondence of cortical and subcortical structures The system on average matched the centroid of a structure to within mm of its true position and t a structure to within of its true volume The overlap between the matched and true structures de ned by the ratio between the volume of their intersection and the volume of their union averaged When the gray white interface was included for matching the mean overlap improved to each structure was matched to within mm of its true position and t to within of its true volume Preliminary studies were also made to determine the e ect of the compliance of the atlas on the resultant match This work was supported by the U S P H S under Program Project Grant NS To appear in Journal of Computer Assisted Tomography (@gee1993elastically)

Maged Goubran, Cathie Crukley, Sandrine De Ribaupierre, Terence M Peters, and Ali R Khan Image registration of ex-vivo mri to sparsely sectioned histology of hippocampal and neocortical temporal lobe specimens , 83:770–781, 2013. (@goubran2013image)

Grant Haskins, Uwe Kruger, and Pingkun Yan Deep learning in medical image registration: a survey , 31(1):8, January 2020. **Abstract:** The establishment of image correspondence through robust image reg- istration is critical to many clinical tasks such as image fusion, organ atlas cre- ation, and tumor growth monitoring, and is a very challenging problem. Since the beginning of the recent deep learning renaissance, the medical imaging research community has developed deep learning based approaches and achieved the state- of-the-art in many applications, including image registration. The rapid adoption of deep learning for image registration applications over the past few years neces- sitates a comprehensive summary and outlook, which is the main scope of this survey. This requires placing a focus on the di erent research areas as well as highlighting challenges that practitioners face. This survey, therefore, outlines the evolution of deep learning based medical image registration in the context of both research challenges and relevant innovations in the past few years. Further, this survey highlights future research directions to show how this eld may be possibly moved forward to the next level. 1 INTRODUCTION Image registration is the process of transforming di erent image datasets into one coordinate system with matched imaging contents, which has signi cant ap- plications in medicine. Registration may be necessary when analyzing a pair of images that were acquired from di erent viewpoints, at di erent times, or us- ing di erent sensors/modalities \[41, 122\]. Until recently, image registration was This work was partially supported by NIH/NIBIB under awards R21EB028001 and R01EB027898, and NIH/NCI under a Bench-to-Bedside award. This is a pre-print of an article published in Machine Vision and Applications. The nal authenticated version is available online at: https://doi.org/10.1007/s00138-020-01060-x G. Haskins, U. Kruger, P. Yan\* Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA Asterisk indicates corresponding author Tel.: +1-518-276-4476 E-mail: yanp2@rpi.eduarXiv:1903.02026v2 \[q-bio.QM\] 21 Jan 20202 Grant Haskins et al. Deep Medical Image Registration Deep Similarit y Metric Sup ervised T ransformation EstimationUnsup ervised T ransformation EstimationClassical Iterativ e F ramew ork Reinforcemen t Learning-Based Registration W eakly/P artially Sup ervised EstimationSimilarit y-Metric Constrain t EstimationF eature Constrain t Estimation2012 2013 2014 2015 2016 2017 2018 2019Slo w Registration Sparse Ground T ruth Data Fig. 1 An overvie (@haskins_deep_2020)

Mattias P. Heinrich, Heinz Handels, and Ivor J. A. Simpson Estimating Large Lung Motion in COPD Patients by Symmetric Regularised Correspondence Fields In Nassir Navab, Joachim Hornegger, William M. Wells, and Alejandro Frangi, editors, *Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015*, Lecture Notes in Computer Science, pages 338–345, Cham, 2015. Springer International Publishing. (@heinrich_estimating_2015)

Alessa Hering, Lasse Hansen, Tony CW Mok, Albert CS Chung, Hanna Siebert, Stephanie Häger, Annkristin Lange, Sven Kuckertz, Stefan Heldmann, Wei Shao, et al Learn2reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning , 42(3):697–712, 2022. **Abstract:** Image registration is a fundamental medical image analysis task, and a wide variety of approaches have been proposed. However, only a few studies have comprehensively compared medical image registration approaches on a wide range of clinically relevant tasks. This limits the development of registration methods, the adoption of research advances into practice, and a fair benchmark across competing approaches. The Learn2Reg challenge addresses these limitations by providing a multi-task medical image registration data set for comprehensive characterisation of deformable registration algorithms. A continuous evaluation will be possible at https://learn2reg.grand-challenge.org. Learn2Reg covers a wide range of anatomies (brain, abdomen, and thorax), modalities (ultrasound, CT, MR), availability of annotations, as well as intra- and inter-patient registration evaluation. We established an easily accessible framework for training and validation of 3D registration methods, which enabled the compilation of results of over 65 individual method submissions from more than 20 unique teams. We used a complementary set of metrics, including robustness, accuracy, plausibility, and runtime, enabling unique insight into the current state-of-the-art of medical image registration. This paper describes datasets, tasks, evaluation methods and results of the challenge, as well as results of further analysis of transferability to new datasets, the importance of label supervision, and resulting bias. While no single approach worked best across all tasks, many methodological aspects could be identified that push the performance of medical image registration to new state-of-the-art performance. Furthermore, we demystified the common belief that conventional registration methods have to be much slower than deep-learning-based methods. (@hering2022learn2reg)

Elizabeth MC Hillman, Venkatakaushik Voleti, Wenze Li, and Hang Yu Light-sheet microscopy in neuroscience , 42:295–313, 2019. **Abstract:** Light-sheet microscopy is an imaging approach that offers unique advantages for a diverse range of neuroscience applications. Unlike point-scanning techniques such as confocal and two-photon microscopy, light-sheet microscopes illuminate an entire plane of tissue, while imaging this plane onto a camera. Although early implementations of light sheet were optimized for longitudinal imaging of embryonic development in small specimens, emerging implementations are capable of capturing light-sheet images in freely moving, unconstrained specimens and even the intact in vivo mammalian brain. Meanwhile, the unique photobleaching and signal-to-noise benefits afforded by light-sheet microscopy’s parallelized detection deliver the ability to perform volumetric imaging at much higher speeds than can be achieved using point scanning. This review describes the basic principles and evolution of light-sheet microscopy, followed by perspectives on emerging applications and opportunities for both imaging large, cleared, and expanded neural tissues and high-speed, functional imaging in vivo. (@hillman2019light)

Malte Hoffmann, Benjamin Billot, Douglas N Greve, Juan Eugenio Iglesias, Bruce Fischl, and Adrian V Dalca Synthmorph: learning contrast-invariant registration without acquired images , 41(3):543–558, 2021. **Abstract:** We introduce a strategy for learning image registration without acquired imaging data, producing powerful networks agnostic to contrast introduced by magnetic resonance imaging (MRI). While classical registration methods accurately estimate the spatial correspondence between images, they solve an optimization problem for every new image pair. Learning-based techniques are fast at test time but limited to registering images with contrasts and geometric content similar to those seen during training. We propose to remove this dependency on training data by leveraging a generative strategy for diverse synthetic label maps and images that exposes networks to a wide range of variability, forcing them to learn more invariant features. This approach results in powerful networks that accurately generalize to a broad array of MRI contrasts. We present extensive experiments with a focus on 3D neuroimaging, showing that this strategy enables robust and accurate registration of arbitrary MRI contrasts even if the target contrast is not seen by the networks during training. We demonstrate registration accuracy surpassing the state of the art both within and across contrasts, using a single model. Critically, training on arbitrary shapes synthesized from noise distributions results in competitive performance, removing the dependency on acquired data of any kind. Additionally, since anatomical label maps are often available for the anatomy of interest, we show that synthesizing images from these dramatically boosts performance, while still avoiding the need for real intensity images. Our code is available at doic https://w3id.org/synthmorph. (@hoffmann2021synthmorph)

Andrew Hoopes, Malte Hoffmann, Bruce Fischl, John Guttag, and Adrian V Dalca Hypermorph: Amortized hyperparameter learning for image registration In *Information Processing in Medical Imaging: 27th International Conference, IPMI 2021, Virtual Event, June 28–June 30, 2021, Proceedings 27*, pages 3–17. Springer, 2021. **Abstract:** We present HyperMorph, a learning-based strategy for deformable image registra- tion that removes the need to tune important registration hyperparameters during training. Classical registration methods solve an optimization problem to nd a set of spatial correspon- dences between two images, while learning-based methods leverage a training dataset to learn a function that generates these correspondences. The quality of the results for both types of techniques depends greatly on the choice of hyperparameters. Unfortunately, hyperparameter tuning is time-consuming and typically involves training many separate models with various hyperparameter values, potentially leading to suboptimal results. To address this ineciency, we introduce amortized hyperparameter learning for image registration, a novel strategy to learn the e ects of hyperparameters on deformation elds. The proposed framework learns a hypernetwork that takes in an input hyperparameter and modulates a registration network to produce the optimal deformation eld for that hyperparameter value. In e ect, this strategy trains a single, rich model that enables rapid, ne-grained discovery of hyperparameter values from a continuous interval at test-time. We demonstrate that this approach can be used to optimize multiple hyperparameters considerably faster than existing search strategies, leading to a reduced computational and human burden as well as increased exibility. We also show several important bene ts, including increased robustness to initialization and the ability to rapidly identify optimal hyperparameter values speci c to a registration task, dataset, or even a single anatomical region, all without retraining the HyperMorph model. Our code is publicly available at http://voxelmorph.mit.edu . (@hoopes2021hypermorph)

Junhao Hu, Weijie Gan, Zhixin Sun, Hongyu An, and Ulugbek S. Kamilov A Plug-and-Play Image Registration Network March 2024. arXiv:2310.04297 \[eess\]. **Abstract:** Deformable image registration (DIR) is an active research topic in biomedical imaging. There is a growing interest in developing DIR methods based on deep learning (DL). A traditional DL approach to DIR is based on training a convolutional neural network (CNN) to estimate the registration field between two input images. While conceptually simple, this approach comes with a limitation that it exclusively relies on a pre-trained CNN without explicitly enforcing fidelity between the registered image and the reference. We present plug-and-play image registration network (PIRATE) as a new DIR method that addresses this issue by integrating an explicit data-fidelity penalty and a CNN prior. PIRATE pre-trains a CNN denoiser on the registration field and "plugs" it into an iterative method as a regularizer. We additionally present PIRATE+ that fine-tunes the CNN prior in PIRATE using deep equilibrium models (DEQ). PIRATE+ interprets the fixed-point iteration of PIRATE as a network with effectively infinite layers and then trains the resulting network end-to-end, enabling it to learn more task-specific information and boosting its performance. Our numerical results on OASIS and CANDI datasets show that our methods achieve state-of-the-art performance on DIR. (@hu_plug-and-play_2024)

Luis Ibanez, Will Schroeder, Lydia Ng, Josh Cates, et al The itk software guide 2003. **Abstract:** The ITK Software Guide is divided into two books. This first book provides a general introduction to ITK including instructions for building and installing ITK; introduces the general architecture and design as well as basic system concepts; and explains how to create your own classes, extend the system, and be an active participant in the open-source ITK community. This book is the companion to The ITK Software Guide Book 2: Design and Functionality. ITK is an open-source, cross-platform software toolkit that provides an extensive suite of tools for image analysis. For over a decade, researchers and developers around the world have processed their MRI, CT, ultrasound, PET, fluoroscopy, and microscopy data with ITK. Developed through extreme programming methodologies, ITK employs leading-edge algorithms for registering and segmenting multidimensional data. (@itkguide)

Rohit Jena, Pratik Chaudhari, and James C Gee Fireants: Adaptive riemannian optimization for multi-scale diffeomorphic registration , 2024. **Abstract:** The paper proposes FireANTs, the first multi-scale Adaptive Riemannian Optimization algorithm for dense diffeomorphic image matching. One of the most critical and understudied aspects of diffeomorphic image matching algorithms are its highly ill-conditioned nature. We quantitatively capture the extent of ill-conditioning in a typical MRI matching task, motivating the need for an adaptive optimization algorithm for diffeomorphic matching. To this end, FireANTs generalizes the concept of momentum and adaptive estimates of the Hessian to mitigate this ill-conditioning in the non-Euclidean space of diffeomorphisms. Unlike common non-Euclidean manifolds, we also formalize considerations for multi-scale optimization of diffeomorphisms. Our rigorous mathematical results and operational contributions lead to a state-of-the-art dense matching algorithm that can be applied to generic image data with remarkable accuracy and robustness. We demonstrate consistent improvements in image matching performance across a spectrum of community-standard medical and biological correspondence matching challenges spanning a wide variety of image modalities, anatomies, resolutions, acquisition protocols, and preprocessing pipelines. This improvement is supplemented by 300x to 3200x speedup over existing CPU-based state-of-the-art algorithms. For the first time, we perform diffeomorphic matching of sub-micron mouse isocortex volumes at native resolution, and generate a 25{\\}mu}m mouse brain atlas in under 25 minutes. Our fast implementation also enables hyperparameter studies that were intractable with existing correspondence matching algorithms. (@jena2024fireants)

Xi Jia, Joseph Bartlett, Tianyang Zhang, Wenqi Lu, Zhaowen Qiu, and Jinming Duan U-net vs transformer: Is u-net outdated in medical image registration? , 2022. **Abstract:** Due to their extreme long-range modeling capability, vision transformer-based networks have become increasingly popular in deformable image registration. We believe, however, that the receptive field of a 5-layer convolutional U-Net is sufficient to capture accurate deformations without needing long-range dependencies. The purpose of this study is therefore to investigate whether U-Net-based methods are outdated compared to modern transformer-based approaches when applied to medical image registration. For this, we propose a large kernel U-Net (LKU-Net) by embedding a parallel convolutional block to a vanilla U-Net in order to enhance the effective receptive field. On the public 3D IXI brain dataset for atlas-based registration, we show that the performance of the vanilla U-Net is already comparable with that of state-of-the-art transformer-based networks (such as TransMorph), and that the proposed LKU-Net outperforms TransMorph by using only 1.12% of its parameters and 10.8% of its mult-adds operations. We further evaluate LKU-Net on a MICCAI Learn2Reg 2021 challenge dataset for inter-subject registration, our LKU-Net also outperforms TransMorph on this dataset and ranks first on the public leaderboard as of the submission of this work. With only modest modifications to the vanilla U-Net, we show that U-Net can outperform transformer-based architectures on inter-subject and atlas-based 3D medical image registration. Code is available at https://github.com/xi-jia/LKU-Net. (@lku)

Di Jiang, Yuhui Du, Hewei Cheng, Tianzi Jiang, and Yong Fan Groupwise spatial normalization of fmri data based on multi-range functional connectivity patterns , 82:355–372, 2013. (@jiang2013groupwise)

Ankita Joshi and Yi Hong Diffeomorphic Image Registration using Lipschitz Continuous Residual Networks page 13. (@joshi_diffeomorphic_nodate)

Marc L Kessler Image registration and data fusion in radiation therapy , 79(special_issue_1):S99–S108, 2006. **Abstract:** This paper provides an overview of image registration and data fusion techniques used in radiation therapy, and examples of their use. They are used at all stages of the patient management process; for initial diagnosis and staging, during treatment planning and delivery, and after therapy to help monitor the patients’ response to treatment. Most treatment planning systems now support some form of interactive or automated image registration and provide tools for mapping information, such as tissue outlines and computed dose from one imaging study to another. To complement this, modern treatment delivery systems offer means for acquiring and registering 2D and 3D image data at the treatment unit to aid patient setup. Techniques for adapting and customizing treatments during the course of therapy using 3D and 4D anatomic and functional imaging data are currently being introduced into the clinic. These techniques require sophisticated image registration and data fusion technology to accumulate properly the delivered dose and to analyse possible physiological and anatomical changes during treatment. Finally, the correlation of radiological changes after therapy with delivered dose also requires the use of image registration and fusion techniques. (@kessler2006image)

Boah Kim, Dong Hwan Kim, Seong Ho Park, Jieun Kim, June-Goo Lee, and Jong Chul Ye Cyclemorph: cycle consistent unsupervised deformable image registration , 71:102036, 2021. **Abstract:** —Image registration is a fundamental task in medical image analysis. Recently, deep learning based image registration methods have been extensively investigated due to their excellent performance despite the ultra-fast computational time. However, the existing deep learning methods still have limitation in the preservation of original topology during the deformation with registration vector ﬁelds. To address this issues, here we present a cycle-consistent deformable image registration. The cycle consistency enhances image registration performance by providing an implicit regularization to preserve topology during the deformation. The proposed method is so ﬂexible that can be applied for both 2D and 3D registration problems for various applications, and can be easily extended to multi- scale implementation to deal with the memory issues in large volume registration. Experimental results on various datasets from medical and non-medical applications demonstrate that the proposed method provides effective and accurate registration on diverse image pairs within a few seconds. Qualitative and quantitative evaluations on deformation ﬁelds also verify the effectiveness of the cycle consistency of the proposed method. (@kim2021cyclemorph)

Boah Kim, Jieun Kim, June-Goo Lee, Dong Hwan Kim, Seong Ho Park, and Jong Chul Ye Unsupervised deformable image registration using cycle-consistent cnn In *Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part VI 22*, pages 166–174. Springer, 2019. **Abstract:** Medical image registration is one of the key processing steps for biomedical image analysis such as cancer diagnosis. Recently, deep learning based supervised and unsupervised image registration methods have been extensively studied due to its excellent performance in spite of ultra-fast computational time compared to the classical approaches. In this paper, we present a novel unsupervised medical image registration method that trains deep neural network for deformable registration of 3D volumes using a cycle-consistency. Thanks to the cycle consistency, the proposed deep neural networks can take diverse pair of image data with severe deformation for accurate registration. Experimental results using multiphase liver CT images demonstrate that our method provides very precise 3D image registration within a few seconds, resulting in more accurate cancer size estimation. (@kim2019unsupervised)

Arno Klein, Jesper Andersson, Babak A. Ardekani, John Ashburner, Brian Avants, Ming-Chang Chiang, Gary E. Christensen, D. Louis Collins, James Gee, Pierre Hellier, Joo Hyun Song, Mark Jenkinson, Claude Lepage, Daniel Rueckert, Paul Thompson, Tom Vercauteren, Roger P. Woods, J. John Mann, and Ramin V. Parsey Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration , 46(3):786–802, July 2009. **Abstract:** All fields of neuroscience that employ brain imaging need to communicate their results with reference to anatomical regions. In particular, comparative morphometry and group analysis of functional and physiological data require coregistration of brains to establish correspondences across brain structures. It is well established that linear registration of one brain to another is inadequate for aligning brain structures, so numerous algorithms have emerged to nonlinearly register brains to one another. This study is the largest evaluation of nonlinear deformation algorithms applied to brain © 2008 Published by Elsevier Inc. \* Corresponding author. E-mail address : arno@binarybottle.com (A. Klein). URL : http://www.binarybottle.com (A. Klein).. NIH Public Access Author Manuscript Neuroimage . Author manuscript; available in PMC 2009 September 21. Published in final edited form as: Neuroimage . 2009 July 1; 46(3): 786±802. doi:10.1016/j.neuroimage.2008.12.037. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscriptimage registration ever conducted. Fourteen algorithms from laboratories around the world are evaluated using 8 different error measures. More than 45,000 registrations between 80 manually labeled brains were performed by algorithms including: AIR, ANIMAL, ART, Diffeomorphic Demons, FNIRT, IRTK, JRD-fluid, ROMEO, SICLE, SyN, and four different SPM5 algorithms (“SPM2-type” and regular Normalization, Unified Segmentation, and the DARTEL Toolbox). All of these registrations were preceded by linear registration between the same image pairs using FLIRT. One of the most significant findings of this study is that the relative performances of the registration methods under comparison appear to be little affected by the choice of subject population, labeling protocol, and type of overlap measure. This is important because it suggests that the findings are generalizable to new subject populations that are labeled or evaluated using different labeling protocols. Furthermore, we ranked the 14 methods according to three completely independent analyses (permutation tests, one-way ANOVA tests, and indifference-zone ranking) and derived three almost identical top rankings of the methods. ART, SyN, IRTK, and SPM’s DARTEL Toolbox gave the best results according to overlap and distance measures, with ART and SyN delivering the most consistently high accuracy across subjects and label sets. Updates will be published on the http://www.mindboggle.info/ (@klein_evaluation_2009)

Julian Krebs, Tommaso Mansi, Hervé Delingette, Li Zhang, Florin C Ghesu, Shun Miao, Andreas K Maier, Nicholas Ayache, Rui Liao, and Ali Kamen Robust non-rigid registration through agent-based action learning In *Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20*, pages 344–352. Springer, 2017. **Abstract:** Robust image registration in medical imaging is essential for comparison or fusion of images, acquired from various perspectives, modalities or at di erent times. Typically, an objective function needs to be minimized assuming speci c a priori deformation models and pre- de ned or learned similarity measures. However, these approaches have diculties to cope with large deformations or a large variability in ap- pearance. Using modern deep learning (DL) methods with automated feature design, these limitations could be resolved by learning the intrin- sic mapping solely from experience. We investigate in this paper how DL could help organ-speci c (ROI-speci c) deformable registration, to solve motion compensation or atlas-based segmentation problems for instance in prostate diagnosis. An arti cial agent is trained to solve the task of non-rigid registration by exploring the parametric space of a statistical deformation model built from training data. Since it is dicult to ex- tract trustworthy ground-truth deformation elds, we present a training scheme with a large number of synthetically deformed image pairs requir- ing only a small number of real inter-subject pairs. Our approach was tested on inter-subject registration of prostate MR data and reached a median DICE score of .88 in 2-D and .76 in 3-D, therefore showing improved results compared to state-of-the-art registration algorithms. 1 Introduction Registration of images with focus on the ROI is essential in fusion and atlas- based segmentation (e.g. \[9\]). Traditional algorithms try to compute the dense mapping between two images by minimizing an objective function with regard to some similarity criterion. However, besides challenges of solving the ill-posed and non-convex problem many approaches have diculties in handling large deformations or large variability in appearance. Recently, promising results using deep representation learning have been presented for learning similarity metrics \[8\], predicting the optical ow \[1\] or the large deformation di eomorphic metric mapping-momentum \[10\]. These approaches either only partially remove theabove-mentioned limitations as they stick to an energy minimization framework (cf. \[8\]) or rely on a large number of training samples derived from existing registration results (cf. \[1,10\]). Inspired by the recent works in reinforcement learning \[6,2\], we propose a reformulation of the non-rigid registration problem following a similar method- ology as in 3-D rigi (@krebs2017robust)

Fae A Kronman, Josephine K Liwang, Rebecca Betty, Daniel J Vanselow, Yuan-Ting Wu, Nicholas J Tustison, Ashwin Bhandiwad, Steffy B Manjila, Jennifer A Minteer, Donghui Shin, et al Developmental mouse brain common coordinate framework , 2023. **Abstract:** 3D standard reference brains serve as key resources to understand the spatial organization of the brain and promote interoperability across different studies. However, unlike the adult mouse brain, the lack of standard 3D reference atlases for developing mouse brains has hindered advancement of our understanding of brain development. Here, we present a multimodal 3D developmental common coordinate framework (DevCCF) spanning mouse embryonic day (E) 11.5, E13.5, E15.5, E18.5, and postnatal day (P) 4, P14, and P56 with anatomical segmentations defined by a developmental ontology. At each age, the DevCCF features undistorted morphologically averaged atlas templates created from Magnetic Resonance Imaging and co-registered high-resolution templates from light sheet fluorescence microscopy. Expert-curated 3D anatomical segmentations at each age adhere to an updated prosomeric model and can be explored via an interactive 3D web-visualizer. As a use case, we employed the DevCCF to unveil the emergence of GABAergic neurons in embryonic brains. Moreover, we integrated the Allen CCFv3 into the P56 template with stereotaxic coordinates and mapped spatial transcriptome cell-type data with the developmental ontology. In summary, the DevCCF is an openly accessible resource that can be used for large-scale data integration to gain a comprehensive understanding of brain development. (@kronman2023developmental)

Jan Kybic and Michael Unser Fast parametric elastic image registration , 12(11):1427–1442, 2003. **Abstract:** We present an algorithm for fast elastic multidimensional intensity-based image registration with a parametric model of the deformation. It is fully automatic in its default mode of operation. In the case of hard real-world problems, it is capable of accepting expert hints in the form of soft landmark constraints. Much fewer landmarks are needed and the results are far superior compared to pure landmark registration. Particular attention has been paid to the factors influencing the speed of this algorithm. The B-spline deformation model is shown to be computationally more efficient than other alternatives. The algorithm has been successfully used for several two-dimensional (2-D) and three-dimensional (3-D) registration tasks in the medical domain, involving MRI, SPECT, CT, and ultrasound image modalities. We also present experiments in a controlled environment, permitting an exact evaluation of the registration accuracy. Test deformations are generated automatically using a random hierarchical fractional wavelet-based generator. (@kybic2003elasticmodels)

Leo Lebrat, Rodrigo Santa Cruz, Frederic de Gournay, Darren Fu, Pierrick Bourgeat, Jurgen Fripp, Clinton Fookes, and Olivier Salvado : A Diffeomorphic Mesh Transformer Network for Cortical Surface Reconstruction In *Advances in Neural Information Processing Systems*, volume 34, pages 29491–29505. Curran Associates, Inc., 2021. (@lebrat_corticalflow_2021)

Devavrat Likhite, Ganesh Adluru, and Edward DiBella Deformable and rigid model-based image registration for quantitative cardiac perfusion In *Statistical Atlases and Computational Models of the Heart-Imaging and Modelling Challenges: 5th International Workshop, STACOM 2014, Held in Conjunction with MICCAI 2014, Boston, MA, USA, September 18, 2014, Revised Selected Papers 5*, pages 41–50. Springer, 2015. **Abstract:** The heart is a relatively complex non-rigid motion organ in the human body. Quantitative motion analysis of the heart takes on a critical significance to help doctors with accurate diagnosis and treatment. Moreover, cardiovascular magnetic resonance imaging (CMRI) can be used to perform a more detailed quantitative analysis evaluation for cardiac diagnosis. Deformable image registration (DIR) has become a vital task in biomedical image analysis since tissue structures have variability in medical images. Recently, the model based on masked autoencoder (MAE) has recently been shown to be effective in computer vision tasks. Vision Transformer has the context aggregation ability to restore the semantic information in the original image regions by using a low proportion of visible image patches to predict the masked image patches. A novel Transformer-ConvNet architecture is proposed in this study based on MAE for medical image registration. The core of the Transformer is designed as a masked autoencoder (MAE) and a lightweight decoder structure, and feature extraction before the downstream registration task is transformed into the self-supervised learning task. This study also rethinks the calculation method of the multi-head self-attention mechanism in the Transformer encoder. We improve the query-key-value-based dot product attention by introducing both depthwise separable convolution (DWSC) and squeeze and excitation (SE) modules into the self-attention module to reduce the amount of parameter computation to highlight image details and maintain high spatial resolution image features. In addition, concurrent spatial and channel squeeze and excitation (scSE) module is embedded into the CNN structure, which also proves to be effective for extracting robust feature representations. The proposed method, called MAE-TransRNet, has better generalization. The proposed model is evaluated on the cardiac short-axis public dataset (with images and labels) at the 2017 Automated Cardiac Diagnosis Challenge (ACDC). The relevant qualitative and quantitative results (e.g., dice performance and Hausdorff distance) suggest that the proposed model can achieve superior results over those achieved by the state-of-the-art methods, thus proving that MAE and improved self-attention are more effective and promising for medical image registration tasks. Codes and models are available at https://github.com/XinXiao101/MAE-TransRNet. (@likhite2015deformable)

Fengze Liu, Ke Yan, Adam P. Harrison, Dazhou Guo, Le Lu, Alan L. Yuille, Lingyun Huang, Guotong Xie, Jing Xiao, Xianghua Ye, and Dakai Jin : Deformable Image Registration Based on Self-supervised Anatomical Embeddings In Marleen de Bruijne, Philippe C. Cattin, Stéphane Cotin, Nicolas Padoy, Stefanie Speidel, Yefeng Zheng, and Caroline Essert, editors, *Medical Image Computing and Computer Assisted Intervention – MICCAI 2021*, Lecture Notes in Computer Science, pages 87–97, Cham, 2021. Springer International Publishing. **Abstract:** In this work, we introduce a fast and accurate method for unsupervised 3D medical image registration. This work is built on top of a recent algorithm self-supervised anatomical embedding (SAM), which is capable of computing dense anatomical/semantic correspondences be- tween two images at the pixel level. Our method is named SAM-enhanced registration (SAME), which breaks down image registration into three steps: ane transformation, coarse deformation, and deep deformable registration. Using SAM embeddings, we enhance these steps by nd- ing more coherent correspondences, and providing features and a loss function with better semantic guidance. We collect a multi-phase chest computed tomography dataset with 35 annotated organs for each patient and conduct inter-subject registration for quantitative evaluation. Re- sults show that SAME outperforms widely-used traditional registration techniques (Elastix FFD, ANTs SyN) and learning based VoxelMorph method by at least 4 :7% and 2 :7% in Dice scores for two separate tasks of within-contrast-phase and across-contrast-phase registration, respec- tively. SAME achieves the comparable performance to the best tradi- tional registration method, DEEDS (from our evaluation), while being orders of magnitude faster (from 45 seconds to 1.2 seconds). (@liu_same_2021)

Andreas Mang, Amir Gholami, Christos Davatzikos, and George Biros : A distributed-memory solver for constrained large deformation diffeomorphic image registration , 41(5):C548–C584, January 2019. arXiv:1808.04487 \[cs, math\]. **Abstract:** With this work, we release CLAIRE, a distributed-memory implementation of an effective solver for constrained large deformation diffeomorphic image registration problems in three dimensions. We consider an optimal control formulation. We invert for a stationary velocity field that parameterizes the deformation map. Our solver is based on a globalized, preconditioned, inexact reduced space Gauss–Newton–Krylov scheme. We exploit state-of-the-art techniques in scientific computing to develop an effective solver that scales to thousands of distributed memory nodes on high-end clusters. We present the formulation, discuss algorithmic features, describe the software package, and introduce an improved preconditioner for the reduced space Hessian to speed up the convergence of our solver. We test registration performance on synthetic and real data. We demonstrate registration accuracy on several neuroimaging datasets. We compare the performance of our scheme against different flavors of the Demons algorithm for diffeomorphic image registration. We study convergence of our preconditioner and our overall algorithm. We report scalability results on state-of-the-art supercomputing platforms. We demonstrate that we can solve registration problems for clinically relevant data sizes in two to four minutes on a standard compute node with 20 cores, attaining excellent data fidelity. With the present work we achieve a speedup of (on average) 5$\\}times$ with a peak performance of up to 17$\\}times$ compared to our former work. (@mang_claire_2019)

Andreas Mang and Lars Ruthotto A lagrangian gauss–newton–krylov solver for mass-and intensity-preserving diffeomorphic image registration , 39(5):B860–B885, 2017. **Abstract:** We present an efficient solver for diffeomorphic image registration problems in the framework of Large Deformations Diffeomorphic Metric Mappings (LDDMM). We use an optimal control formulation, in which the velocity field of a hyperbolic PDE needs to be found such that the distance between the final state of the system (the transformed/transported template image) and the observation (the reference image) is minimized. Our solver supports both stationary and non-stationary (i.e., transient or time-dependent) velocity fields. As transformation models, we consider both the transport equation (assuming intensities are preserved during the deformation) and the continuity equation (assuming mass-preservation). We consider the reduced form of the optimal control problem and solve the resulting unconstrained optimization problem using a discretize-then-optimize approach. A key contribution is the elimination of the PDE constraint using a Lagrangian hyperbolic PDE solver. Lagrangian methods rely on the concept of characteristic curves that we approximate here using a fourth-order Runge-Kutta method. We also present an efficient algorithm for computing the derivatives of final state of the system with respect to the velocity field. This allows us to use fast Gauss-Newton based methods. We present quickly converging iterative linear solvers using spectral preconditioners that render the overall optimization efficient and scalable. Our method is embedded into the image registration framework FAIR and, thus, supports the most commonly used similarity measures and regularization functionals. We demonstrate the potential of our new approach using several synthetic and real world test problems with up to 14.7 million degrees of freedom. (@mang2017lagrangian)

Daniel S Marcus, Tracy H Wang, Jamie Parker, John G Csernansky, John C Morris, and Randy L Buckner Open access series of imaging studies (oasis): cross-sectional mri data in young, middle aged, nondemented, and demented older adults , 19(9):1498–1507, 2007. **Abstract:** Abstract The Open Access Series of Imaging Studies is a series of magnetic resonance imaging data sets that is publicly available for study and analysis. The initial data set consists of a cross-sectional collection of 416 subjects aged 18 to 96 years. One hundred of the included subjects older than 60 years have been clinically diagnosed with very mild to moderate Alzheimer’s disease. The subjects are all right-handed and include both men and women. For each subject, three or four individual T1-weighted magnetic resonance imaging scans obtained in single imaging sessions are included. Multiple within-session acquisitions provide extremely high contrast-to-noise ratio, making the data amenable to a wide range of analytic approaches including automated computational analysis. Additionally, a reliability data set is included containing 20 subjects without dementia imaged on a subsequent visit within 90 days of their initial session. Automated calculation of whole-brain volume and estimated total intracranial volume are presented to demonstrate use of the data for measuring differences associated with normal aging and Alzheimer’s disease. (@oasisdataset)

Michael I. Miller, Alain Trouvé, and Laurent Younes On the Metrics and Euler-Lagrange Equations of Computational Anatomy , 4(1):375–405, 2002. \_eprint: https://doi.org/10.1146/annurev.bioeng.4.092101.125733. **Abstract:** This paper reviews literature, current concepts and approaches in computational anatomy (CA). The model of CA is a Grenander deformable template, an orbit generated from a template under groups of diffeomorphisms. The metric space of all anatomical images is constructed from the geodesic connecting one anatomical structure to another in the orbit. The variational problems specifying these metrics are reviewed along with their associated Euler-Lagrange equations. The Euler equations of motion derived by Arnold for the geodesics in the group of divergence-free volume-preserving diffeomorphisms of incompressible fluids are generalized for the larger group of diffeomorphisms used in CA with nonconstant Jacobians. Metrics that accommodate photometric variation are described extending the anatomical model to incorporate the construction of neoplasm. Metrics on landmarked shapes are reviewed as well as Joshi’s diffeomorphism metrics, Bookstein’s thin-plate spline approximate-metrics, and Kendall’s affine invariant metrics. We conclude by showing recent experimental results from the Toga & Thompson group in growth, the Van Essen group in macaque and human cortex mapping, and the Csernansky group in hippocampus mapping for neuropsychiatric studies in aging and schizophrenia. (@miller_metrics_2002)

Marc Modat, Gerard R Ridgway, Zeike A Taylor, Manja Lehmann, Josephine Barnes, David J Hawkes, Nick C Fox, and Sébastien Ourselin Fast free-form deformation using graphics processing units , 98(3):278–284, 2010. **Abstract:** A large number of algorithms have been developed to perform n on-rigid reg- istration and it is a tool commonly used in medical image anal ysis. The Free- Form Deformation algorithm is a well-established techniqu e, but is extremely time consuming. In this paper we present a parallel-friendl y formulation of the algorithm suitable for Graphics Processing Unit execut ion. Using our approach we perform registration of T1-weighted MR images i n less than 1 minute and show the same level of accuracy as a classical serial implemen- tation when performing segmentation propagation. This tec hnology could be of signiﬁcant utility in time-critical applications suc h as image-guided interventions, or in the processing of large data sets. (@niftyreg)

Tony C. W. Mok and Albert C. S. Chung Large Deformation Diffeomorphic Image Registration with Laplacian Pyramid Networks June 2020. arXiv:2006.16148 \[cs, eess\]. **Abstract:** Deep learning-based methods have recently demonstrated promising results in deformable image registration for a wide range of medical image analysis tasks. However, existing deep learning-based methods are usually limited to small deformation settings, and desirable properties of the transformation including bijective mapping and topology preservation are often being ignored by these approaches. In this paper, we propose a deep Laplacian Pyramid Image Registration Network, which can solve the image registration optimization problem in a coarse-to-fine fashion within the space of diffeomorphic maps. Extensive quantitative and qualitative evaluations on two MR brain scan datasets show that our method outperforms the existing methods by a significant margin while maintaining desirable diffeomorphic properties and promising registration speed. (@mok_large_2020)

Tony CW Mok and Albert Chung Fast symmetric diffeomorphic image registration with convolutional neural networks In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*, pages 4644–4653, 2020. **Abstract:** Diffeomorphic deformable image registration is crucial in many medical image studies, as it offers unique, special features including topology preservation and invertibility of the transformation. Recent deep learning-based deformable image registration methods achieve fast image registration by leveraging a convolutional neural network (CNN) to learn the spatial transformation from the synthetic ground truth or the similarity metric. However, these approaches often ignore the topology preservation of the transformation and the smoothness of the transformation which is enforced by a global smoothing energy function alone. Moreover, deep learning-based approaches often estimate the displacement field directly, which cannot guarantee the existence of the inverse transformation. In this paper, we present a novel, efficient unsupervised symmetric image registration method which maximizes the similarity between images within the space of diffeomorphic maps and estimates both forward and inverse transformations simultaneously. We evaluate our method on 3D image registration with a large scale brain image dataset. Our method achieves state-of-the-art registration accuracy and running time while maintaining desirable diffeomorphic properties. (@mok2020fast)

Tony CW Mok and Albert Chung Affine medical image registration with coarse-to-fine vision transformer In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 20835–20844, 2022. **Abstract:** Affine registration is indispensable in a comprehensive medical image registration pipeline. However, only a few studies focus on fast and robust affine registration algorithms. Most of these studies utilize convolutional neural networks (CNNs) to learn joint affine and non-parametric registration, while the standalone performance of the affine subnetwork is less explored. Moreover, existing CNN-based affine registration approaches focus either on the local mis-alignment or the global orientation and position of the input to predict the affine transformation matrix, which are sensitive to spatial initialization and exhibit limited generalizability apart from the training dataset. In this paper, we present a fast and robust learning-based algorithm, Coarse-to-Fine Vision Transformer (C2FViT), for 3D affine medical image registration. Our method naturally leverages the global connectivity and locality of the convolutional vision transformer and the multi-resolution strategy to learn the global affine registration. We evaluate our method on 3D brain atlas registration and template-matching normalization. Comprehensive results demonstrate that our method is superior to the existing CNNs-based affine registration methods in terms of registration accuracy, robustness and generalizability while preserving the runtime advantage of the learning-based methods. The source code is available at https://github.com/cwmok/C2FViT. (@mok2022affine)

Tony CW Mok and Albert CS Chung Large deformation diffeomorphic image registration with laplacian pyramid networks pages 211–221, 2020. **Abstract:** Deep learning-based methods have recently demonstrated promising results in deformable image registration for a wide range of medical image analysis tasks. However, existing deep learning-based meth- ods are usually limited to small deformation settings, and desirable prop- erties of the transformation including bijective mapping and topology preservation are often being ignored by these approaches. In this pa- per, we propose a deep Laplacian Pyramid Image Registration Network, which can solve the image registration optimization problem in a coarse- to- ne fashion within the space of di eomorphic maps. Extensive quan- titative and qualitative evaluations on two MR brain scan datasets show that our method outperforms the existing methods by a signi cant mar- gin while maintaining desirable di eomorphic properties and promising registration speed. (@mok2020large)

Tony CW Mok and Albert CS Chung Conditional deformable image registration with convolutional neural network pages 35–45, 2021. **Abstract:** Recent deep learning-based methods have shown promising results and runtime advantages in deformable image registration. How- ever, analyzing the e ects of hyperparameters and searching for optimal regularization parameters prove to be too prohibitive in deep learning- based methods. This is because it involves training a substantial num- ber of separate models with distinct hyperparameter values. In this pa- per, we propose a conditional image registration method and a new self- supervised learning paradigm for deep deformable image registration. By learning the conditional features that are correlated with the regulariza- tion hyperparameter, we demonstrate that optimal solutions with arbi- trary hyperparameters can be captured by a single deep convolutional neural network. In addition, the smoothness of the resulting deformation eld can be manipulated with arbitrary strength of smoothness regular- ization during inference. Extensive experiments on a large-scale brain MRI dataset show that our proposed method enables the precise con- trol of the smoothness of the deformation eld without sacri cing the runtime advantage or registration accuracy. (@mok2021conditional)

Annette Moter and Ulf B Göbel Fluorescence in situ hybridization (fish) for direct visualization of microorganisms , 41(2):85–112, 2000. (@moter2000fluorescence)

Keelin Murphy, Bram Van Ginneken, Joseph M Reinhardt, Sven Kabus, Kai Ding, Xiang Deng, Kunlin Cao, Kaifang Du, Gary E Christensen, Vincent Garcia, et al Evaluation of registration methods on thoracic ct: the empire10 challenge , 30(11):1901–1920, 2011. **Abstract:** EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration 2010) is a public platform for fair and meaningful comparison of registration algorithms which are applied to a database of intrapatient thoracic CT image pairs. Evaluation of nonrigid registration techniques is a nontrivial task. This is compounded by the fact that researchers typically test only on their own data, which varies widely. For this reason, reliable assessment and comparison of different registration algorithms has been virtually impossible in the past. In this work we present the results of the launch phase of EMPIRE10, which comprised the comprehensive evaluation and comparison of 20 individual algorithms from leading academic and industrial research groups. All algorithms are applied to the same set of 30 thoracic CT pairs. Algorithm settings and parameters are chosen by researchers expert in the configuration of their own method and the evaluation is independent, using the same criteria for all participants. All results are published on the EMPIRE10 website (http://empire10.isi.uu.nl). The challenge remains ongoing and open to new participants. Full results from 24 algorithms have been published at the time of writing. This paper details the organization of the challenge, the data and evaluation methods and the outcome of the initial launch with 20 algorithms. The gain in knowledge and future work are discussed. (@murphy2011evaluation)

Seung Wook Oh, Julie A Harris, Lydia Ng, Brent Winslow, Nicholas Cain, Stefan Mihalas, Quanxin Wang, Chris Lau, Leonard Kuan, Alex M Henry, et al A mesoscale connectome of the mouse brain , 508(7495):207–214, 2014. **Abstract:** Abstract The wiring diagram of the mouse brain has recently been mapped at a mesoscopic scale in the Allen Mouse Brain Connectivity Atlas. Axonal projections from brain regions were traced using green fluoresent proteins. The resulting data were registered to a common three-dimensional reference space. They yielded a matrix of connection strengths between 213 brain regions. Global features such as closed loops formed by connections of similar intensity can be inferred using tools from persistent homology. We map the wiring diagram of the mouse brain to a simplicial complex (filtered by connection strengths). We work out generators of the first homology group. Some regions, including nucleus accumbens, are connected to the entire brain by loops, whereas no region has non-zero connection strength to all brain regions. Thousands of loops go through the isocortex, the striatum and the thalamus. On the other hand, medulla is the only major brain compartment that contains more than 100 loops. (@oh2014mesoscale)

Seungjong Oh and Siyong Kim Deformable image registration in radiation therapy , 35(2):101, 2017. **Abstract:** A greyscale-based fully automatic deformable image registration algorithm, originally known as the ’demons’ algorithm, was implemented for CT image-guided radiotherapy. We accelerated the algorithm by introducing an ’active force’ along with an adaptive force strength adjustment during the iterative process. These improvements led to a 40% speed improvement over the original algorithm and a high tolerance of large organ deformations. We used three methods to evaluate the accuracy of the algorithm. First, we created a set of mathematical transformations for a series of patient’s CT images. This provides a ’ground truth’ solution for quantitatively validating the deformable image registration algorithm. Second, we used a physically deformable pelvic phantom, which can measure deformed objects under different conditions. The results of these two tests allowed us to quantify the accuracy of the deformable registration. Validation results showed that more than 96% of the voxels were within 2 mm of their intended shifts for a prostate and a head-and-neck patient case. The mean errors and standard deviations were 0.5 mm ± 1.5 mm and 0.2 mm ± 0.6 mm, respectively. Using the deformable pelvis phantom, the result showed a tracking accuracy of better than 1.5 mm for 23 seeds implanted in a phantom prostate that was deformed by inflation of a rectal balloon. Third, physician-drawn contours outlining the tumour volumes and certain anatomical structures in the original CT images were deformed along with the CT images acquired during subsequent treatments or during a different respiratory phase for a lung cancer case. Visual inspection of the positions and shapes of these deformed contours agreed well with human judgment. Together, these results suggest that the accelerated demons algorithm has significant potential for delineating and tracking doses in targets and critical structures during CT-guided radiotherapy. (@oh2017deformable)

Omar E Olarte, Jordi Andilla, Emilio J Gualda, and Pablo Loza-Alvarez Light-sheet microscopy: a tutorial , 10(1):111–179, 2018. **Abstract:** This paper is intended to give a comprehensive review of light-sheet (LS) microscopy from an optics perspective.As such, emphasis is placed on the advantages that LS microscope configurations present, given the degree of freedom gained by uncoupling the excitation and detection arms.The new imaging properties are first highlighted in terms of optical parameters and how these have enabled several biomedical applications.Then, the basics are presented for understanding how a LS microscope works.This is followed by a presentation of a tutorial for LS microscope designs, each working at different resolutions and for different applications.Then, based on a numerical Fourier analysis and given the multiple possibilities for generating the LS in the microscope (using Gaussian, Bessel, and Airy beams in the linear and nonlinear regimes), a systematic comparison of their optical performance is presented.Finally, based on advances in optics and photonics, the novel optical implementations possible in a LS microscope are highlighted. (@olarte2018light)

Karsten Østergaard Noe, Baudouin Denis De Senneville, Ulrik Vindelev Elstrøm, Kari Tanderup, and Thomas Sangild Sørensen Acceleration and validation of optical flow based deformable registration for image-guided radiotherapy , 47(7):1286–1293, 2008. **Abstract:** Materials and methods. Two registration methods based on optical flow estimation have been programmed to run on a graphics programming unit (GPU). One of these methods by Horn & Schunck is tested on a 4DCT thorax data set with 10 phases and 41 landmarks identified per phase. The other method by Cornelius & Kanade is tested on a series of six 3D cone beam CT (CBCT) data sets and a conventional planning CT data set from a head and neck cancer patient. In each of these data sets 6 landmark points have been identified on the cervical vertebrae and the base of skull. Both CBCT to CBCT and CBCT to CT registration is performed. Results. For the 4DCT registration average landmark error was reduced by deformable registration from 3.5±2.0mm to 1.1±0.6mm. For CBCT to CBCT registration the average bone landmark error was 1.8±1.0mm after rigid registration and 1.6±0.8mm after deformable registration. For CBCT to CT registration errors were 2.2±0.6mm and 1.8±0.6mm for rigid and deformable registration respectively. Using GPU hardware the Horn & Schunck method was accelerated by a factor of 48. The 4DCT registration can be performed in 37seconds. The head and neck cancer patient registration takes 64seconds. Discussion. Compared to image slice thickness, which limits accuracy of landmark point determination, we consider the landmark point accuracy of the registration acceptable. The points identified in the CBCT images do not give a full impression of the result of doing deformable registration as opposed to rigid registration. A larger validation study is being planned in which soft tissue landmarks will facilitate tracking the deformable registration. The acceleration obtained using GPU hardware means that registration can be done online for CBCT. (@ostergaard2008opticalflow)

Hanchuan Peng, Phuong Chung, Fuhui Long, Lei Qu, Arnim Jenett, Andrew M Seeds, Eugene W Myers, and Julie H Simpson Brainaligner: 3d registration atlases of drosophila brains , 8(6):493–498, 2011. **Abstract:** Analyzing Drosophila neural expression patterns in thousands of 3D image stacks of individual brains requires registering them into a canonical framework based on a fiducial reference of neuropil morphology. Given a target brain labeled with predefined landmarks, the BrainAligner program automatically finds the corresponding landmarks in a subject brain and maps it to the coordinate system of the target brain via a deformable warp. Using a neuropil marker (the antibody nc82) as a reference of the brain morphology and a target brain that is itself a statistical average of 295 brains, we achieved a registration accuracy of 2µm on average, permitting assessment of stereotypy, potential connectivity, and functional mapping of the adult fruitfly brain. We used BrainAligner to generate an image pattern atlas of 2,954 registered brains containing 470 different expression patterns that cover all the major compartments of the fly brain. (@peng2011brainaligner)

Javier Pérez de Frutos, André Pedersen, Egidijus Pelanis, David Bouget, Shanmugapriya Survarachakan, Thomas Langø, Ole-Jakob Elle, and Frank Lindseth Learning deep abdominal ct registration through adaptive loss weighting and synthetic data generation , 18(2):e0282110, 2023. **Abstract:** Purpose: This study aims to explore training strategies to improve convolutional neural network-based image-to-image deformable registration for abdominal imaging. Methods: Different training strategies, loss functions, and transfer learning schemes were considered. Furthermore, an augmentation layer which generates artificial training image pairs on-the-fly was proposed, in addition to a loss layer that enables dynamic loss weighting. Results: Guiding registration using segmentations in the training step proved beneficial for deep-learning-based image registration. Finetuning the pretrained model from the brain MRI dataset to the abdominal CT dataset further improved performance on the latter application, removing the need for a large dataset to yield satisfactory performance. Dynamic loss weighting also marginally improved performance, all without impacting inference runtime. Conclusion: Using simple concepts, we improved the performance of a commonly used deep image registration architecture, VoxelMorph. In future work, our framework, DDMR, should be validated on different datasets to further assess its value. (@perez2023learning)

Chen Qin, Shuo Wang, Chen Chen, Wenjia Bai, and Daniel Rueckert Generative Myocardial Motion Tracking via Latent Space Exploration with Biomechanics-informed Prior June 2022. arXiv:2206.03830 \[cs, eess\]. **Abstract:** Myocardial motion and deformation are rich descriptors that characterize cardiac function. Image registration, as the most commonly used technique for myocardial motion tracking, is an ill-posed inverse problem which often requires prior assumptions on the solution space. In contrast to most existing approaches which impose explicit generic regularization such as smoothness, in this work we propose a novel method that can implicitly learn an application-specific biomechanics-informed prior and embed it into a neural network-parameterized transformation model. Particularly, the proposed method leverages a variational autoencoder-based generative model to learn a manifold for biomechanically plausible deformations. The motion tracking then can be performed via traversing the learnt manifold to search for the optimal transformations while considering the sequence information. The proposed method is validated on three public cardiac cine MRI datasets with comprehensive evaluations. The results demonstrate that the proposed method can outperform other approaches, yielding higher motion tracking accuracy with reasonable volume preservation and better generalizability to varying data distributions. It also enables better estimates of myocardial strains, which indicates the potential of the method in characterizing spatiotemporal signatures for understanding cardiovascular diseases. (@qin_generative_2022-1)

Chen Qin, Shuo Wang, Chen Chen, Huaqi Qiu, Wenjia Bai, and Daniel Rueckert Biomechanics-informed Neural Networks for Myocardial Motion Tracking in MRI July 2020. arXiv:2006.04725 \[cs, eess\]. **Abstract:** Image registration is an ill-posed inverse problem which often requires regularisation on the solution space. In contrast to most of the current approaches which impose explicit regularisation terms such as smoothness, in this paper we propose a novel method that can implicitly learn biomechanics-informed regularisation. Such an approach can incorporate application-specific prior knowledge into deep learning based registration. Particularly, the proposed biomechanics-informed regularisation leverages a variational autoencoder (VAE) to learn a manifold for biomechanically plausible deformations and to implicitly capture their underlying properties via reconstructing biomechanical simulations. The learnt VAE regulariser then can be coupled with any deep learning based registration network to regularise the solution space to be biomechanically plausible. The proposed method is validated in the context of myocardial motion tracking on 2D stacks of cardiac MRI data from two different datasets. The results show that it can achieve better performance against other competing methods in terms of motion tracking accuracy and has the ability to learn biomechanical properties such as incompressibility and strains. The method has also been shown to have better generalisability to unseen domains compared with commonly used L2 regularisation schemes. (@qin_biomechanics-informed_2020)

Huaqi Qiu, Chen Qin, Andreas Schuh, Kerstin Hammernik, and Daniel Rueckert Learning diffeomorphic and modality-invariant registration using b-splines . (@qiu2021learning)

Lei Qu, Fuhui Long, and Hanchuan Peng -d registration of biological images and models: registration of microscopic images and its uses in segmentation and annotation , 32(1):70–77, 2014. **Abstract:** The registration, segmentation, and annotation of microscopy images and respective biological objects (e.g., cells) are distinct challenges often encountered in bioimage informatics. Here we present several studies in widely used model systems of the fruit fly, zebrafish, and C. elegans to demonstrate how registration methods have been employed to align three-dimensional (3-D) brain images at a very large scale and to solve challenging segmentation and annotation problems for 3-D cellular images. Specifically, we consider two types of registration between images and models: image-to-image registration and model-to-image registration, where a model consists of a description of the geometrical shape or the spatial layout of biological objects in the respective images. (@qu20143)

Marc-Michel Rohé, Manasi Datar, Tobias Heimann, Maxime Sermesant, and Xavier Pennec Svf-net: learning deformable image registration using shape matching In *Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20*, pages 266–274. Springer, 2017. **Abstract:** In this paper, we propose an innovative approach for regis- tration based on the deterministic prediction of the parameters from both images instead of the optimization of a energy criteria. The method relies on a fully convolutional network whose architecture consists of contract- ing layers to detect relevant features and a symmetric expanding path that matches them together and outputs the transformation parametriza- tion. Whereas convolutional networks have seen a widespread expansion and have been already applied to many medical imaging problems such as segmentation and classi cation, its application to registration has so far faced the challenge of de ning ground truth data on which to train the algorithm. Here, we present a novel training strategy to build refer- ence deformations which relies on the registration of segmented regions of interest. We apply this methodology to the problem of inter-patient heart registration and show an important improvement over a state of the art optimization based algorithm. Not only our method is more ac- curate but it is also faster - registration of two 3 D-images taking less than 30 mssecond on a GPU - and more robust to outliers. 1 Introduction Non-linear registration - the process of nding voxel correspondence between pair of images - is a key instrument in computational anatomy and has gained an increasing importance in the past years. Traditional methods to nd the optimal deformation eld mapping two images rely on the optimization of a matching criteria controlling the local correspondence of the voxel intensities. These methods usually have several drawbacks: their high computational cost (time and memory) as they often requires many iterations and evaluations of the energy function \[3\] and also the possibility of the optimization to remain stuck in a local minimum because of the non-convexity of the objective function. New approaches to predict registration parameters based on machine learning have been proposed. In particular, Convolutional Neural Networks have set new standards where there is a need to predict highly non-linear function. Whereas these methods have gained large popularity for medical image segmentation and classi cation, they are still underrepresented in the context of image registration due to the diculty to provide a ground truth mapping between pairs of images.While it is possible for a human to classify an image or to draw the contours of the segmentation, the task of de ning pai (@rohe2017svf)

Julian G Rosenman, Elizabeth P Miller, and Tim J Cullip Image registration: an essential part of radiation therapy treatment planning , 40(1):197–205, 1998. (@rosenman1998image)

Hanna Siebert, Lasse Hansen, and Mattias P Heinrich Fast 3d registration with accurate optimisation and little learning for learn2reg 2021. In *International Conference on Medical Image Computing and Computer-Assisted Intervention*, pages 174–179. Springer, 2021. **Abstract:** Current approaches for deformable medical image registra- tion often struggle to ful ll all of the following criteria: versatile ap- plicability, small computation or training times, and the being able to estimate large deformations. Furthermore, end-to-end networks for su- pervised training of registration often become overly complex and di- cult to train. For the Learn2Reg2021 challenge, we aim to address these issues by decoupling feature learning and geometric alignment. First, we introduce a new very fast and accurate optimisation method. By using discretised displacements and a coupled convex optimisation procedure, we are able to robustly cope with large deformations. With the help of an Adam-based instance optimisation, we achieve very accurate registration performances and by using regularisation, we obtain smooth and plau- sible deformation elds. Second, to be versatile for di erent registration tasks, we extract hand-crafted features that are modality and contrast in- variant and complement them with semantic features from a task-speci c segmentation U-Net. With our results we were able to achieve the over- all Learn2Reg2021 challenge’s second place, winning Task 1 and being second and third in the other two tasks. (@siebert2021fast)

Hessam Sokooti, Bob De Vos, Floris Berendsen, Boudewijn PF Lelieveldt, Ivana Išgum, and Marius Staring Nonrigid image registration using multi-scale 3d convolutional neural networks In *Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20*, pages 232–239. Springer, 2017. **Abstract:** Structural magnetic resonance imaging (MRI) studies have shown that Alzheimer’s Disease (AD) induces both localised and widespread neural degenerative changes throughout the brain. However, the absence of segmentation that highlights brain degenerative changes presents unique challenges for training CNN-based classifiers in a supervised fashion. In this work, we evaluated several unsupervised methods to train a feature extractor for downstream AD vs. CN classification. Using the 3D T1-weighted MRI data of cognitive normal (CN) subjects from the synthetic neuroimaging LDM100K dataset, lightweight 3D CNN-based models are trained for brain age prediction, brain image rotation classification, brain image reconstruction and a multi-head task combining all three tasks into one. Feature extractors trained on the LDM100K synthetic dataset achieved similar performance compared to the same model using real-world data. This supports the feasibility of utilising large-scale synthetic data for pretext task training. All the training and testing splits are performed on the subject-level to prevent data leakage issues. Alongside the simple preprocessing steps, the random cropping data augmentation technique shows consistent improvement across all experiments. (@sokooti2017nonrigid)

Joo Hyun Song, Gary E Christensen, Jeffrey A Hawley, Ying Wei, and Jon G Kuhl Evaluating image registration using nirep In *Biomedical Image Registration: 4th International Workshop, WBIR 2010, Lübeck, Germany, July 11-13, 2010. Proceedings 4*, pages 140–150. Springer, 2010. **Abstract:** Evaluating non-rigid image registration algorithm performance is a difficult problem since there is rarely a "gold standard" (i.e., known) correspondence between two images. This paper reports the analysis and comparison of five non-rigid image registration algorithms using the Non-Rigid Image Registration Evaluation Project (NIREP) (www.nirep.org) framework. The NIREP framework evaluates registration performance using centralized databases of well-characterized images and standard evaluation statistics (methods) which are implemented in a software package. The performance of five non-rigid registration algorithms (Affine, AIR, Demons, SLE and SICLE) was evaluated using 22 images from two NIREP neuroanatomical evaluation databases. Six evaluation statistics (relative overlap, intensity variance, normalized ROI overlap, alignment of calcarine sulci, inverse consistency error and transitivity error) were used to evaluate and compare image registration performance. The results indicate that the Demons registration algorithm produced the best registration results with respect to the relative overlap statistic but produced nearly the worst registration results with respect to the inverse consistency statistic. The fact that one registration algorithm produced the best result for one criterion and nearly the worst for another illustrates the need to use multiple evaluation statistics to fully assess performance. (@song2010evaluating)

Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro Ikeda, and Masashi Sugiyama Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators In *Advances in Neural Information Processing Systems*, volume 33, pages 3362–3373. Curran Associates, Inc., 2020. **Abstract:** Invertible neural networks based on coupling flows (CF-INNs) have various machine learning applications such as image synthesis and representation learning. However, their desirable characteristics such as analytic invertibility come at the cost of restricting the functional forms. This poses a question on their representation power: are CF-INNs universal approximators for invertible functions? Without a universality, there could be a well-behaved invertible transformation that the CF-INN can never approximate, hence it would render the model class unreliable. We answer this question by showing a convenient criterion: a CF-INN is universal if its layers contain affine coupling and invertible linear functions as special cases. As its corollary, we can affirmatively resolve a previously unsolved problem: whether normalizing flow models based on affine coupling can be universal distributional approximators. In the course of proving the universality, we prove a general theorem to show the equivalence of the universality for certain diffeomorphism classes, a theoretical insight that is of interest by itself. (@teshima_coupling-based_2020)

Lin Tian, Hastings Greer, François-Xavier Vialard, Roland Kwitt, Raúl San José Estépar, Richard Jarrett Rushmore, Nikolaos Makris, Sylvain Bouix, and Marc Niethammer Gradicon: Approximate diffeomorphisms via gradient inverse consistency In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 18084–18094, 2023. **Abstract:** We present an approach to learning regular spatial transformations between image pairs in the context of medical image registration. Contrary to optimization-based registration techniques and many modern learning-based methods, we do not directly penalize transformation irregularities but instead promote transformation regularity via an inverse consistency penalty. We use a neural network to predict a map between a source and a target image as well as the map when swapping the source and target images. Different from existing approaches, we compose these two resulting maps and regularize deviations of the Jacobian of this composition from the identity matrix. This regularizer - GradICON - results in much better convergence when training registration models compared to promoting inverse consistency of the composition of maps directly while retaining the desirable implicit regularization effects of the latter. We achieve state-of-the-art registration performance on a variety of real-world medical image datasets using a single set of hyperparameters and a single non-dataset-specific training protocol. Code is available at https://github.com/uncbiag/ICON. (@tian2023gradicon)

Lin Tian, Zi Li, Fengze Liu, Xiaoyu Bai, Jia Ge, Le Lu, Marc Niethammer, Xianghua Ye, Ke Yan, and Daikai Jin ++: A Self-supervised Anatomical eMbeddings Enhanced medical image registration framework using stable sampling and regularized transformation November 2023. arXiv:2311.14986 \[cs\]. **Abstract:** Image registration is a fundamental medical image analysis task. Ideally, registration should focus on aligning semantically corresponding voxels, i.e., the same anatomical locations. However, existing methods often optimize similarity measures computed directly on intensities or on hand-crafted features, which lack anatomical semantic information. These similarity measures may lead to sub-optimal solutions where large deformations, complex anatomical differences, or cross-modality imagery exist. In this work, we introduce a fast and accurate method for unsupervised 3D medical image registration building on top of a Self-supervised Anatomical eMbedding (SAM) algorithm, which is capable of computing dense anatomical correspondences between two images at the voxel level. We name our approach SAM-Enhanced registration (SAME++), which decomposes image registration into four steps: affine transformation, coarse deformation, deep non-parametric transformation, and instance optimization. Using SAM embeddings, we enhance these steps by finding more coherent correspondence and providing features with better semantic guidance. We extensively evaluated SAME++ using more than 50 labeled organs on three challenging inter-subject registration tasks of different body parts. As a complete registration framework, SAME++ markedly outperforms leading methods by $4.2\\}%$ - $8.2\\}%$ in terms of Dice score while being orders of magnitude faster than numerical optimization-based methods. Code is available at \\}url{https://github.com/alibaba-damo-academy/same}. (@tian_same_2023)

Arthur W Toga and Paul M Thompson The role of image registration in brain mapping , 19(1-2):3–24, 2001. **Abstract:** Image registration is a key step in a great variety of biomedical imaging applications. It provides the ability to geometrically align one dataset with another, and is a prerequisite for all imaging applications that compare datasets across subjects, imaging modalities, or across time. Registration algorithms also enable the pooling and comparison of experimental findings across laboratories, the construction of population-based brain atlases, and the creation of systems to detect group patterns in structural and functional imaging data. We review the major types of registration approaches used in brain imaging today. We focus on their conceptual basis, the underlying mathematics, and their strengths and weaknesses in different contexts. We describe the major goals of registration, including data fusion, quantification of change, automated image segmentation and labeling, shape measurement, and pathology detection. We indicate that registration algorithms have great potential when used in conjunction with a digital brain atlas, which acts as a reference system in which brain images can be compared for statistical analysis. The resulting armory of registration approaches is fundamental to medical image analysis, and in a brain mapping context provides a means to elucidate clinical, demographic, or functional trends in the anatomy or physiology of the brain. (@toga2001role)

Nicholas J Tustison, Hans J Johnson, Torsten Rohlfing, Arno Klein, Satrajit S Ghosh, Luis Ibanez, and Brian B Avants Instrumentation bias in the use and evaluation of scientific software: recommendations for reproducible practices in the computational sciences 2013. **Abstract:** OPINION article Front. Neurosci., 09 September 2013Sec. Brain Imaging Methods Volume 7 - 2013 \| https://doi.org/10.3389/fnins.2013.00162 (@tustison2013instrumentation)

Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky Deep Image Prior , 128(7):1867–1888, July 2020. arXiv:1711.10925 \[cs, stat\]. **Abstract:** Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity. Code and supplementary material are available at https://dmitryulyanov.github.io/deep_image_prior . (@ulyanov_deep_2020)

Hristina Uzunova, Matthias Wilms, Heinz Handels, and Jan Ehrhardt Training cnns for image registration from few samples with model-based data augmentation In *Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20*, pages 223–231. Springer, 2017. **Abstract:** In this article, we present a deep learning approach to sketch-based shape retrieval that incorporates a few novel techniques to improve the quality of the retrieval results. First, to address the problem of scarcity of training sketch data, we present a sketch augmentation method that more closely mimics human sketches compared to simple image transformation. Our method generates more sketches from the existing training data by (i) removing a stroke, (ii) adjusting a stroke, and (iii) rotating the sketch. As such, we generate a large number of sketch samples for training our neural network. Second, we obtain the 2D renderings of each 3D model in the shape database by determining the view positions that best depict the 3D shape: i.e., avoiding self-occlusion, showing the most salient features, and following how a human would normally sketch the model. We use a convolutional neural network (CNN) to learn the best viewing positions of each 3D model and generates their 2D images for the next step. Third, our method uses a cross-domain learning strategy based on two Siamese CNNs that pair up sketches and the 2D shape images. A joint Bayesian measure is used to measure the output similarity from these CNNs to maximize inter-class similarity and minimize intra-class similarity. Extensive experiments show that our proposed approach comprehensively outperforms many existing state-of-the-art methods. (@uzunova2017training)

David C Van Essen, Heather A Drury, Sarang Joshi, and Michael I Miller Functional and structural mapping of human cerebral cortex: solutions are in the surfaces , 95(3):788–795, 1998. **Abstract:** The human cerebral cortex is notorious for the depth and irregularity of its convolutions and for its variability from one individual to the next. These complexities of cortical geography have been a chronic impediment to studies of functional specialization in the cortex. In this report, we discuss ways to compensate for the convolutions by using a combination of strategies whose common denominator involves explicit reconstructions of the cortical surface. Surface-based visualization involves reconstructing cortical surfaces and displaying them, along with associated experimental data, in various complementary formats (including three-dimensional native configurations, two-dimensional slices, extensively smoothed surfaces, ellipsoidal representations, and cortical flat maps). Generating these representations for the cortex of the Visible Man leads to a surface-based atlas that has important advantages over conventional stereotaxic atlases as a substrate for displaying and analyzing large amounts of experimental data. We illustrate this by showing the relationship between functionally specialized regions and topographically organized areas in human visual cortex. Surface-based warping allows data to be mapped from individual hemispheres to a surface-based atlas while respecting surface topology, improving registration of identifiable landmarks, and minimizing unwanted distortions. Surface-based warping also can aid in comparisons between species, which we illustrate by warping a macaque flat map to match the shape of a human flat map. Collectively, these approaches will allow more refined analyses of commonalities as well as individual differences in the functional organization of primate cerebral cortex. (@van1998functional)

Erdem Varol, Amin Nejatbakhsh, Ruoxi Sun, Gonzalo Mena, Eviatar Yemini, Oliver Hobert, and Liam Paninski Statistical atlas of c. elegans neurons In *Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part V 23*, pages 119–129. Springer, 2020. **Abstract:** Constructing a statistical atlas of neuron positions in the ne- matode Caenorhabditis elegans enables a wide range of applications that require neural identity. These applications include annotating gene ex- pression, extracting calcium activity, and evaluating nervous-system mu- tations. Large complete sets of neural annotations are necessary to deter- mine canonical neuron positions and their associated con dence regions. Recently, a strain of C. elegans ("NeuroPAL") has been introduced to as- sign correct identities to all neurons in the worm via a deterministic, u- orescent colormap. This strain has enabled ecient and accurate annota- tion of worm neurons. Using a dataset of 10 worms, we propose a statisti- cal model that captures the latent means and covariances of neuron loca- tions, with ecient optimization strategies to infer model parameters. We demonstrate the utility of this model in two critical applications. First, we use our trained atlas to automatically annotate neuron identities in C. elegans at the state-of-the-art rate. Second, we use our atlas to compute canonical correlations between neuron positions, thereby determining co- variance in neuron placement. The code to replicate the statistical atlas is distributed publicly at https://github.com/amin-nejat/StatAtlas. 1 Introduction Imaging-based atlases of human and animal brains have enabled the princi- pled and standardized means of hypothesis testing in a wide variety of do- mains \[3,20,7,10,13,12,15\]. Common procedures that atlases enable are the reg- istration of population samples to a common space \[23\], discriminating pattern di erences across samples \[2\], segmentation into regions of interest \[4\], and regu- larizing complex Bayesian models \[17\]. Importantly, atlases enable the formation of large-scale population studies due to their ability to gather high-dimensional data into a commensurate space. C. elegans is a widely studied model organism with a simple nervous system that consists of 302 neurons in the adult hermaphrodite \[21\]. Its simplicity and2 E. Varol et al. stereotypy have enabled highly-reproducible experimental settings which have been crucial in elucidating neuroscienti c hypotheses. Furthermore, to date, C. elegans is the only animal whose connectome is completely mapped \[21,9,6\]. De- spite this atlas of connectivity, there have been no large-scale attempts at quan- tifying the variability of the neuron positions. This is due to the limited number of samples avai (@varol2020statistical)

Vivek Venkatachalam, Ni Ji, Xian Wang, Christopher Clark, James Kameron Mitchell, Mason Klein, Christopher J Tabone, Jeremy Florman, Hongfei Ji, Joel Greenwood, et al Pan-neuronal imaging in roaming caenorhabditis elegans , 113(8):E1082–E1088, 2016. **Abstract:** We present an imaging system for pan-neuronal recording in crawling Caenorhabditis elegans. A spinning disk confocal microscope, modified for automated tracking of the C. elegans head ganglia, simultaneously records the activity and position of ∼80 neurons that coexpress cytoplasmic calcium indicator GCaMP6s and nuclear localized red fluorescent protein at 10 volumes per second. We developed a behavioral analysis algorithm that maps the movements of the head ganglia to the animal’s posture and locomotion. Image registration and analysis software automatically assigns an index to each nucleus and calculates the corresponding calcium signal. Neurons with highly stereotyped positions can be associated with unique indexes and subsequently identified using an atlas of the worm nervous system. To test our system, we analyzed the brainwide activity patterns of moving worms subjected to thermosensory inputs. We demonstrate that our setup is able to uncover representations of sensory input and motor output of individual neurons from brainwide dynamics. Our imaging setup and analysis pipeline should facilitate mapping circuits for sensory to motor transformation in transparent behaving animals such as C. elegans and Drosophila larva. (@venkatachalam2016pan)

Tom Vercauteren, Xavier Pennec, Aymeric Perchant, and Nicholas Ayache Non-parametric diffeomorphic image registration with the demons algorithm In *International conference on medical image computing and computer-assisted intervention*, pages 319–326. Springer, 2007. (@vercauteren2007non)

Tom Vercauteren, Xavier Pennec, Aymeric Perchant, and Nicholas Ayache Symmetric Log-Domain Diffeomorphic Registration: A Demons-Based Approach In Dimitris Metaxas, Leon Axel, Gabor Fichtinger, and Gábor Székely, editors, *Medical Image Computing and Computer-Assisted Intervention – MICCAI 2008*, Lecture Notes in Computer Science, pages 754–761, Berlin, Heidelberg, 2008. Springer. **Abstract:** Modern morphometric studies use non-linear image regis- tration to compare anatomies and perform group analysis. Rece ntly, log- Euclidean approaches have contributed to promote the use of su ch com- putational anatomy tools by permitting simple computations of statis- tics on a rather large class of invertible spatial transformat ions. In this work, we propose a non-linear registration algorithm perfe ctly ﬁt for log- Euclidean statistics on diﬀeomorphisms. Our algorithm works completely in the log-domain, i.e. it uses a stationary velocity ﬁeld. Th is implies that we guarantee the invertibility of the deformation and have a ccess to the true inverse transformation. This also means that our outpu t can be directly used for log-Euclidean statistics without relying on the heavy computation of the log of the spatial transformation. As it is often desir- able, our algorithm is symmetric with respect to the order of t he input images. Furthermore, we use an alternate optimization appro ach related to Thirion’s demons algorithm to provide a fast non-linear r egistration algorithm. First results show that our algorithm outperfor ms both the demons algorithm and the recently proposed diﬀeomorphic dem ons algo- rithm in terms of accuracy of the transformation while remainin g com- putationally eﬃcient. 1 Introduction Non-linear image registration has opened the way for computa tional character- ization of morphological evolution and morphological vari ability. Most compu- tational anatomy tools make use of registration results \[1– 4\] but require that they satisfy some advanced properties such as invertibilit y and symmetry with respect to the order of the inputs. Image registration schem es can thus only be used if they meet the requirements of these tools. Large defo rmation diﬀeomor- phic methods have initially been developed for this purpose . Transformations are determined by a time-varying ordinary diﬀerential equatio n (ODE) \[5\]. Following the seminal work on inverse consistency \[6\], the large defor mations framework has also been extended to enforce the symmetry of the solutio n \[3,7\]. A widely acknowledged issue with the large deformation sett ing lies in its computational complexity and memory requirements. Recent work has strived towards bridging the gap between these rigorous mathematic al tools and very ef- ﬁcient non-linear registration schemes such as Thirion’s d emons algorithm \[8\]. On one hand it has been proposed to constrain the large deformat io (@vercauteren_symmetric_2008)

Tom Vercauteren, Xavier Pennec, Aymeric Perchant, and Nicholas Ayache Diffeomorphic demons: Efficient non-parametric image registration , 45(1):S61–S72, March 2009. **Abstract:** We propose an eﬃcient non-parametric diﬀeomorphic image re gistration algo- rithm based on Thirion’s demons algorithm. In the ﬁrst part o f this paper, we show that Thirion’s demons algorithm can be seen as an optimi zation procedure on the entire space of displacement ﬁelds. We provide strong theoretical roots to the diﬀerent variants of Thirion’s demons algorithm. Thi s analysis predicts a theoretical advantage for the symmetric forces variant of the demons algo- rithm. We show on controlled experiments that this advantag e is conﬁrmed in practice and yields a faster convergence. In the second part of this paper, we adapt the optimization procedure underlying the demons alg orithm to a space of diﬀeomorphic transformations. In contrast to many diﬀeo morphic registra- tion algorithms, our solution is computationally eﬃcient s ince in practice it only replaces an addition of displacement ﬁelds by a few composit ions. Our exper- iments show that in addition to being diﬀeomorphic, our algo rithm provides results that are similar to the ones from the demons algorith m but with trans- formations that are much smoother and closer to the gold stan dard, available in controlled experiments, in terms of Jacobians. (@vercauteren_diffeomorphic_2009)

Tom Vercauteren, Xavier Pennec, Aymeric Perchant, Nicholas Ayache, et al Diffeomorphic demons using itk’s finite difference solver hierarchy , 1, 2007. **Abstract:** This article provides an implementation of our non-parametric diffeomorphic image registration algorithm generalizing Thirion’s demons algorithm. Within the Insight Toolkit (ITK), the demons algorithm is implemented as part of the finite difference solver framework. We show that this framework can be extended to handle diffeomorphic transformations. The source code is composed of a set of reusable ITK filters and classes. In addition to an overview of our implementation, we provide a small example program that allows the user to compare the different variants of the demons algorithm. (@vercauteren2007diffeomorphic)

Quanxin Wang, Song-Lin Ding, Yang Li, Josh Royall, David Feng, Phil Lesnar, Nile Graddis, Maitham Naeemi, Benjamin Facer, Anh Ho, Tim Dolbeare, Brandon Blanchard, Nick Dee, Wayne Wakeman, Karla E. Hirokawa, Aaron Szafer, Susan M. Sunkin, Seung Wook Oh, Amy Bernard, John W. Phillips, Michael Hawrylycz, Christof Koch, Hongkui Zeng, Julie A. Harris, and Lydia Ng The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas , 181(4):936–953.e20, May 2020. **Abstract:** 3D brain atlases are key resources to understand the brain’s spatial organization and promote interoperability across different studies. However, unlike the adult mouse brain, the lack of developing mouse brain 3D reference atlases hinders advancements in understanding brain development. Here, we present a 3D developmental common coordinate framework (DevCCF) spanning embryonic day (E)11.5, E13.5, E15.5, E18.5, and postnatal day (P)4, P14, and P56, featuring undistorted morphologically averaged atlas templates created from magnetic resonance imaging and co-registered high-resolution light sheet fluorescence microscopy templates. The DevCCF with 3D anatomical segmentations can be downloaded or explored via an interactive 3D web-visualizer. As a use case, we utilize the DevCCF to unveil GABAergic neuron emergence in embryonic brains. Moreover, we map the Allen CCFv3 and spatial transcriptome cell-type data to our stereotaxic P56 atlas. In summary, the DevCCF is an openly accessible resource for multi-study data integration to advance our understanding of brain development. (@wang_allen_2020)

Yan Wang, Xu Wei, Fengze Liu, Jieneng Chen, Yuyin Zhou, Wei Shen, Elliot K. Fishman, and Alan L. Yuille Deep Distance Transform for Tubular Structure Segmentation in CT Scans In *2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, pages 3832–3841, Seattle, WA, USA, June 2020. IEEE. **Abstract:** Tubular structure segmentation in medical images, e.g., segmenting vessels in CT scans, serves as a vital step in the use of computers to aid in screening early stages of related diseases. But automatic tubular structure segmentation in CT scans is a challenging problem, due to issues such as poor contrast, noise and complicated background. A tubular structure usually has a cylinder-like shape which can be well represented by its skeleton and cross-sectional radii (scales). Inspired by this, we propose a geometry-aware tubular structure segmentation method, Deep Distance Transform (DDT), which combines intuitions from the classical distance transform for skeletonization and modern deep segmentation networks. DDT first learns a multi-task network to predict a segmentation mask for a tubular structure and a distance map. Each value in the map represents the distance from each tubular structure voxel to the tubular structure surface. Then the segmentation mask is refined by leveraging the shape prior reconstructed from the distance map. We apply our DDT on six medical image datasets. Results show that (1) DDT can boost tubular structure segmentation performance significantly (e.g., over 13% DSC improvement for pancreatic duct segmentation), and (2) DDT additionally provides a geometrical measurement for a tubular structure, which is important for clinical diagnosis (e.g., the cross-sectional scale of a pancreatic duct can be an indicator for pancreatic cancer). (@wang_deep_2020)

Asmamaw T Wassie, Yongxin Zhao, and Edward S Boyden Expansion microscopy: principles and uses in biological research , 16(1):33–41, 2019. **Abstract:** Organ-on-chip systems are promising new in vitro research tools in medical, pharmaceutical, and biological research. Their main benefit, compared to standard cell culture platforms, lies in the improved in vivo resemblance of the cell culture environment. A critical aspect of these systems is the ability to monitor both the cell culture conditions and biological responses of the cultured cells, such as proliferation and differentiation rates, release of signaling molecules, and metabolic activity. Today, this is mostly done using microscopy techniques and off-chip analytical techniques and assays. Integrating in situ analysis methods on-chip enables improved time resolution, continuous measurements, and a faster read-out; hence, more information can be obtained from the developed organ and disease models. Integrated electrical, electrochemical, and optical sensors have been developed and used for chemical analysis in lab-on-a-chip systems for many years, and recently some of these sensing principles have started to find use in organ-on-chip systems as well. This perspective review describes the basic sensing principles, sensor fabrication, and sensor integration in organ-on-chip systems. The review also presents the current state of the art of integrated sensors and discusses future potential. We bring a technological perspective, with the aim of introducing in-line sensing and its promise to advance organ-on-chip systems and the challenges that lie in the integration to researchers without expertise in sensor technology. (@wassie2019expansion)

Jelmer M Wolterink, Jesse C Zwienenberg, and Christoph Brune Implicit Neural Representations for Deformable Image Registration page 11. (@wolterink_implicit_nodate)

Jelmer M Wolterink, Jesse C Zwienenberg, and Christoph Brune Implicit neural representations for deformable image registration In *International Conference on Medical Imaging with Deep Learning*, pages 1349–1359. PMLR, 2022. (@wolterink2022implicit)

Yifan Wu, Tom Z. Jiahao, Jiancong Wang, Paul A. Yushkevich, M. Ani Hsieh, and James C. Gee : A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration , February 2022. arXiv: 2108.03443. **Abstract:** Deformable image registration (DIR), aiming to find spatial correspondence between images, is one of the most critical problems in the domain of medical image analysis. In this paper, we present a novel, generic, and accurate diffeomorphic image registration framework that utilizes neural ordinary differential equations (NODEs). We model each voxel as a moving particle and consider the set of all voxels in a 3D image as a high-dimensional dynamical system whose trajectory determines the targeted deformation field. Our method leverages deep neural networks for their expressive power in modeling dynamical systems, and simultaneously optimizes for a dynamical system between the image pairs and the corresponding transformation. Our formulation allows various constraints to be imposed along the transformation to maintain desired regularities. Our experiment results show that our method outperforms the benchmarks under various metrics. Additionally, we demonstrate the feasibility to expand our framework to register multiple image sets using a unified form of transformation,which could possibly serve a wider range of applications. (@wu_nodeo_2022)

Chenglong Xia, Jean Fan, George Emanuel, Junjie Hao, and Xiaowei Zhuang Spatial transcriptome profiling by merfish reveals subcellular rna compartmentalization and cell cycle-dependent gene expression , 116(39):19490–19499, 2019. **Abstract:** The expression profiles and spatial distributions of RNAs regulate many cellular functions. Image-based transcriptomic approaches provide powerful means to measure both expression and spatial information of RNAs in individual cells within their native environment. Among these approaches, multiplexed error-robust fluorescence in situ hybridization (MERFISH) has achieved spatially resolved RNA quantification at transcriptome scale by massively multiplexing single-molecule FISH measurements. Here, we increased the gene throughput of MERFISH and demonstrated simultaneous measurements of RNA transcripts from ∼10,000 genes in individual cells with ∼80% detection efficiency and ∼4% misidentification rate. We combined MERFISH with cellular structure imaging to determine subcellular compartmentalization of RNAs. We validated this approach by showing enrichment of secretome transcripts at the endoplasmic reticulum, and further revealed enrichment of long noncoding RNAs, RNAs with retained introns, and a subgroup of protein-coding mRNAs in the cell nucleus. Leveraging spatially resolved RNA profiling, we developed an approach to determine RNA velocity in situ using the balance of nuclear versus cytoplasmic RNA counts. We applied this approach to infer pseudotime ordering of cells and identified cells at different cell-cycle states, revealing ∼1,600 genes with putative cell cycle-dependent expression and a gradual transcription profile change as cells progress through cell-cycle stages. Our analysis further revealed cell cycle-dependent and cell cycle-independent spatial heterogeneity of transcriptionally distinct cells. We envision that the ability to perform spatially resolved, genome-wide RNA profiling with high detection efficiency and accuracy by MERFISH could help address a wide array of questions ranging from the regulation of gene expression in cells to the development of cell fate and organization in tissues. (@xia2019spatial)

Deshan Yang, Hua Li, Daniel A Low, Joseph O Deasy, and Issam El Naqa A fast inverse consistent deformable image registration method based on symmetric optical flow computation , 53(21):6143, 2008. **Abstract:** Deformable image registration is widely used in various radiation therapy applications including daily treatment planning adaptation to map planned tissue or dose to changing anatomy. In this work, a simple and efficient inverse consistency deformable registration method is proposed with aims of higher registration accuracy and faster convergence speed. Instead of registering image I to a second image J, the two images are symmetrically deformed toward one another in multiple passes, until both deformed images are matched and correct registration is therefore achieved. In each pass, a delta motion field is computed by minimizing a symmetric optical flow system cost function using modified optical flow algorithms. The images are then further deformed with the delta motion field in the positive and negative directions respectively, and then used for the next pass. The magnitude of the delta motion field is forced to be less than 0.4 voxel for every pass in order to guarantee smoothness and invertibility for the two overall motion fields that are accumulating the delta motion fields in both positive and negative directions, respectively. The final motion fields to register the original images I and J, in either direction, are calculated by inverting one overall motion field and combining the inversion result with the other overall motion field. The final motion fields are inversely consistent and this is ensured by the symmetric way that registration is carried out. The proposed method is demonstrated with phantom images, artificially deformed patient images and 4D-CT images. Our results suggest that the proposed method is able to improve the overall accuracy (reducing registration error by 30% or more, compared to the original and inversely inconsistent optical flow algorithms), reduce the inverse consistency error (by 95% or more) and increase the convergence rate (by 100% or more). The overall computation speed may slightly decrease, or increase in most cases because the new method converges faster. Compared to previously reported inverse consistency algorithms, the proposed method is simpler, easier to implement and more efficient. (@yang2008opticalflow)

Michael A Yassa, Shauna M Stark, Arnold Bakker, Marilyn S Albert, Michela Gallagher, and Craig EL Stark High-resolution structural and functional mri of hippocampal ca3 and dentate gyrus in patients with amnestic mild cognitive impairment , 51(3):1242–1252, 2010. **Abstract:** Functional magnetic resonance imaging (fMRI) studies have observed hyperactivity in the hippocampal region in individuals with Mild Cognitive Impairment (MCI). However, the actual source of such hyperactivity is not well understood. Studies of aged rats observed similar hyperactive signals in the CA3 region of the hippocampus that correlated with spatial memory deficits and, in particular, with their ability to represent novel environments as being distinct from familiar ones (pattern separation). In this study, we tested the hypothesis that patients with amnestic MCI (aMCI) have deficits in pattern separation, along with hyperactive fMRI BOLD activity in the CA3 region of the hippocampus. We used high-resolution fMRI during a continuous recognition task designed to emphasize pattern separation. We conducted hippocampal subfield- level region of interest analyses to test for dysfunctional activity in aMCI patients. We found that patients showed impaired performance on trials that taxed their pattern separation abilities. We also observed hyperactive BOLD signals in the CA3/dentate and hypoactive signals in the entorhinal cortex during the separation condition. In a high-resolution morphometric analysis of hippocampal subfields, aMCI patients also had smaller CA3/dentate and CA1 volumes (no difference in the subiculum). The CA3/dentate region bilaterally also exhibited the largest shape deformations in aMCI patients, suggesting that this locus is affected early in the course of the disease. These findings suggest that structural and functional changes in the CA3/dentate region of the hippocampus contribute to the deficits in episodic memory that are observed in patients with aMCI. The functional hyperactivity may be evidence for a dysfunctional encoding mechanism, consistent with the predictions of computational models of hippocampal learning. © 2010 Elsevier Inc. All rights reserved. †Corresponding author: Craig E. L. Stark, Ph.D., 211 Qureshey Research Laboratory, University of California, Irvine, Irvine CA, 92697-3800, Tel (949) 824-4230, Fax (949) 824-2447, cestark@uci.edu. Publisher’s Disclaimer: This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors (@yassa2010high)

Inwan Yoo, David GC Hildebrand, Willie F Tobin, Wei-Chung Allen Lee, and Won-Ki Jeong ssemnet: Serial-section electron microscopy image registration using a spatial transformer network with learned features pages 249–257, 2017. **Abstract:** The alignment of serial-section electron microscopy (ssEM) images is critical for e orts in neuroscience that seek to reconstruct neu- ronal circuits. However, each ssEM plane contains densely packed struc- tures that vary from one section to the next, which makes matching fea- tures across images a challenge. Advances in deep learning has resulted in unprecedented performance in similar computer vision problems, but to our knowledge, they have not been successfully applied to ssEM image co-registration. In this paper, we introduce a novel deep network model that combines a spatial transformer for image deformation and a convo- lutional autoencoder for unsupervised feature learning for robust ssEM image alignment. This results in improved accuracy and robustness while requiring substantially less user intervention than conventional methods. We evaluate our method by comparing registration quality across several datasets. 1 Introduction Ambitious e orts in neuroscience\|referred to as \\}connectomics"\|seek to generate comprehensive brain connectivity maps. This eld utilizes the high res- olution of electron microscopy (EM) to resolve neuronal structures such as den- dritic spine necks and synapses, which are only tens of nanometers in size \[5\]. A standard procedure for obtaining such datasets is cutting brain tissue into 30 50 nm-thick sections (e.g. ATUM \[4\]), acquiring images with 2  5 nm lat- eral resolution for each section, and aligning two-dimensional (2D) images into three-dimensional (3D) volumes. Though the tissue is chemically xed and em- bedded in epoxy resin to preserve ultrastructure, several deformations occur in this serial-section EM (ssEM) process. These include tissue shrinkage, com- pression or expansion during sectioning, and warping from sample heating or charging due to the electron beam. Overcoming such non-linear distortions are necessary to reproduce a 3D image volume in a state as close as possible to the original biological specimen. Therefore, excellent image alignment is an impor- tant prerequisite for subsequent analysis.arXiv:1707.07833v2 \[cs.CV\] 5 Dec 20172 Authors Suppressed Due to Excessive Length Signi cant research e orts in image registration have been made to address medical imaging needs. However, ssEM image registration remains challenging due to its image characteristics: large and irregular tissue deformations with artifacts such as dusts and folds, drifting for long image sequences alignment, and diculty in ndin (@yoo2017ssemnet)

Paul A Yushkevich, John Pluta, Hongzhi Wang, Laura EM Wisse, Sandhitsu Das, and David Wolk Ic-p-174: fast automatic segmentation of hippocampal subfields and medial temporal lobe subregions in 3 tesla and 7 tesla t2-weighted mri , 12:P126–P127, 2016. **Abstract:** NFT pathology emerges in the transentorhinal are and proceeds in a complex pattern through different medial temporal lobe (MTL) subregions and hippocampal subfields, eventually spreading to most of the cortex. Since neurodegeneration in AD closely follows NFT pathology, granular MRI-based measures of change in MTL subregions can be more sensitive biomarkers for treatment evaluation than conventional markers such as hippocampal volume, particularly in preclinical disease, when effects are subtle and largely contained to the MTL. Several large studies, including ADNI, collect T2-weighted MRI scans of the MTL that offer higher resolution and significantly better contrast for visualizing hippocampal and MTL subregion boundaries than conventional 1mm isotropic T1w MRI. We previously developed an automatic multi-atlas segmentation technique "ASHS" that extracts MTL subregion volume and thickness measures in 3T and 7T MRI scans, and showed that it is can reliably reproduce manual segmentation. Until now, however, ASHS required access to a high-performance computing cluster. Through extensive optimization, we have accelerated ASHS by more than one order of magnitude, making it possible to use on commodity computers without compromising reliability. ASHS uses deformable registration (Avants et al., 2008) to warp 20-30 expert-labeled example scans called atlases to a new subject’s T2w MRI scan, and combines the deformed segmentations using intelligent label fusion. Registration accounts for \>95% of computational requirements of ASHS. We optimized the registration in ASHS using separable one-dimensional algorithms for computing the normalized cross-correlation metric of image similarity, as well as approximate deformation field regularization. We evaluate ASHS using ten-fold cross-validation on 29 3T expert-labeled scans. Optimized ASHS runs 16 times faster than the published ASHS algorithm on the same hardware. Processing for one subject takes 24 minutes on an 8-core MacBook laptop. Segmentation accuracy is not statistically different from previously published results. (@yushkevich2016ic)

Liutong Zhang, Lei Zhou, Ruiyang Li, Xianyu Wang, Boxuan Han, and Hongen Liao Cascaded feature warping network for unsupervised medical image registration In *2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)*, pages 913–916. IEEE, 2021. **Abstract:** Deformable image registration is widely utilized in medical image analysis, but most proposed methods fail in the situation of complex deformations. In this paper, we present a cascaded feature warping network to perform the coarse-to-fine registration. To achieve this, a shared-weights encoder network is adopted to generate the feature pyramids for the unaligned images. The feature warping registration module is then used to estimate the deformation field at each level. The coarse-to-fine manner is implemented by cascading the module from the bottom level to the top level. Furthermore, the multi-scale loss is also introduced to boost the registration performance. We employ two public benchmark datasets and conduct various experiments to evaluate our method. The results show that our method outperforms the state-of-the-art methods, which also demonstrates that the cascaded feature warping network can perform the coarse-to-fine registration effectively and efficiently. (@zhang2021cascaded)

Shengyu Zhao, Yue Dong, Eric I-Chao Chang, and Yan Xu Recursive cascaded networks for unsupervised medical image registration In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)*, October 2019. **Abstract:** We present recursive cascaded networks, a general architecture that enables learning deep cascades, for deformable image registration. The proposed architecture is simple in design and can be built on any base network. The moving image is warped successively by each cascade and finally aligned to the fixed image; this procedure is recursive in a way that every cascade learns to perform a progressive deformation for the current warped image. The entire system is end-to-end and jointly trained in an unsupervised manner. In addition, enabled by the recursive architecture, one cascade can be iteratively applied for multiple times during testing, which approaches a better fit between each of the image pairs. We evaluate our method on 3D medical images, where deformable registration is most commonly applied. We demonstrate that recursive cascaded networks achieve consistent, significant gains and outperform state-of-the-art methods. The performance reveals an increasing trend as long as more cascades are trained, while the limit is not observed. Code is available at https://github.com/microsoft/Recursive-Cascaded-Networks. (@Zhao_2019_ICCV)

Shengyu Zhao, Tingfung Lau, Ji Luo, I Eric, Chao Chang, and Yan Xu Unsupervised 3d end-to-end medical image registration with volume tweening network , 24(5):1394–1404, 2019. **Abstract:** 3D medical image registration is of great clinical importance. However, supervised learning methods require a large amount of accurately annotated corresponding control points (or morphing), which are very difficult to obtain. Unsupervised learning methods ease the burden of manual annotation by exploiting unlabeled data without supervision. In this paper, we propose a new unsupervised learning method using convolutional neural networks under an end-to-end framework, Volume Tweening Network (VTN), for 3D medical image registration. We propose three innovative technical components: (1) An end-to-end cascading scheme that resolves large displacement; (2) An efficient integration of affine registration network; and (3) An additional invertibility loss that encourages backward consistency. Experiments demonstrate that our algorithm is 880x faster (or 3.3x faster without GPU acceleration) than traditional optimization-based methods and achieves state-of-theart performance in medical image registration. (@zhao2019unsupervised)

</div>

[^1]: Equal advising
